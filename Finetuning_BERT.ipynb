{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "  \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our friends won't buy this analysis, let alone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Poseidon appears to own a dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8547</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Digitize is my happiest memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8548</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is easy to slay the Gorgon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I had the strangest feeling that I knew you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What all did you get for Christmas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8551 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "0               gj04      1         NaN   \n",
       "1               gj04      1         NaN   \n",
       "2               gj04      1         NaN   \n",
       "3               gj04      1         NaN   \n",
       "4               gj04      1         NaN   \n",
       "...              ...    ...         ...   \n",
       "8546            ad03      0           *   \n",
       "8547            ad03      0           *   \n",
       "8548            ad03      1         NaN   \n",
       "8549            ad03      1         NaN   \n",
       "8550            ad03      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "0     Our friends won't buy this analysis, let alone...  \n",
       "1     One more pseudo generalization and I'm giving up.  \n",
       "2      One more pseudo generalization or I'm giving up.  \n",
       "3        The more we study verbs, the crazier they get.  \n",
       "4             Day by day the facts are getting murkier.  \n",
       "...                                                 ...  \n",
       "8546                   Poseidon appears to own a dragon  \n",
       "8547                     Digitize is my happiest memory  \n",
       "8548                     It is easy to slay the Gorgon.  \n",
       "8549       I had the strangest feeling that I knew you.  \n",
       "8550                What all did you get for Christmas?  \n",
       "\n",
       "[8551 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/DELL/Desktop/cola_public/raw/in_domain_train.tsv',delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>I have six of them more.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>I lent Tony the book halfway.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>the bottle drained the liquid free.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>She always clad herself in black.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>the box contains little tool.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>They tried all to like John.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>It mattered with a telescope.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>It started to rain after Jackie and me, we had...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>Sketch by his students appeared in the magazine.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>Because did Marianne love Willoughby, she refu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>Everyone rumored that he was on his way out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>I would like to might do it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>That the sun is out was obvious.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>Kim must will bake a cake.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>To please John is ready.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>We proclaimed sincerely John to be a hero.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Linda winked his eye.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>Shannon kissed quietly the kitten.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>She tried to may leave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>I know which book Mag read, and which book Bob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>Almost an owl hunts mice.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>Paul exhaled at Mary.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>John seems that it is likely to win.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>Mary got heard to insult her parents.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>The boy whose uncle and Tom's aunt's grandmoth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>The package drove.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>Kim likes Sandy, and Lee to Leslie.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7423</th>\n",
       "      <td>Yes, she.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>Which city do you believe the claim that Phili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>the book with a red cover from Blackwell of po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>She always wore.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7058</th>\n",
       "      <td>I was trying and buying some whiskey.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>Kelly reeked the onions.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>I'm going out, wherever that hurricane.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>I went to the movies not to pick the shirts up.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Although I don't know which book Sam did, I do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Whose tax did the nurse polish her trombone an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>Her will put a picture of Bill on your desk be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>It is important for the more you eat, the more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>Linda taped the wall with the picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>John may rain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>The more contented for us to pretend to be bec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>It is that Bill is honest that John believes.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7963</th>\n",
       "      <td>There was he in the garden.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>The thief stole at the painting from the museum.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>John heard that they criticized each other.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>Bill will put a picture of she her on your des...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6012</th>\n",
       "      <td>He always might eats deep fried muffins.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>Carla poured the pitcher with lemonade.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>Because in came Aunt Norris, Fanny stopped tal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "5465                           I have six of them more.      0\n",
       "2105                      I lent Tony the book halfway.      0\n",
       "591                 the bottle drained the liquid free.      0\n",
       "3188                  She always clad herself in black.      0\n",
       "3477                      the box contains little tool.      0\n",
       "496                        They tried all to like John.      0\n",
       "7365                      It mattered with a telescope.      0\n",
       "1823  It started to rain after Jackie and me, we had...      0\n",
       "3926   Sketch by his students appeared in the magazine.      0\n",
       "6751  Because did Marianne love Willoughby, she refu...      0\n",
       "4658       Everyone rumored that he was on his way out.      0\n",
       "8074                        I would like to might do it      0\n",
       "1522                   That the sun is out was obvious.      0\n",
       "4419                         Kim must will bake a cake.      0\n",
       "5010                           To please John is ready.      0\n",
       "747          We proclaimed sincerely John to be a hero.      0\n",
       "3138                              Linda winked his eye.      0\n",
       "5738                 Shannon kissed quietly the kitten.      0\n",
       "8356                             She tried to may leave      0\n",
       "912   I know which book Mag read, and which book Bob...      0\n",
       "5245                          Almost an owl hunts mice.      0\n",
       "3132                              Paul exhaled at Mary.      0\n",
       "396                John seems that it is likely to win.      0\n",
       "4737              Mary got heard to insult her parents.      0\n",
       "1423  The boy whose uncle and Tom's aunt's grandmoth...      0\n",
       "2707                                 The package drove.      0\n",
       "7104                Kim likes Sandy, and Lee to Leslie.      0\n",
       "7423                                          Yes, she.      0\n",
       "8225  Which city do you believe the claim that Phili...      0\n",
       "5790  the book with a red cover from Blackwell of po...      0\n",
       "3183                                   She always wore.      0\n",
       "7058              I was trying and buying some whiskey.      0\n",
       "3216                           Kelly reeked the onions.      0\n",
       "182             I'm going out, wherever that hurricane.      0\n",
       "1285    I went to the movies not to pick the shirts up.      0\n",
       "918   Although I don't know which book Sam did, I do...      0\n",
       "1272  Whose tax did the nurse polish her trombone an...      0\n",
       "7138  Her will put a picture of Bill on your desk be...      0\n",
       "148   It is important for the more you eat, the more...      0\n",
       "2885             Linda taped the wall with the picture.      0\n",
       "4464                                     John may rain.      0\n",
       "1756  The more contented for us to pretend to be bec...      0\n",
       "5082      It is that Bill is honest that John believes.      0\n",
       "7963                        There was he in the garden.      0\n",
       "2657   The thief stole at the painting from the museum.      0\n",
       "7547        John heard that they criticized each other.      0\n",
       "7140  Bill will put a picture of she her on your des...      0\n",
       "6012           He always might eats deep fried muffins.      0\n",
       "2136            Carla poured the pitcher with lemonade.      0\n",
       "6761  Because in came Aunt Norris, Fanny stopped tal...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(50)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Our friends won't buy this analysis, let alone the next one we propose.\"\n",
      " \"One more pseudo generalization and I'm giving up.\"\n",
      " \"One more pseudo generalization or I'm giving up.\" ...\n",
      " 'It is easy to slay the Gorgon.'\n",
      " 'I had the strangest feeling that I knew you.'\n",
      " 'What all did you get for Christmas?']\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "print(sentences)\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tokenization & Input Formatting\n",
    "3.1. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading bert tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "print('loading bert tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal: Our friends won't buy this analysis, let alone the next one we propose.\n",
      "tokenzied: ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
      "token IDs: [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
     ]
    }
   ],
   "source": [
    "print('orginal:', sentences[0])\n",
    "\n",
    "print('tokenzied:', tokenizer.tokenize((sentences[0])))\n",
    "\n",
    "print('token IDs:', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " a. Add special tokens to the start and end of each sentence.\n",
    " b. Pad & truncate all sentences to a single constant length.\n",
    " c. Explicitly differentiate real tokens from padding tokens with the \"attention mask\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Required Formatting\n",
    "3.3. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence len 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[101,\n",
       "  2256,\n",
       "  2814,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  4965,\n",
       "  2023,\n",
       "  4106,\n",
       "  1010,\n",
       "  2292,\n",
       "  2894,\n",
       "  1996,\n",
       "  2279,\n",
       "  2028,\n",
       "  2057,\n",
       "  16599,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2028,\n",
       "  2062,\n",
       "  18404,\n",
       "  2236,\n",
       "  3989,\n",
       "  1998,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  3228,\n",
       "  2039,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2028,\n",
       "  2062,\n",
       "  18404,\n",
       "  2236,\n",
       "  3989,\n",
       "  2030,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  3228,\n",
       "  2039,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2057,\n",
       "  2817,\n",
       "  16025,\n",
       "  1010,\n",
       "  1996,\n",
       "  13675,\n",
       "  16103,\n",
       "  2121,\n",
       "  2027,\n",
       "  2131,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2154, 2011, 2154, 1996, 8866, 2024, 2893, 14163, 8024, 3771, 1012, 102],\n",
       " [101, 1045, 1005, 2222, 8081, 2017, 1037, 4392, 1012, 102],\n",
       " [101, 5965, 27129, 1996, 4264, 4257, 1012, 102],\n",
       " [101, 3021, 19055, 2010, 2126, 2041, 1997, 1996, 4825, 1012, 102],\n",
       " [101, 2057, 1005, 2128, 5613, 1996, 2305, 2185, 1012, 102],\n",
       " [101, 11458, 25756, 1996, 3384, 4257, 1012, 102],\n",
       " [101, 1996, 4401, 4191, 1996, 2377, 2125, 1996, 2754, 1012, 102],\n",
       " [101, 1996, 8644, 10619, 5024, 1012, 102],\n",
       " [101, 3021, 4565, 2041, 1997, 1996, 2282, 1012, 102],\n",
       " [101, 1996, 19785, 27129, 1996, 4870, 4257, 1012, 102],\n",
       " [101, 1996, 19785, 27129, 1996, 4870, 1012, 102],\n",
       " [101, 3021, 3631, 1996, 7198, 28251, 2046, 4109, 1012, 102],\n",
       " [101, 3021, 3631, 1996, 7198, 28251, 1012, 102],\n",
       " [101, 2027, 10749, 1996, 9047, 4318, 1012, 102],\n",
       " [101, 2027, 10749, 1996, 9047, 1012, 102],\n",
       " [101, 1996, 2934, 5720, 2149, 2046, 1037, 24646, 17822, 1012, 102],\n",
       " [101, 1996, 2934, 5720, 2149, 1012, 102],\n",
       " [101, 2057, 7581, 9731, 21221, 1012, 102],\n",
       " [101, 2057, 7581, 9731, 1012, 102],\n",
       " [101, 2057, 7581, 4302, 21221, 1012, 102],\n",
       " [101, 4302, 19055, 2370, 2046, 1037, 4906, 1012, 102],\n",
       " [101, 4302, 19055, 2370, 1012, 102],\n",
       " [101, 4302, 19055, 2149, 2046, 1037, 4906, 1012, 102],\n",
       " [101, 3021, 2628, 1996, 2346, 2046, 1996, 3224, 1012, 102],\n",
       " [101, 2057, 5225, 3307, 1019, 2013, 17371, 2000, 16420, 1012, 102],\n",
       " [101, 5965, 12808, 1996, 17271, 2000, 2049, 3120, 1012, 102],\n",
       " [101, 2198, 10948, 17569, 2229, 2408, 1996, 2282, 1012, 102],\n",
       " [101, 3021, 24471, 15833, 2041, 1996, 3332, 1012, 102],\n",
       " [101, 3021, 19055, 2041, 1996, 3332, 1012, 102],\n",
       " [101, 3021, 23919, 2006, 1996, 2723, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  11848,\n",
       "  15748,\n",
       "  2083,\n",
       "  1996,\n",
       "  2723,\n",
       "  2046,\n",
       "  1996,\n",
       "  3829,\n",
       "  2917,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 3021, 8823, 2125, 1996, 2723, 1012, 102],\n",
       " [101, 3021, 10749, 2013, 1996, 21290, 1012, 102],\n",
       " [101, 2023, 3384, 8691, 2015, 4257, 4089, 1012, 102],\n",
       " [101, 2027, 2081, 2032, 2343, 1012, 102],\n",
       " [101, 2027, 2081, 2032, 4854, 1012, 102],\n",
       " [101, 2027, 3303, 2032, 2000, 2468, 4854, 2011, 2437, 2032, 1012, 102],\n",
       " [101, 2027, 3303, 2032, 2000, 2468, 2343, 2011, 2437, 2032, 1012, 102],\n",
       " [101, 2027, 2081, 2032, 2000, 15575, 1012, 102],\n",
       " [101, 2027, 2081, 2032, 2046, 1037, 6071, 1012, 102],\n",
       " [101, 1996, 20820, 22257, 2083, 1996, 5234, 1012, 102],\n",
       " [101, 1996, 9540, 22257, 2091, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 10432, 26265, 2627, 1996, 2160, 1012, 102],\n",
       " [101, 1996, 6181, 6110, 4018, 9655, 2039, 1996, 5108, 1012, 102],\n",
       " [101, 1996, 2482, 10189, 8126, 2091, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 3899, 17554, 2041, 1997, 1996, 2282, 1012, 102],\n",
       " [101, 1996, 3899, 17554, 2049, 2126, 2041, 1997, 1996, 2282, 1012, 102],\n",
       " [101, 3021, 26265, 2010, 2126, 2627, 1996, 2160, 1012, 102],\n",
       " [101, 1996, 6965, 9955, 2046, 1996, 3224, 1012, 102],\n",
       " [101, 3021, 5419, 2091, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 6965, 2253, 2046, 1996, 3224, 2011, 24866, 1012, 102],\n",
       " [101, 1996, 6965, 2253, 2046, 1996, 3224, 1998, 8558, 9955, 1012, 102],\n",
       " [101, 1996, 2311, 2003, 4206, 1998, 2898, 1012, 102],\n",
       " [101, 1996, 2311, 2003, 4206, 1998, 4206, 1012, 102],\n",
       " [101, 2023, 2311, 2003, 12283, 1998, 7289, 2084, 2008, 2028, 1012, 102],\n",
       " [101, 2023, 2311, 2288, 12283, 1998, 7289, 2084, 2008, 2028, 1012, 102],\n",
       " [101, 2023, 2311, 2288, 12283, 1998, 12283, 1012, 102],\n",
       " [101, 2023, 2311, 2003, 12283, 1998, 12283, 1012, 102],\n",
       " [101, 2023, 2311, 2288, 2084, 2008, 2028, 1012, 102],\n",
       " [101, 2023, 2311, 2003, 2084, 2008, 2028, 1012, 102],\n",
       " [101, 3021, 13715, 2046, 1996, 5430, 1012, 102],\n",
       " [101, 3021, 13715, 2046, 1996, 5430, 2005, 2847, 1012, 102],\n",
       " [101, 3021, 3724, 4302, 2125, 1996, 10682, 2005, 2847, 1012, 102],\n",
       " [101, 3021, 13715, 2091, 1996, 2314, 2005, 2847, 1012, 102],\n",
       " [101, 3021, 13715, 2091, 1996, 2314, 1012, 102],\n",
       " [101, 3021, 3724, 4302, 2247, 1996, 4446, 2005, 2847, 1012, 102],\n",
       " [101, 3021, 3724, 4302, 2247, 1996, 4446, 1012, 102],\n",
       " [101, 1996, 2346, 1062, 8004, 4143, 15567, 2091, 1996, 2940, 1012, 102],\n",
       " [101, 1996, 8164, 7121, 2058, 1996, 4139, 3240, 1012, 102],\n",
       " [101, 1996, 15871, 7121, 1996, 8164, 2058, 1996, 4139, 3240, 1012, 102],\n",
       " [101, 1996, 15871, 2921, 1996, 8164, 7121, 2058, 1996, 4139, 3240, 1012, 102],\n",
       " [101, 3520, 3013, 2370, 2489, 1012, 102],\n",
       " [101, 3520, 2288, 2489, 2011, 6276, 2010, 4344, 1012, 102],\n",
       " [101, 3021, 6639, 2370, 2000, 3637, 1012, 102],\n",
       " [101, 3021, 6639, 9790, 2000, 3637, 1012, 102],\n",
       " [101, 3021, 7757, 2370, 2083, 1996, 4920, 1012, 102],\n",
       " [101, 3021, 6369, 2370, 2000, 3637, 1012, 102],\n",
       " [101, 3021, 7757, 1996, 13997, 2083, 1996, 4920, 1012, 102],\n",
       " [101, 3021, 6369, 9790, 2000, 3637, 1012, 102],\n",
       " [101, 1996, 7764, 22257, 2993, 2000, 1996, 2598, 1012, 102],\n",
       " [101, 2065, 1996, 7026, 8369, 1010, 2009, 2071, 3614, 2993, 10021, 1012, 102],\n",
       " [101, 2016, 7581, 21221, 1012, 102],\n",
       " [101, 6945, 6639, 2000, 3637, 1012, 102],\n",
       " [101, 1996, 6816, 23919, 2000, 2331, 1012, 102],\n",
       " [101,\n",
       "  2002,\n",
       "  19055,\n",
       "  8300,\n",
       "  1998,\n",
       "  2057,\n",
       "  2020,\n",
       "  2035,\n",
       "  2058,\n",
       "  24793,\n",
       "  2098,\n",
       "  1010,\n",
       "  2926,\n",
       "  7838,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  19055,\n",
       "  8300,\n",
       "  1010,\n",
       "  10137,\n",
       "  2010,\n",
       "  4451,\n",
       "  1998,\n",
       "  19752,\n",
       "  2104,\n",
       "  2010,\n",
       "  3052,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  19055,\n",
       "  2370,\n",
       "  8300,\n",
       "  2006,\n",
       "  1996,\n",
       "  2924,\n",
       "  1997,\n",
       "  1996,\n",
       "  2697,\n",
       "  2073,\n",
       "  2002,\n",
       "  1998,\n",
       "  3021,\n",
       "  2018,\n",
       "  2037,\n",
       "  2377,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 6902, 27626, 2370, 8300, 1012, 102],\n",
       " [101,\n",
       "  2016,\n",
       "  19055,\n",
       "  2841,\n",
       "  8300,\n",
       "  2004,\n",
       "  1996,\n",
       "  7053,\n",
       "  5565,\n",
       "  2006,\n",
       "  2014,\n",
       "  4451,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 15485, 23277, 8004, 11533, 3031, 1996, 10135, 1012, 102],\n",
       " [101, 1996, 7967, 12501, 3031, 1996, 10135, 1012, 102],\n",
       " [101, 1996, 3608, 23277, 8004, 11533, 2993, 6065, 1012, 102],\n",
       " [101, 3021, 23277, 8004, 11533, 2370, 6065, 1012, 102],\n",
       " [101, 4862, 4143, 23277, 8004, 11533, 2014, 11868, 6065, 1012, 102],\n",
       " [101, 1996, 2125, 2415, 9419, 4875, 22920, 3184, 2993, 6065, 1012, 102],\n",
       " [101, 1996, 2062, 2017, 4521, 1010, 1996, 2625, 2017, 2215, 1012, 102],\n",
       " [101, 2065, 2017, 4521, 2062, 1010, 2017, 2215, 7978, 2135, 2625, 1012, 102],\n",
       " [101, 2043, 2017, 4521, 2062, 1010, 2017, 2215, 7978, 2135, 2625, 1012, 102],\n",
       " [101, 2004, 2017, 4521, 2062, 1010, 2017, 2215, 7978, 2135, 2625, 1012, 102],\n",
       " [101, 1996, 2087, 2017, 2215, 1010, 1996, 2560, 2017, 4521, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  9790,\n",
       "  4152,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  5965,\n",
       "  19837,\n",
       "  2015,\n",
       "  2014,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2008,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2008,\n",
       "  9790,\n",
       "  4152,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  5965,\n",
       "  19837,\n",
       "  2015,\n",
       "  2014,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2228,\n",
       "  2008,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  2025,\n",
       "  7135,\n",
       "  2011,\n",
       "  1996,\n",
       "  2801,\n",
       "  2008,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  5793,\n",
       "  2008,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2025,\n",
       "  4498,\n",
       "  3154,\n",
       "  2065,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2215,\n",
       "  2000,\n",
       "  4863,\n",
       "  3599,\n",
       "  2339,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2215,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  5157,\n",
       "  2008,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  12778,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  5157,\n",
       "  2008,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  3477,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  5157,\n",
       "  2008,\n",
       "  2198,\n",
       "  3477,\n",
       "  2062,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  5157,\n",
       "  2008,\n",
       "  2198,\n",
       "  12778,\n",
       "  2062,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  4521,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2131,\n",
       "  17076,\n",
       "  16252,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2057,\n",
       "  4521,\n",
       "  1010,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2017,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2131,\n",
       "  17076,\n",
       "  16252,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2057,\n",
       "  4521,\n",
       "  1010,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2057,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  2038,\n",
       "  28270,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2008,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  2038,\n",
       "  28270,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  15811,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  2008,\n",
       "  2079,\n",
       "  2017,\n",
       "  2448,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  15811,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  2079,\n",
       "  2017,\n",
       "  2448,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  15811,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2079,\n",
       "  2017,\n",
       "  2156,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2009,\n",
       "  15811,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2008,\n",
       "  2079,\n",
       "  2017,\n",
       "  2156,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  2009,\n",
       "  15811,\n",
       "  6211,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2004,\n",
       "  2009,\n",
       "  15811,\n",
       "  6211,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2004,\n",
       "  2009,\n",
       "  15811,\n",
       "  6211,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2008,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  2009,\n",
       "  15811,\n",
       "  6211,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2008,\n",
       "  3544,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2129,\n",
       "  2172,\n",
       "  6211,\n",
       "  2038,\n",
       "  2009,\n",
       "  28270,\n",
       "  1010,\n",
       "  1996,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2017,\n",
       "  2156,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2129,\n",
       "  2172,\n",
       "  6211,\n",
       "  2038,\n",
       "  2009,\n",
       "  28270,\n",
       "  1010,\n",
       "  2043,\n",
       "  2017,\n",
       "  2156,\n",
       "  1037,\n",
       "  5514,\n",
       "  4834,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  12347,\n",
       "  2562,\n",
       "  2115,\n",
       "  2677,\n",
       "  3844,\n",
       "  2055,\n",
       "  2009,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  3071,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  7906,\n",
       "  2010,\n",
       "  2502,\n",
       "  2677,\n",
       "  3844,\n",
       "  2055,\n",
       "  2009,\n",
       "  1010,\n",
       "  7929,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  2198,\n",
       "  20323,\n",
       "  2062,\n",
       "  1010,\n",
       "  2562,\n",
       "  2115,\n",
       "  2677,\n",
       "  3844,\n",
       "  12347,\n",
       "  1010,\n",
       "  7929,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2004,\n",
       "  2198,\n",
       "  20323,\n",
       "  2062,\n",
       "  1010,\n",
       "  2562,\n",
       "  2115,\n",
       "  2677,\n",
       "  3844,\n",
       "  12347,\n",
       "  1010,\n",
       "  7929,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2562,\n",
       "  2115,\n",
       "  2677,\n",
       "  3844,\n",
       "  12347,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  20323,\n",
       "  1010,\n",
       "  7929,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  3071,\n",
       "  2562,\n",
       "  2115,\n",
       "  2677,\n",
       "  3844,\n",
       "  12347,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  20323,\n",
       "  1010,\n",
       "  7929,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2064,\n",
       "  2092,\n",
       "  5674,\n",
       "  1996,\n",
       "  2062,\n",
       "  2032,\n",
       "  5983,\n",
       "  1010,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2032,\n",
       "  2893,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 3021, 2064, 2092, 5674, 2893, 6638, 1012, 102],\n",
       " [101,\n",
       "  3021,\n",
       "  2064,\n",
       "  2092,\n",
       "  5674,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2893,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  5965,\n",
       "  2064,\n",
       "  2092,\n",
       "  5674,\n",
       "  3533,\n",
       "  2893,\n",
       "  6638,\n",
       "  3334,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2005,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  2000,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2005,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2005,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  2000,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2005,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  2000,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2005,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  2000,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2005,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2005,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  6176,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2005,\n",
       "  2017,\n",
       "  2000,\n",
       "  2022,\n",
       "  2062,\n",
       "  6176,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2590,\n",
       "  2000,\n",
       "  2022,\n",
       "  2062,\n",
       "  6176,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2017,\n",
       "  4521,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 2064, 2092, 5674, 2855, 2984, 10739, 1996, 3160, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  2064,\n",
       "  2092,\n",
       "  5674,\n",
       "  2007,\n",
       "  1037,\n",
       "  11300,\n",
       "  3388,\n",
       "  2984,\n",
       "  9846,\n",
       "  1996,\n",
       "  14007,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2064,\n",
       "  2092,\n",
       "  5674,\n",
       "  2065,\n",
       "  2002,\n",
       "  20323,\n",
       "  2062,\n",
       "  1010,\n",
       "  2032,\n",
       "  2893,\n",
       "  6638,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2025,\n",
       "  4498,\n",
       "  5793,\n",
       "  2065,\n",
       "  1010,\n",
       "  2984,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1010,\n",
       "  2016,\n",
       "  4152,\n",
       "  14777,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2025,\n",
       "  4498,\n",
       "  5793,\n",
       "  3251,\n",
       "  1010,\n",
       "  2984,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1010,\n",
       "  2016,\n",
       "  4152,\n",
       "  14777,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1998,\n",
       "  2016,\n",
       "  4152,\n",
       "  14777,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2065,\n",
       "  2984,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1010,\n",
       "  2016,\n",
       "  4152,\n",
       "  14777,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  2984,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1010,\n",
       "  2016,\n",
       "  4152,\n",
       "  14777,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  4152,\n",
       "  14777,\n",
       "  2065,\n",
       "  2016,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  4152,\n",
       "  14777,\n",
       "  2043,\n",
       "  2016,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2016,\n",
       "  2246,\n",
       "  2012,\n",
       "  4620,\n",
       "  1010,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2984,\n",
       "  2288,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  2984,\n",
       "  2246,\n",
       "  2012,\n",
       "  1010,\n",
       "  2016,\n",
       "  2288,\n",
       "  17076,\n",
       "  16252,\n",
       "  1998,\n",
       "  17076,\n",
       "  16252,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  4152,\n",
       "  14777,\n",
       "  1998,\n",
       "  2016,\n",
       "  4952,\n",
       "  2015,\n",
       "  2000,\n",
       "  1996,\n",
       "  8794,\n",
       "  2757,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  3020,\n",
       "  1996,\n",
       "  7533,\n",
       "  2024,\n",
       "  1010,\n",
       "  1996,\n",
       "  2896,\n",
       "  2010,\n",
       "  10908,\n",
       "  2024,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 3020, 1996, 7533, 1010, 1996, 2896, 2010, 10908, 1012, 102],\n",
       " [101, 2010, 10908, 2024, 2896, 1010, 1996, 3020, 1996, 7533, 1012, 102],\n",
       " [101, 2010, 10908, 2024, 2896, 1010, 1996, 3020, 1996, 7533, 2024, 1012, 102],\n",
       " [101, 2010, 10908, 2896, 1010, 1996, 3020, 1996, 7533, 1012, 102],\n",
       " [101, 2010, 10908, 2896, 1010, 1996, 3020, 1996, 7533, 2024, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  5965,\n",
       "  2003,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  3086,\n",
       "  2017,\n",
       "  2323,\n",
       "  3477,\n",
       "  2000,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  5965,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  3086,\n",
       "  2017,\n",
       "  2323,\n",
       "  3477,\n",
       "  2000,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  5965,\n",
       "  2003,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2323,\n",
       "  3477,\n",
       "  3086,\n",
       "  2000,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  5965,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2017,\n",
       "  2323,\n",
       "  3477,\n",
       "  3086,\n",
       "  2000,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2010, 10908, 2024, 2467, 2896, 2084, 3067, 1012, 102],\n",
       " [101,\n",
       "  2198,\n",
       "  2001,\n",
       "  7167,\n",
       "  2062,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  2084,\n",
       "  5965,\n",
       "  2001,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2323,\n",
       "  2467,\n",
       "  5843,\n",
       "  2115,\n",
       "  2341,\n",
       "  1010,\n",
       "  2053,\n",
       "  3043,\n",
       "  2129,\n",
       "  11281,\n",
       "  1996,\n",
       "  3309,\n",
       "  2453,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2323,\n",
       "  2467,\n",
       "  5843,\n",
       "  2115,\n",
       "  2341,\n",
       "  1010,\n",
       "  2053,\n",
       "  3043,\n",
       "  2129,\n",
       "  11281,\n",
       "  1996,\n",
       "  3309,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2933,\n",
       "  2000,\n",
       "  5843,\n",
       "  1996,\n",
       "  2341,\n",
       "  1010,\n",
       "  2053,\n",
       "  3043,\n",
       "  2129,\n",
       "  11281,\n",
       "  2023,\n",
       "  3309,\n",
       "  2003,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2933,\n",
       "  2000,\n",
       "  5843,\n",
       "  1996,\n",
       "  2341,\n",
       "  1010,\n",
       "  2053,\n",
       "  3043,\n",
       "  2129,\n",
       "  11281,\n",
       "  2023,\n",
       "  3309,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 1005, 1049, 2183, 2041, 1010, 3649, 1996, 4633, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  2183,\n",
       "  2041,\n",
       "  1010,\n",
       "  11210,\n",
       "  2008,\n",
       "  7064,\n",
       "  2453,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 1005, 1049, 2183, 2041, 1010, 11210, 2008, 7064, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4973,\n",
       "  2984,\n",
       "  2758,\n",
       "  2008,\n",
       "  3021,\n",
       "  2038,\n",
       "  3271,\n",
       "  5965,\n",
       "  2000,\n",
       "  7523,\n",
       "  1996,\n",
       "  2625,\n",
       "  1045,\n",
       "  2903,\n",
       "  2014,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2833,\n",
       "  2984,\n",
       "  4282,\n",
       "  1037,\n",
       "  2158,\n",
       "  2008,\n",
       "  20323,\n",
       "  1996,\n",
       "  27196,\n",
       "  2016,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2002,\n",
       "  3632,\n",
       "  2000,\n",
       "  1037,\n",
       "  3460,\n",
       "  2043,\n",
       "  2002,\n",
       "  4152,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2008,\n",
       "  2008,\n",
       "  2002,\n",
       "  4152,\n",
       "  8572,\n",
       "  2015,\n",
       "  2032,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2808,\n",
       "  1045,\n",
       "  3198,\n",
       "  2000,\n",
       "  3183,\n",
       "  2002,\n",
       "  2097,\n",
       "  2507,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  9631,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  1045,\n",
       "  3198,\n",
       "  2054,\n",
       "  2002,\n",
       "  2097,\n",
       "  2507,\n",
       "  2000,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  9631,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  5362,\n",
       "  2002,\n",
       "  2616,\n",
       "  1996,\n",
       "  3661,\n",
       "  1996,\n",
       "  13726,\n",
       "  2002,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  5362,\n",
       "  2002,\n",
       "  4282,\n",
       "  1037,\n",
       "  2158,\n",
       "  2008,\n",
       "  2773,\n",
       "  2098,\n",
       "  1996,\n",
       "  3661,\n",
       "  1996,\n",
       "  13726,\n",
       "  2002,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  11067,\n",
       "  2229,\n",
       "  2198,\n",
       "  6010,\n",
       "  1010,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2002,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  6010,\n",
       "  11067,\n",
       "  2229,\n",
       "  1010,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2002,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2017,\n",
       "  2360,\n",
       "  2097,\n",
       "  4965,\n",
       "  9735,\n",
       "  1010,\n",
       "  1996,\n",
       "  19366,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2017,\n",
       "  2360,\n",
       "  2008,\n",
       "  2097,\n",
       "  4965,\n",
       "  9735,\n",
       "  1010,\n",
       "  1996,\n",
       "  19366,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2017,\n",
       "  2360,\n",
       "  2008,\n",
       "  2157,\n",
       "  2044,\n",
       "  1996,\n",
       "  2265,\n",
       "  7480,\n",
       "  2097,\n",
       "  4965,\n",
       "  9735,\n",
       "  1010,\n",
       "  1996,\n",
       "  19366,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  1045,\n",
       "  2831,\n",
       "  2000,\n",
       "  3533,\n",
       "  1010,\n",
       "  1996,\n",
       "  2625,\n",
       "  2055,\n",
       "  15397,\n",
       "  1045,\n",
       "  2572,\n",
       "  13050,\n",
       "  2000,\n",
       "  2228,\n",
       "  8836,\n",
       "  2038,\n",
       "  4036,\n",
       "  2032,\n",
       "  2000,\n",
       "  9120,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  27196,\n",
       "  2002,\n",
       "  4282,\n",
       "  1037,\n",
       "  2450,\n",
       "  2008,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2002,\n",
       "  3632,\n",
       "  2000,\n",
       "  1037,\n",
       "  3460,\n",
       "  2043,\n",
       "  2002,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  20323,\n",
       "  1010,\n",
       "  1996,\n",
       "  6638,\n",
       "  3334,\n",
       "  2008,\n",
       "  2008,\n",
       "  2002,\n",
       "  4152,\n",
       "  2428,\n",
       "  8572,\n",
       "  2015,\n",
       "  2033,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2808,\n",
       "  1045,\n",
       "  4687,\n",
       "  2000,\n",
       "  3183,\n",
       "  2002,\n",
       "  2097,\n",
       "  2507,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  1045,\n",
       "  4687,\n",
       "  2054,\n",
       "  2002,\n",
       "  2097,\n",
       "  2507,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  2655,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  5362,\n",
       "  1045,\n",
       "  2113,\n",
       "  1037,\n",
       "  2158,\n",
       "  2008,\n",
       "  2097,\n",
       "  2773,\n",
       "  1996,\n",
       "  3661,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  26108,\n",
       "  2198,\n",
       "  4152,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  11067,\n",
       "  2229,\n",
       "  2198,\n",
       "  6010,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  26108,\n",
       "  2002,\n",
       "  4152,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2198,\n",
       "  6010,\n",
       "  11067,\n",
       "  2229,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4790,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  8491,\n",
       "  2111,\n",
       "  2002,\n",
       "  6732,\n",
       "  2097,\n",
       "  2175,\n",
       "  2046,\n",
       "  15397,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4790,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  8491,\n",
       "  2111,\n",
       "  2002,\n",
       "  6732,\n",
       "  2008,\n",
       "  2097,\n",
       "  2175,\n",
       "  2046,\n",
       "  15397,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4790,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  8491,\n",
       "  2111,\n",
       "  2002,\n",
       "  6732,\n",
       "  2008,\n",
       "  2104,\n",
       "  1996,\n",
       "  2783,\n",
       "  6214,\n",
       "  2097,\n",
       "  2175,\n",
       "  2046,\n",
       "  15397,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4790,\n",
       "  2002,\n",
       "  9631,\n",
       "  1010,\n",
       "  1996,\n",
       "  8491,\n",
       "  2111,\n",
       "  2002,\n",
       "  6732,\n",
       "  2104,\n",
       "  1996,\n",
       "  2783,\n",
       "  6214,\n",
       "  2097,\n",
       "  2175,\n",
       "  2046,\n",
       "  15397,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2008,\n",
       "  7180,\n",
       "  1010,\n",
       "  1996,\n",
       "  10989,\n",
       "  2008,\n",
       "  2009,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 2062, 2111, 2008, 7180, 1010, 1996, 10989, 2009, 4152, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2017,\n",
       "  2507,\n",
       "  5404,\n",
       "  2000,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2008,\n",
       "  2131,\n",
       "  5305,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2008,\n",
       "  2017,\n",
       "  2507,\n",
       "  5404,\n",
       "  2000,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2008,\n",
       "  2131,\n",
       "  5305,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 2062, 2111, 7180, 1010, 1996, 10989, 2008, 2009, 4152, 1012, 102],\n",
       " [101, 1996, 2062, 2111, 7180, 1010, 1996, 10989, 2009, 4152, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2008,\n",
       "  2017,\n",
       "  2507,\n",
       "  5404,\n",
       "  2000,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  2131,\n",
       "  5305,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2198,\n",
       "  2008,\n",
       "  2002,\n",
       "  23311,\n",
       "  1996,\n",
       "  2062,\n",
       "  15818,\n",
       "  2002,\n",
       "  4150,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  2008,\n",
       "  2198,\n",
       "  23311,\n",
       "  1996,\n",
       "  2062,\n",
       "  15818,\n",
       "  2002,\n",
       "  4150,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 2158, 2008, 3369, 2006, 1996, 3345, 2001, 2026, 2567, 1012, 102],\n",
       " [101, 1996, 2158, 3369, 2006, 1996, 3345, 2001, 2026, 2567, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  3071,\n",
       "  2040,\n",
       "  7777,\n",
       "  12778,\n",
       "  3086,\n",
       "  2000,\n",
       "  1010,\n",
       "  1996,\n",
       "  19366,\n",
       "  2057,\n",
       "  2035,\n",
       "  2024,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2101,\n",
       "  2009,\n",
       "  4152,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2111,\n",
       "  3071,\n",
       "  2040,\n",
       "  7777,\n",
       "  12778,\n",
       "  3086,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  7188,\n",
       "  3021,\n",
       "  5610,\n",
       "  2015,\n",
       "  1010,\n",
       "  6294,\n",
       "  16424,\n",
       "  2032,\n",
       "  2035,\n",
       "  1996,\n",
       "  2062,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 7188, 3021, 5610, 2015, 1010, 6294, 16424, 2032, 2172, 2062, 1012, 102],\n",
       " [101, 7188, 3021, 5610, 2015, 1010, 6294, 16424, 2032, 2521, 2062, 1012, 102],\n",
       " [101,\n",
       "  7188,\n",
       "  3021,\n",
       "  5610,\n",
       "  2015,\n",
       "  1010,\n",
       "  6294,\n",
       "  16424,\n",
       "  2032,\n",
       "  1037,\n",
       "  2843,\n",
       "  2062,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2320,\n",
       "  9965,\n",
       "  2187,\n",
       "  1010,\n",
       "  5965,\n",
       "  2150,\n",
       "  2035,\n",
       "  1996,\n",
       "  13675,\n",
       "  16103,\n",
       "  2121,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2320,\n",
       "  9965,\n",
       "  2187,\n",
       "  1010,\n",
       "  5965,\n",
       "  2150,\n",
       "  2172,\n",
       "  13675,\n",
       "  16103,\n",
       "  2121,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2320,\n",
       "  9965,\n",
       "  2187,\n",
       "  1010,\n",
       "  5965,\n",
       "  2150,\n",
       "  2521,\n",
       "  13675,\n",
       "  16103,\n",
       "  2121,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  5965,\n",
       "  2150,\n",
       "  2035,\n",
       "  1996,\n",
       "  13675,\n",
       "  16103,\n",
       "  2121,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2411,\n",
       "  9965,\n",
       "  2187,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  3021,\n",
       "  5610,\n",
       "  2015,\n",
       "  1010,\n",
       "  2035,\n",
       "  1996,\n",
       "  2062,\n",
       "  2515,\n",
       "  6294,\n",
       "  5223,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  3021,\n",
       "  5610,\n",
       "  2015,\n",
       "  1010,\n",
       "  2172,\n",
       "  2062,\n",
       "  2515,\n",
       "  6294,\n",
       "  5223,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2043,\n",
       "  3021,\n",
       "  5610,\n",
       "  2015,\n",
       "  1010,\n",
       "  2035,\n",
       "  1996,\n",
       "  2062,\n",
       "  6294,\n",
       "  16424,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2061, 2172, 2106, 2017, 4521, 2008, 3071, 8535, 1012, 102],\n",
       " [101, 2061, 3435, 2106, 2017, 2448, 2008, 3071, 8535, 1012, 102],\n",
       " [101, 2061, 9414, 1037, 3899, 2106, 2017, 4965, 2008, 3071, 8535, 1012, 102],\n",
       " [101, 1045, 2113, 2129, 2172, 2017, 8823, 1012, 102],\n",
       " [101, 1045, 2113, 2129, 3435, 2017, 2743, 1012, 102],\n",
       " [101, 1045, 2113, 2129, 9414, 1037, 3899, 2017, 4149, 1012, 102],\n",
       " [101, 2002, 8823, 2061, 2172, 2008, 2002, 2288, 5305, 1012, 102],\n",
       " [101, 2061, 2172, 2106, 2002, 4521, 2008, 2002, 2288, 5305, 1012, 102],\n",
       " [101, 1996, 2062, 2017, 4521, 1010, 1996, 2062, 2017, 2215, 1012, 102],\n",
       " [101, 2017, 4521, 1996, 2062, 1010, 1996, 2062, 2017, 2215, 1012, 102],\n",
       " [101, 1996, 2062, 2017, 4521, 1010, 2017, 2215, 1996, 2062, 1012, 102],\n",
       " [101, 1045, 4687, 2017, 8823, 2129, 2172, 1012, 102],\n",
       " [101, 1045, 4687, 2000, 2129, 2116, 2111, 3021, 7566, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2936,\n",
       "  2002,\n",
       "  2038,\n",
       "  2000,\n",
       "  3524,\n",
       "  1010,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2198,\n",
       "  4152,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2065, 2002, 2038, 2000, 3524, 1010, 2198, 4152, 4854, 1012, 102],\n",
       " [101, 2002, 4152, 4854, 1010, 1996, 2936, 2198, 2038, 2000, 3524, 1012, 102],\n",
       " [101, 2002, 4152, 4854, 2065, 2198, 2038, 2000, 3524, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  4620,\n",
       "  1997,\n",
       "  2032,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  10339,\n",
       "  2198,\n",
       "  4150,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  2008,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  10339,\n",
       "  2198,\n",
       "  4150,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  10339,\n",
       "  2198,\n",
       "  4150,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2032,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  3497,\n",
       "  2198,\n",
       "  2003,\n",
       "  2000,\n",
       "  2131,\n",
       "  4727,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  3497,\n",
       "  2198,\n",
       "  2003,\n",
       "  2000,\n",
       "  2131,\n",
       "  4727,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  4620,\n",
       "  1997,\n",
       "  2032,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  3497,\n",
       "  2198,\n",
       "  2003,\n",
       "  2000,\n",
       "  2131,\n",
       "  4727,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  3497,\n",
       "  2198,\n",
       "  2003,\n",
       "  2000,\n",
       "  2131,\n",
       "  4727,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  2198,\n",
       "  4152,\n",
       "  6314,\n",
       "  2011,\n",
       "  2068,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  3441,\n",
       "  2055,\n",
       "  2032,\n",
       "  4025,\n",
       "  2000,\n",
       "  2265,\n",
       "  2039,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  2198,\n",
       "  4152,\n",
       "  6314,\n",
       "  2011,\n",
       "  2068,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  3441,\n",
       "  2055,\n",
       "  2370,\n",
       "  4025,\n",
       "  2000,\n",
       "  2265,\n",
       "  2039,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  2003,\n",
       "  2062,\n",
       "  10339,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2032,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  2003,\n",
       "  2062,\n",
       "  10339,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2032,\n",
       "  2008,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  2003,\n",
       "  2062,\n",
       "  10339,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  2003,\n",
       "  2062,\n",
       "  10339,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  2008,\n",
       "  3711,\n",
       "  1999,\n",
       "  1996,\n",
       "  2739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3441,\n",
       "  2055,\n",
       "  2032,\n",
       "  4025,\n",
       "  2000,\n",
       "  2265,\n",
       "  2039,\n",
       "  2062,\n",
       "  2006,\n",
       "  1996,\n",
       "  3944,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  2198,\n",
       "  4152,\n",
       "  6314,\n",
       "  2011,\n",
       "  2068,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3441,\n",
       "  2055,\n",
       "  2370,\n",
       "  4025,\n",
       "  2000,\n",
       "  2265,\n",
       "  2039,\n",
       "  2062,\n",
       "  2006,\n",
       "  1996,\n",
       "  3944,\n",
       "  2739,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2008,\n",
       "  2198,\n",
       "  4152,\n",
       "  6314,\n",
       "  2011,\n",
       "  2068,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2065,\n",
       "  2017,\n",
       "  2507,\n",
       "  2032,\n",
       "  2438,\n",
       "  4495,\n",
       "  1010,\n",
       "  2296,\n",
       "  5205,\n",
       "  2097,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2507,\n",
       "  2032,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  2296,\n",
       "  5205,\n",
       "  2097,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  2435,\n",
       "  2032,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  1010,\n",
       "  2469,\n",
       "  2438,\n",
       "  1010,\n",
       "  2296,\n",
       "  5205,\n",
       "  25642,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2065,\n",
       "  2017,\n",
       "  2507,\n",
       "  2151,\n",
       "  5205,\n",
       "  2438,\n",
       "  4495,\n",
       "  1010,\n",
       "  2002,\n",
       "  2097,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2507,\n",
       "  2151,\n",
       "  5205,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  2002,\n",
       "  2097,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2507,\n",
       "  2296,\n",
       "  5205,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  2002,\n",
       "  2097,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  2435,\n",
       "  2151,\n",
       "  5205,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  1010,\n",
       "  2469,\n",
       "  2438,\n",
       "  1010,\n",
       "  2002,\n",
       "  25642,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  2435,\n",
       "  2296,\n",
       "  5205,\n",
       "  2438,\n",
       "  4495,\n",
       "  1998,\n",
       "  1010,\n",
       "  2469,\n",
       "  2438,\n",
       "  1010,\n",
       "  2002,\n",
       "  25642,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  13593,\n",
       "  2296,\n",
       "  5205,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  4511,\n",
       "  1998,\n",
       "  11586,\n",
       "  2063,\n",
       "  2032,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  2296,\n",
       "  5205,\n",
       "  2003,\n",
       "  18002,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  2062,\n",
       "  2051,\n",
       "  2008,\n",
       "  2296,\n",
       "  5205,\n",
       "  15970,\n",
       "  2007,\n",
       "  9568,\n",
       "  5130,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  3497,\n",
       "  2002,\n",
       "  10514,\n",
       "  9468,\n",
       "  25438,\n",
       "  2015,\n",
       "  2000,\n",
       "  7897,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2296,\n",
       "  5205,\n",
       "  4150,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2151,\n",
       "  5205,\n",
       "  4150,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  2151,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  2296,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2296,\n",
       "  5205,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2065,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2151,\n",
       "  5205,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2065,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2151,\n",
       "  5205,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2004,\n",
       "  2002,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2065,\n",
       "  2151,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2065,\n",
       "  2296,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2004,\n",
       "  2296,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2002,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  13593,\n",
       "  1010,\n",
       "  2004,\n",
       "  2151,\n",
       "  5205,\n",
       "  7566,\n",
       "  2000,\n",
       "  2062,\n",
       "  9568,\n",
       "  5130,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1996,\n",
       "  4066,\n",
       "  1997,\n",
       "  3291,\n",
       "  2029,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2024,\n",
       "  1996,\n",
       "  4066,\n",
       "  1997,\n",
       "  2111,\n",
       "  2040,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2040, 2106, 2017, 2507, 4620, 1997, 2000, 2814, 1997, 1029, 102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  2023,\n",
       "  3291,\n",
       "  2008,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  2003,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2040,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2029,\n",
       "  3291,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  1010,\n",
       "  2097,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2029,\n",
       "  3291,\n",
       "  2515,\n",
       "  1996,\n",
       "  10076,\n",
       "  2008,\n",
       "  2017,\n",
       "  9611,\n",
       "  1010,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2029,\n",
       "  3291,\n",
       "  1996,\n",
       "  10076,\n",
       "  2008,\n",
       "  2017,\n",
       "  9611,\n",
       "  1010,\n",
       "  2097,\n",
       "  1996,\n",
       "  2062,\n",
       "  4089,\n",
       "  2017,\n",
       "  13225,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1029,\n",
       "  102],\n",
       " [101, 1996, 6211, 2009, 15811, 1010, 1996, 5514, 2040, 3216, 1029, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  10989,\n",
       "  2040,\n",
       "  7566,\n",
       "  1010,\n",
       "  1996,\n",
       "  17076,\n",
       "  16252,\n",
       "  2017,\n",
       "  2131,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  6211,\n",
       "  2008,\n",
       "  2009,\n",
       "  15811,\n",
       "  1010,\n",
       "  2129,\n",
       "  2172,\n",
       "  5514,\n",
       "  1037,\n",
       "  4834,\n",
       "  2079,\n",
       "  2017,\n",
       "  2156,\n",
       "  1999,\n",
       "  1996,\n",
       "  2314,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  3478,\n",
       "  2000,\n",
       "  2425,\n",
       "  2033,\n",
       "  2029,\n",
       "  3291,\n",
       "  1996,\n",
       "  10076,\n",
       "  1045,\n",
       "  9611,\n",
       "  1010,\n",
       "  1996,\n",
       "  19059,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2633,\n",
       "  2499,\n",
       "  2039,\n",
       "  2438,\n",
       "  8424,\n",
       "  2000,\n",
       "  3198,\n",
       "  2029,\n",
       "  2111,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  1996,\n",
       "  10076,\n",
       "  1045,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  19059,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  2131,\n",
       "  2489,\n",
       "  1997,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2029,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2079,\n",
       "  2017,\n",
       "  2228,\n",
       "  2008,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1010,\n",
       "  1996,\n",
       "  19059,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2425,\n",
       "  1056,\n",
       "  2000,\n",
       "  12610,\n",
       "  2125,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1037,\n",
       "  3291,\n",
       "  2008,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2425,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2000,\n",
       "  12610,\n",
       "  2125,\n",
       "  2065,\n",
       "  2017,\n",
       "  9611,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1037,\n",
       "  3291,\n",
       "  2008,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2425,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2000,\n",
       "  12610,\n",
       "  2125,\n",
       "  2065,\n",
       "  2017,\n",
       "  9611,\n",
       "  2009,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1037,\n",
       "  3291,\n",
       "  2008,\n",
       "  2017,\n",
       "  9611,\n",
       "  2009,\n",
       "  1998,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2425,\n",
       "  1996,\n",
       "  12455,\n",
       "  2039,\n",
       "  2012,\n",
       "  5971,\n",
       "  4075,\n",
       "  2000,\n",
       "  12610,\n",
       "  2125,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2216,\n",
       "  2024,\n",
       "  1996,\n",
       "  12455,\n",
       "  2008,\n",
       "  2017,\n",
       "  2074,\n",
       "  9611,\n",
       "  2023,\n",
       "  3291,\n",
       "  1998,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2404,\n",
       "  2068,\n",
       "  2006,\n",
       "  3256,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  3478,\n",
       "  2000,\n",
       "  2425,\n",
       "  2033,\n",
       "  2029,\n",
       "  3291,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  3786,\n",
       "  1996,\n",
       "  2971,\n",
       "  2062,\n",
       "  4089,\n",
       "  1010,\n",
       "  1996,\n",
       "  10076,\n",
       "  1045,\n",
       "  9611,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1996,\n",
       "  3291,\n",
       "  2008,\n",
       "  2017,\n",
       "  1005,\n",
       "  2222,\n",
       "  3786,\n",
       "  1996,\n",
       "  2971,\n",
       "  2062,\n",
       "  4089,\n",
       "  1010,\n",
       "  1996,\n",
       "  10076,\n",
       "  2017,\n",
       "  9611,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2387, 1996, 2158, 1999, 1996, 2282, 1012, 102],\n",
       " [101, 2029, 2282, 2106, 2198, 2156, 1996, 2158, 1999, 1029, 102],\n",
       " [101,\n",
       "  2040,\n",
       "  2106,\n",
       "  2198,\n",
       "  2228,\n",
       "  2008,\n",
       "  3021,\n",
       "  3555,\n",
       "  2008,\n",
       "  2984,\n",
       "  6878,\n",
       "  2008,\n",
       "  7955,\n",
       "  4669,\n",
       "  1029,\n",
       "  102],\n",
       " [101, 2198, 2071, 2025, 3942, 8836, 1012, 102],\n",
       " [101, 2054, 2198, 2071, 2079, 2003, 2025, 3942, 8836, 1012, 102],\n",
       " [101, 2198, 2481, 1005, 1056, 3942, 8836, 1012, 102],\n",
       " [101, 2339, 2106, 2198, 2681, 1029, 102],\n",
       " [101, 1045, 2718, 1996, 3608, 1012, 102],\n",
       " [101, 2017, 2718, 1996, 3608, 1012, 102],\n",
       " [101, 2002, 2718, 1996, 3608, 1012, 102],\n",
       " [101, 2016, 2718, 1996, 3608, 1012, 102],\n",
       " [101, 2027, 2718, 1996, 3608, 1012, 102],\n",
       " [101, 2572, 2025, 1045, 2183, 1029, 102],\n",
       " [101, 1045, 2572, 2025, 2183, 1012, 102],\n",
       " [101, 4995, 1005, 1056, 1045, 2183, 1029, 102],\n",
       " [101, 1045, 4995, 1005, 1056, 2183, 1012, 102],\n",
       " [101, 8227, 2003, 12511, 1010, 3475, 1005, 1056, 2016, 1029, 102],\n",
       " [101, 8227, 7777, 2025, 2108, 3407, 1010, 2987, 1005, 1056, 2016, 1029, 102],\n",
       " [101, 2025, 2116, 2808, 5175, 1996, 2543, 1010, 2106, 2027, 1029, 102],\n",
       " [101, 2053, 2808, 5175, 1996, 2543, 1010, 2106, 2027, 1029, 102],\n",
       " [101, 2002, 8440, 1005, 1056, 2411, 3825, 7773, 1010, 2038, 2002, 1029, 102],\n",
       " [101, 2002, 2064, 1005, 1056, 3477, 7773, 1010, 2064, 2002, 1029, 102],\n",
       " [101, 2016, 2515, 2025, 2156, 2032, 1012, 102],\n",
       " [101, 2016, 2921, 2025, 3773, 2032, 1012, 102],\n",
       " [101, 2016, 2071, 2025, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 19887, 2025, 2187, 1012, 102],\n",
       " [101, 19887, 2187, 2025, 1012, 102],\n",
       " [101, 2002, 2071, 2025, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 2002, 3685, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 2002, 2064, 3432, 2025, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 2017, 2442, 2025, 3432, 2025, 2147, 1012, 102],\n",
       " [101, 2002, 2089, 2025, 2074, 2025, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 2002, 2064, 1005, 1056, 2031, 2042, 2551, 1012, 102],\n",
       " [101, 2064, 1005, 1056, 2002, 2031, 2042, 2551, 1029, 102],\n",
       " [101, 2064, 2002, 2025, 2031, 2042, 2551, 1029, 102],\n",
       " [101, 2064, 2002, 2025, 2031, 2042, 2551, 1029, 102],\n",
       " [101, 2198, 2626, 2808, 1012, 102],\n",
       " [101, 2198, 4339, 2808, 1012, 102],\n",
       " [101, 2198, 2626, 2808, 1012, 102],\n",
       " [101, 2198, 2106, 2025, 4339, 2808, 1012, 102],\n",
       " [101, 2198, 3849, 2008, 2003, 3835, 1012, 102],\n",
       " [101,\n",
       "  1036,\n",
       "  1036,\n",
       "  1045,\n",
       "  2572,\n",
       "  2061,\n",
       "  3407,\n",
       "  1005,\n",
       "  1005,\n",
       "  1010,\n",
       "  2245,\n",
       "  2198,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2091, 1996, 2940, 4565, 2198, 1012, 102],\n",
       " [101, 2198, 8537, 2411, 2984, 1012, 102],\n",
       " [101, 2198, 2411, 8537, 2984, 1012, 102],\n",
       " [101, 2040, 2079, 2017, 2228, 2984, 2056, 2198, 7777, 1029, 102],\n",
       " [101, 2040, 2106, 2017, 3198, 3251, 2984, 4282, 2339, 2198, 7777, 1029, 102],\n",
       " [101, 2040, 2079, 2017, 2228, 2008, 2984, 2056, 2008, 2198, 7777, 1029, 102],\n",
       " [101, 2129, 2079, 2017, 4687, 3251, 2984, 13332, 1996, 3291, 1029, 102],\n",
       " [101, 2129, 2079, 2017, 2228, 2008, 2984, 13332, 1996, 3291, 1029, 102],\n",
       " [101,\n",
       "  2129,\n",
       "  2079,\n",
       "  2017,\n",
       "  4687,\n",
       "  3251,\n",
       "  2198,\n",
       "  2056,\n",
       "  2008,\n",
       "  2984,\n",
       "  13332,\n",
       "  1996,\n",
       "  3291,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2129,\n",
       "  2079,\n",
       "  2017,\n",
       "  4687,\n",
       "  3251,\n",
       "  2198,\n",
       "  2056,\n",
       "  2984,\n",
       "  13332,\n",
       "  1996,\n",
       "  3291,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2029,\n",
       "  3291,\n",
       "  2079,\n",
       "  2017,\n",
       "  4687,\n",
       "  3251,\n",
       "  2198,\n",
       "  2056,\n",
       "  2008,\n",
       "  2984,\n",
       "  13332,\n",
       "  1029,\n",
       "  102],\n",
       " [101, 2129, 2106, 2017, 2228, 2008, 2984, 13332, 1996, 3291, 1029, 102],\n",
       " [101, 2984, 5086, 2619, 1012, 102],\n",
       " [101, 1045, 2657, 2008, 2984, 5086, 2619, 1012, 102],\n",
       " [101, 1045, 5295, 2138, 2984, 5086, 2619, 1012, 102],\n",
       " [101, 2984, 4999, 2029, 3861, 1997, 2370, 3021, 2387, 1029, 102],\n",
       " [101,\n",
       "  2029,\n",
       "  3861,\n",
       "  1997,\n",
       "  2370,\n",
       "  2515,\n",
       "  2984,\n",
       "  2228,\n",
       "  2008,\n",
       "  2198,\n",
       "  2056,\n",
       "  2008,\n",
       "  6294,\n",
       "  7777,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  6732,\n",
       "  2008,\n",
       "  2198,\n",
       "  2056,\n",
       "  2008,\n",
       "  6294,\n",
       "  7777,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  6732,\n",
       "  2008,\n",
       "  2198,\n",
       "  2056,\n",
       "  2008,\n",
       "  4620,\n",
       "  1997,\n",
       "  2370,\n",
       "  1010,\n",
       "  6294,\n",
       "  7777,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2065,\n",
       "  2017,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2903,\n",
       "  2033,\n",
       "  1010,\n",
       "  2017,\n",
       "  2097,\n",
       "  1996,\n",
       "  4633,\n",
       "  2386,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  4565,\n",
       "  2039,\n",
       "  1037,\n",
       "  3780,\n",
       "  1010,\n",
       "  1998,\n",
       "  9399,\n",
       "  2106,\n",
       "  1037,\n",
       "  2932,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  14986,\n",
       "  7777,\n",
       "  12799,\n",
       "  1010,\n",
       "  2021,\n",
       "  2016,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  23879,\n",
       "  6779,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  4830,\n",
       "  4928,\n",
       "  3557,\n",
       "  5905,\n",
       "  1998,\n",
       "  1996,\n",
       "  3353,\n",
       "  4830,\n",
       "  2097,\n",
       "  6011,\n",
       "  3044,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2984, 2097, 2903, 6294, 1010, 1998, 2017, 2097, 3960, 1012, 102],\n",
       " [101, 2017, 2453, 2025, 2903, 2033, 2021, 2017, 2097, 3960, 1012, 102],\n",
       " [101, 2017, 2097, 3960, 2903, 1012, 102],\n",
       " [101, 2129, 2106, 2017, 9611, 1996, 3291, 1029, 102],\n",
       " [101, 1045, 4687, 2040, 2071, 9611, 1996, 3291, 1999, 2023, 2126, 1012, 102],\n",
       " [101, 2129, 2079, 2017, 4687, 2040, 2071, 9611, 2023, 3291, 1012, 102],\n",
       " [101,\n",
       "  2053,\n",
       "  4018,\n",
       "  2064,\n",
       "  16014,\n",
       "  2129,\n",
       "  2116,\n",
       "  2111,\n",
       "  2097,\n",
       "  3789,\n",
       "  2005,\n",
       "  2032,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2296, 3761, 2003, 5191, 2043, 1996, 2811, 4627, 7866, 2032, 1012, 102],\n",
       " [101, 2029, 3761, 2805, 1996, 4988, 2040, 3569, 2032, 1029, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2755,\n",
       "  2008,\n",
       "  2053,\n",
       "  4018,\n",
       "  2001,\n",
       "  2700,\n",
       "  3065,\n",
       "  2008,\n",
       "  2002,\n",
       "  2001,\n",
       "  14710,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  15187,\n",
       "  2808,\n",
       "  1010,\n",
       "  2984,\n",
       "  23311,\n",
       "  2636,\n",
       "  1998,\n",
       "  3021,\n",
       "  1058,\n",
       "  6399,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  3160,\n",
       "  1997,\n",
       "  3251,\n",
       "  2198,\n",
       "  2777,\n",
       "  2984,\n",
       "  15508,\n",
       "  1996,\n",
       "  2111,\n",
       "  2040,\n",
       "  2490,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 2031, 2187, 1012, 102],\n",
       " [101, 2031, 2027, 2187, 1029, 102],\n",
       " [101, 2071, 2027, 2031, 2187, 1029, 102],\n",
       " [101, 2002, 2038, 2411, 2464, 2984, 1012, 102],\n",
       " [101, 2002, 1045, 2411, 5927, 2984, 1012, 102],\n",
       " [101, 2002, 5927, 2411, 2984, 1012, 102],\n",
       " [101, 5927, 2002, 1045, 2411, 2984, 1029, 102],\n",
       " [101, 2009, 3849, 2008, 2009, 2003, 3497, 2008, 2198, 2097, 2663, 1012, 102],\n",
       " [101, 2009, 3849, 2008, 2198, 2003, 3497, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 3849, 2000, 2022, 3497, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 3849, 2008, 2009, 2003, 3497, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 3849, 2097, 2663, 1012, 102],\n",
       " [101, 2129, 2079, 2017, 4687, 2029, 3291, 2000, 9611, 1029, 102],\n",
       " [101, 2129, 9414, 2079, 2017, 5136, 2198, 1029, 102],\n",
       " [101, 2129, 2116, 2111, 2079, 2017, 4687, 3251, 1045, 5136, 9414, 1029, 102],\n",
       " [101, 2129, 9414, 2079, 2017, 4687, 3251, 1045, 5136, 2198, 1029, 102],\n",
       " [101, 2054, 1996, 3109, 2079, 2017, 4687, 2129, 2000, 2360, 1029, 102],\n",
       " [101, 2002, 2038, 2187, 1012, 102],\n",
       " [101, 2010, 2338, 2003, 3835, 1012, 102],\n",
       " [101, 3021, 2387, 2032, 1012, 102],\n",
       " [101, 3021, 2573, 2007, 2032, 1012, 102],\n",
       " [101, 2198, 7164, 2032, 2000, 2022, 1037, 3835, 3124, 1012, 102],\n",
       " [101, 2198, 10592, 2032, 1037, 3835, 3124, 1012, 102],\n",
       " [101, 2005, 2032, 2000, 2079, 2008, 2052, 2022, 1037, 6707, 1012, 102],\n",
       " [101, 2007, 2032, 5305, 1010, 1996, 2136, 2003, 1999, 4390, 1012, 102],\n",
       " [101, 1037, 2158, 2000, 2022, 1999, 1996, 3871, 2003, 9832, 1012, 102],\n",
       " [101, 1037, 2158, 2000, 2272, 2003, 9832, 1012, 102],\n",
       " [101, 2198, 2000, 2655, 2052, 2022, 9832, 1012, 102],\n",
       " [101, 2023, 7091, 2000, 2022, 3369, 2012, 2003, 11341, 1012, 102],\n",
       " [101, 2198, 7164, 2008, 2002, 2003, 5305, 1012, 102],\n",
       " [101, 2198, 7164, 2008, 2032, 2003, 5305, 1012, 102],\n",
       " [101, 2198, 5363, 2032, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 16278, 2073, 2032, 2000, 2175, 1012, 102],\n",
       " [101, 2040, 2079, 2017, 2228, 2008, 3021, 7777, 1029, 102],\n",
       " [101, 2040, 2079, 2017, 2228, 2008, 3021, 7164, 2000, 2022, 7036, 1029, 102],\n",
       " [101, 2040, 2079, 2017, 2228, 2008, 7164, 2198, 2000, 2022, 7036, 1029, 102],\n",
       " [101, 2040, 2052, 2017, 9544, 2005, 2000, 2663, 1996, 2679, 1029, 102],\n",
       " [101, 2619, 10312, 2026, 2482, 1012, 102],\n",
       " [101, 2026, 2482, 2001, 7376, 1012, 102],\n",
       " [101, 1996, 2336, 4521, 2035, 7967, 1012, 102],\n",
       " [101, 2198, 2038, 2411, 4782, 2984, 1012, 102],\n",
       " [101, 1996, 4268, 2031, 2035, 8828, 1996, 7967, 1012, 102],\n",
       " [101, 1999, 2236, 1010, 2002, 19821, 2054, 1005, 1055, 2183, 2006, 1012, 102],\n",
       " [101,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  15596,\n",
       "  2008,\n",
       "  1999,\n",
       "  2236,\n",
       "  2002,\n",
       "  19821,\n",
       "  2054,\n",
       "  1005,\n",
       "  1055,\n",
       "  2183,\n",
       "  2006,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  15596,\n",
       "  1999,\n",
       "  2236,\n",
       "  2008,\n",
       "  2002,\n",
       "  19821,\n",
       "  2054,\n",
       "  1005,\n",
       "  1055,\n",
       "  2183,\n",
       "  2006,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1999,\n",
       "  2236,\n",
       "  2008,\n",
       "  2002,\n",
       "  19821,\n",
       "  2054,\n",
       "  1005,\n",
       "  1055,\n",
       "  2183,\n",
       "  2006,\n",
       "  2003,\n",
       "  11341,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 4541, 2129, 2000, 8081, 1996, 7752, 1012, 102],\n",
       " [101, 1045, 4541, 2129, 2057, 2323, 8081, 1996, 7752, 1012, 102],\n",
       " [101, 1045, 4541, 2008, 2057, 2323, 8081, 1996, 7752, 1012, 102],\n",
       " [101, 1045, 4541, 2000, 8081, 1996, 7752, 1012, 102],\n",
       " [101, 11021, 2246, 2039, 1996, 4431, 1012, 102],\n",
       " [101, 11021, 2246, 1996, 4431, 2039, 1012, 102],\n",
       " [101, 11021, 2246, 2039, 2068, 1012, 102],\n",
       " [101, 11021, 12597, 2039, 2007, 1996, 2308, 1012, 102],\n",
       " [101, 11021, 12597, 2007, 1996, 2308, 2039, 1012, 102],\n",
       " [101, 11021, 4197, 2041, 2008, 5639, 2018, 2187, 1012, 102],\n",
       " [101, 11021, 4197, 2008, 5639, 2018, 2187, 2041, 1012, 102],\n",
       " [101, 11021, 17433, 2039, 2035, 1996, 2051, 1012, 102],\n",
       " [101, 11021, 17433, 2035, 1996, 2051, 2039, 1012, 102],\n",
       " [101, 2054, 2515, 2198, 2228, 2984, 4149, 1029, 102],\n",
       " [101, 2198, 6732, 2054, 2984, 4149, 1012, 102],\n",
       " [101, 2198, 16278, 2054, 2984, 4149, 1012, 102],\n",
       " [101, 2054, 2515, 2198, 4687, 2984, 4149, 1029, 102],\n",
       " [101, 2040, 2003, 2002, 3752, 1037, 2338, 2008, 6232, 10057, 1029, 102],\n",
       " [101, 2054, 2079, 2017, 3342, 2073, 2057, 4149, 1029, 102],\n",
       " [101, 2040, 4149, 2054, 1029, 102],\n",
       " [101, 2040, 2003, 3752, 1037, 2338, 2008, 6232, 10057, 2040, 1029, 102],\n",
       " [101, 2040, 17749, 2073, 2057, 4149, 2054, 1029, 102],\n",
       " [101, 1045, 4687, 2040, 2054, 4149, 1029, 102],\n",
       " [101, 1045, 4687, 2054, 2040, 4149, 1029, 102],\n",
       " [101, 2045, 4995, 1005, 1056, 2116, 15397, 2493, 2182, 1012, 102],\n",
       " [101, 1045, 4033, 1005, 1056, 2777, 2116, 15397, 2493, 1012, 102],\n",
       " [101, 2054, 2515, 2296, 3076, 4965, 1029, 102],\n",
       " [101, 1045, 2342, 8836, 2000, 2022, 2045, 1012, 102],\n",
       " [101, 1996, 4049, 7569, 2000, 8145, 1996, 5427, 1012, 102],\n",
       " [101, 1996, 4049, 2001, 10417, 2000, 8145, 1996, 5427, 1012, 102],\n",
       " [101, 2198, 4122, 2000, 2663, 1012, 102],\n",
       " [101, 1996, 2793, 2001, 4895, 21565, 1012, 102],\n",
       " [101, 2132, 4576, 2001, 4895, 21565, 1012, 102],\n",
       " [101, 2198, 2001, 4242, 1012, 102],\n",
       " [101, 2198, 2001, 4242, 2000, 2022, 1996, 13422, 1012, 102],\n",
       " [101, 2057, 2354, 2198, 2000, 2022, 1996, 13422, 1012, 102],\n",
       " [101, 2002, 7349, 1996, 2336, 1012, 102],\n",
       " [101, 1996, 2336, 2020, 16655, 8566, 12921, 1012, 102],\n",
       " [101, 1996, 2336, 2020, 6151, 2483, 6895, 28296, 2098, 1012, 102],\n",
       " [101, 1045, 3373, 2122, 2493, 2035, 2000, 2066, 2198, 1012, 102],\n",
       " [101, 2027, 2699, 2000, 2035, 2066, 2198, 1012, 102],\n",
       " [101, 1045, 3373, 2122, 2493, 2000, 2035, 2066, 2198, 1012, 102],\n",
       " [101, 2106, 2002, 3046, 2412, 2000, 2831, 2000, 1996, 3076, 1029, 102],\n",
       " [101,\n",
       "  2106,\n",
       "  2017,\n",
       "  2903,\n",
       "  2032,\n",
       "  2412,\n",
       "  2000,\n",
       "  2031,\n",
       "  2081,\n",
       "  2019,\n",
       "  3947,\n",
       "  2000,\n",
       "  2831,\n",
       "  2000,\n",
       "  1996,\n",
       "  3076,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2106,\n",
       "  2002,\n",
       "  3046,\n",
       "  2000,\n",
       "  2412,\n",
       "  2022,\n",
       "  2012,\n",
       "  6528,\n",
       "  6024,\n",
       "  2000,\n",
       "  1996,\n",
       "  3791,\n",
       "  1997,\n",
       "  2493,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2106,\n",
       "  2017,\n",
       "  2903,\n",
       "  2032,\n",
       "  2000,\n",
       "  2412,\n",
       "  2031,\n",
       "  2081,\n",
       "  2019,\n",
       "  3947,\n",
       "  2000,\n",
       "  2831,\n",
       "  2000,\n",
       "  1996,\n",
       "  3076,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  2147,\n",
       "  2041,\n",
       "  2019,\n",
       "  4106,\n",
       "  2008,\n",
       "  2003,\n",
       "  5171,\n",
       "  1997,\n",
       "  2023,\n",
       "  3193,\n",
       "  1997,\n",
       "  5319,\n",
       "  5739,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  2020,\n",
       "  3373,\n",
       "  2035,\n",
       "  2000,\n",
       "  2022,\n",
       "  3243,\n",
       "  29454,\n",
       "  29206,\n",
       "  2102,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2001, 2002, 3373, 2412, 2000, 8246, 2493, 1029, 102],\n",
       " [101,\n",
       "  2045,\n",
       "  2003,\n",
       "  25069,\n",
       "  2000,\n",
       "  2022,\n",
       "  2062,\n",
       "  1998,\n",
       "  2062,\n",
       "  6594,\n",
       "  1997,\n",
       "  2122,\n",
       "  3314,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2790, 2000, 2022, 1037, 2307, 22978, 1012, 102],\n",
       " [101, 2045, 10659, 2000, 2022, 1037, 4040, 3892, 1012, 102],\n",
       " [101, 2198, 29453, 2094, 2000, 2022, 3144, 1012, 102],\n",
       " [101, 2198, 2359, 2000, 5335, 2010, 2843, 1999, 2166, 1012, 102],\n",
       " [101, 2198, 3517, 2000, 2663, 1012, 102],\n",
       " [101,\n",
       "  2023,\n",
       "  2338,\n",
       "  2003,\n",
       "  2205,\n",
       "  9742,\n",
       "  2000,\n",
       "  2022,\n",
       "  3191,\n",
       "  1999,\n",
       "  2028,\n",
       "  3564,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2045,\n",
       "  2003,\n",
       "  2205,\n",
       "  3497,\n",
       "  2000,\n",
       "  2022,\n",
       "  1037,\n",
       "  11421,\n",
       "  2000,\n",
       "  2022,\n",
       "  1037,\n",
       "  3809,\n",
       "  6594,\n",
       "  1997,\n",
       "  1996,\n",
       "  3314,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2699, 1012, 102],\n",
       " [101, 2198, 4622, 1012, 102],\n",
       " [101, 2198, 2003, 4188, 1012, 102],\n",
       " [101, 2198, 9471, 1012, 102],\n",
       " [101,\n",
       "  3021,\n",
       "  3849,\n",
       "  2000,\n",
       "  2022,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2228,\n",
       "  2008,\n",
       "  3520,\n",
       "  6433,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3021,\n",
       "  3849,\n",
       "  2000,\n",
       "  2022,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2228,\n",
       "  2008,\n",
       "  3520,\n",
       "  4332,\n",
       "  2041,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3021,\n",
       "  3849,\n",
       "  2000,\n",
       "  2022,\n",
       "  27885,\n",
       "  3630,\n",
       "  25171,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2228,\n",
       "  2008,\n",
       "  3520,\n",
       "  12102,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 2699, 2035, 2000, 2066, 2198, 1012, 102],\n",
       " [101, 2027, 2790, 2035, 2000, 2066, 2198, 1012, 102],\n",
       " [101, 2198, 7164, 8836, 2000, 2022, 13205, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  2903,\n",
       "  2198,\n",
       "  2007,\n",
       "  2035,\n",
       "  2026,\n",
       "  2540,\n",
       "  2000,\n",
       "  2022,\n",
       "  1037,\n",
       "  2986,\n",
       "  2711,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2003, 2359, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 2052, 2022, 4669, 2000, 2663, 1012, 102],\n",
       " [101, 2057, 2052, 2066, 2198, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 2052, 2022, 6283, 2000, 2663, 1012, 102],\n",
       " [101, 2198, 2052, 2022, 6871, 2000, 2022, 1996, 4018, 1012, 102],\n",
       " [101, 2057, 2052, 9544, 2198, 2000, 2022, 1996, 4018, 1012, 102],\n",
       " [101, 1045, 2052, 2066, 2005, 2198, 2000, 2663, 1012, 102],\n",
       " [101, 1045, 2052, 5223, 2005, 2198, 2000, 2663, 1012, 102],\n",
       " [101, 1045, 2052, 9544, 2005, 2198, 2000, 2022, 1996, 4018, 1012, 102],\n",
       " [101, 2198, 3908, 1996, 2160, 1012, 102],\n",
       " [101, 1996, 28688, 22627, 15956, 2046, 1996, 5396, 1012, 102],\n",
       " [101, 15956, 4930, 1996, 28688, 1012, 102],\n",
       " [101, 1996, 5396, 3397, 15956, 1012, 102],\n",
       " [101, 1996, 2160, 3908, 2198, 1012, 102],\n",
       " [101, 15956, 2187, 1996, 28688, 1012, 102],\n",
       " [101, 1996, 28688, 2001, 2187, 2011, 15956, 1012, 102],\n",
       " [101, 1996, 28688, 2001, 4930, 2011, 15956, 1012, 102],\n",
       " [101, 1996, 3608, 3658, 1999, 1996, 3482, 1012, 102],\n",
       " [101, 1996, 3608, 4565, 2013, 1996, 5747, 2000, 1996, 3392, 1012, 102],\n",
       " [101, 1996, 3482, 3397, 1996, 3608, 1012, 102],\n",
       " [101, 1996, 3392, 3333, 5909, 2000, 1996, 2598, 1012, 102],\n",
       " [101, 5909, 2718, 1996, 2598, 2013, 1996, 3392, 1012, 102],\n",
       " [101, 1996, 2962, 6573, 2114, 1996, 6536, 2046, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 2962, 6573, 1996, 6536, 2046, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 3482, 4838, 1996, 3608, 1012, 102],\n",
       " [101, 1996, 3482, 6360, 4838, 1996, 3608, 1012, 102],\n",
       " [101, 1996, 3482, 2012, 2320, 4838, 1996, 3608, 1012, 102],\n",
       " [101, 1996, 3482, 4838, 1996, 3608, 2000, 1996, 2598, 1012, 102],\n",
       " [101, 1996, 3392, 6360, 3333, 2049, 5909, 2000, 1996, 2598, 1012, 102],\n",
       " [101, 1996, 3392, 3333, 2049, 5909, 2000, 1996, 2598, 1012, 102],\n",
       " [101, 5909, 2718, 1996, 4412, 1012, 102],\n",
       " [101, 5909, 2718, 1996, 4412, 2013, 1996, 3392, 1012, 102],\n",
       " [101, 5909, 2012, 2320, 2718, 1996, 4412, 2013, 1996, 3392, 1012, 102],\n",
       " [101, 5909, 2718, 1996, 4412, 2114, 1996, 2598, 1012, 102],\n",
       " [101, 5909, 2012, 2320, 2718, 1996, 4412, 2114, 1996, 2598, 1012, 102],\n",
       " [101, 5909, 3333, 2013, 1996, 3392, 1012, 102],\n",
       " [101, 5909, 3333, 2013, 1996, 3392, 2013, 1996, 8044, 1012, 102],\n",
       " [101, 5909, 3062, 2114, 1996, 2160, 1012, 102],\n",
       " [101, 5909, 3062, 2114, 1996, 2160, 2114, 1996, 2598, 1012, 102],\n",
       " [101, 1996, 3392, 2904, 2046, 2019, 6116, 1012, 102],\n",
       " [101, 1996, 3392, 2904, 2013, 1037, 11035, 2046, 2019, 6116, 1012, 102],\n",
       " [101, 1996, 11035, 2904, 2046, 2019, 6116, 2013, 1037, 11354, 1012, 102],\n",
       " [101, 1996, 11035, 2904, 2046, 2019, 6116, 2013, 1037, 11354, 1012, 102],\n",
       " [101, 1996, 11035, 2904, 2046, 2019, 6116, 1012, 102],\n",
       " [101, 1996, 6116, 2764, 2041, 1997, 1037, 11035, 1012, 102],\n",
       " [101, 1996, 3345, 2584, 1996, 2276, 1012, 102],\n",
       " [101, 1996, 5628, 6573, 2114, 1996, 2813, 1012, 102],\n",
       " [101, 1996, 2775, 2150, 1037, 2158, 1012, 102],\n",
       " [101, 1996, 2283, 6354, 6229, 7090, 1012, 102],\n",
       " [101, 1996, 3899, 2253, 4689, 1012, 102],\n",
       " [101, 2009, 4930, 2198, 2008, 2009, 2001, 2061, 1012, 102],\n",
       " [101, 2009, 2234, 2000, 2198, 2008, 2009, 2001, 2061, 1012, 102],\n",
       " [101, 1996, 7488, 2387, 2046, 1996, 9089, 1012, 102],\n",
       " [101, 2524, 2147, 4504, 1999, 2152, 7022, 1012, 102],\n",
       " [101, 1996, 3888, 2979, 2000, 2198, 1012, 102],\n",
       " [101, 2198, 2003, 7244, 1996, 2813, 1012, 102],\n",
       " [101, 1996, 2813, 2003, 2108, 5028, 2011, 2198, 1012, 102],\n",
       " [101, 1037, 4562, 14133, 1996, 5430, 1012, 102],\n",
       " [101, 1037, 4562, 21490, 2015, 1996, 5430, 1012, 102],\n",
       " [101, 2300, 17469, 1996, 14366, 1012, 102],\n",
       " [101, 1996, 3751, 2364, 9794, 1996, 2160, 4984, 1999, 1996, 8102, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2160,\n",
       "  4984,\n",
       "  2003,\n",
       "  2587,\n",
       "  2011,\n",
       "  1996,\n",
       "  3751,\n",
       "  2364,\n",
       "  1999,\n",
       "  1996,\n",
       "  8102,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 8638, 2358, 12173, 27822, 1996, 11996, 1012, 102],\n",
       " [101, 1996, 11996, 2003, 2358, 12173, 20043, 2011, 1996, 8638, 1012, 102],\n",
       " [101, 1996, 2158, 2007, 1037, 2338, 1012, 102],\n",
       " [101, 3806, 6376, 1996, 7270, 1012, 102],\n",
       " [101, 1996, 9452, 6376, 1996, 3827, 3526, 1012, 102],\n",
       " [101, 1996, 3827, 3526, 2001, 6376, 2011, 1996, 9452, 1012, 102],\n",
       " [101, 1996, 5291, 2962, 9511, 1996, 2314, 1012, 102],\n",
       " [101, 1996, 2314, 2001, 9511, 2011, 1996, 5291, 2962, 1012, 102],\n",
       " [101, 1996, 6074, 3236, 1996, 9452, 1012, 102],\n",
       " [101, 1996, 25742, 13077, 2039, 1996, 2300, 1012, 102],\n",
       " [101, 1996, 14366, 3561, 2007, 2300, 1012, 102],\n",
       " [101, 2198, 2363, 1037, 2338, 1012, 102],\n",
       " [101, 2198, 4342, 1037, 10800, 1012, 102],\n",
       " [101, 1996, 20463, 2584, 2198, 1012, 102],\n",
       " [101, 2198, 2363, 1996, 20463, 1012, 102],\n",
       " [101, 1996, 3888, 2633, 2288, 2000, 2198, 2044, 2172, 15382, 1012, 102],\n",
       " [101, 1996, 3888, 2633, 2584, 2198, 2044, 2172, 15382, 1012, 102],\n",
       " [101, 2300, 3561, 1996, 2452, 2152, 1012, 102],\n",
       " [101, 2300, 3561, 1996, 2452, 1012, 102],\n",
       " [101, 2300, 21764, 1996, 2452, 1012, 102],\n",
       " [101, 1996, 2452, 3561, 1996, 2300, 2152, 1012, 102],\n",
       " [101, 1996, 2452, 3561, 1997, 2300, 1012, 102],\n",
       " [101, 1996, 2452, 3561, 2007, 2300, 1012, 102],\n",
       " [101, 1996, 2452, 21764, 2007, 2300, 1012, 102],\n",
       " [101, 1996, 19398, 17835, 2152, 2007, 15664, 1012, 102],\n",
       " [101, 1996, 2346, 8534, 2007, 1037, 2962, 1012, 102],\n",
       " [101, 1996, 3589, 3333, 6436, 1997, 2049, 6207, 1012, 102],\n",
       " [101, 1996, 15664, 17835, 1996, 19398, 2152, 1012, 102],\n",
       " [101, 1037, 2962, 8534, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 5835, 11055, 1996, 6381, 2489, 1012, 102],\n",
       " [101, 1996, 3589, 3333, 2049, 6207, 2489, 1012, 102],\n",
       " [101, 2070, 5628, 3631, 2125, 1997, 1996, 3392, 1012, 102],\n",
       " [101, 1996, 3392, 3631, 2125, 2070, 5628, 1012, 102],\n",
       " [101, 1996, 3392, 3333, 2070, 5628, 1012, 102],\n",
       " [101, 1996, 3392, 2439, 2070, 5628, 1012, 102],\n",
       " [101, 2300, 11957, 2094, 2041, 1997, 1996, 22421, 1012, 102],\n",
       " [101, 1996, 22421, 11957, 2094, 2300, 2039, 1012, 102],\n",
       " [101, 1996, 22421, 11957, 2094, 2300, 1012, 102],\n",
       " [101, 1996, 2452, 3561, 2300, 1012, 102],\n",
       " [101, 1996, 2962, 6573, 1996, 6536, 2046, 1996, 2346, 1012, 102],\n",
       " [101, 1996, 14366, 15748, 4064, 1997, 2300, 1012, 102],\n",
       " [101, 1996, 2962, 6573, 2114, 1996, 6536, 2046, 1996, 2346, 1012, 102],\n",
       " [101, 16889, 6386, 3631, 1996, 3332, 1012, 102],\n",
       " [101, 1996, 2486, 1997, 1996, 3612, 3631, 1996, 3332, 1012, 102],\n",
       " [101, 1996, 3332, 3631, 2013, 16889, 6386, 1012, 102],\n",
       " [101, 1996, 3332, 3631, 2013, 1996, 2486, 1997, 1996, 3612, 1012, 102],\n",
       " [101,\n",
       "  2054,\n",
       "  1996,\n",
       "  2486,\n",
       "  1997,\n",
       "  1996,\n",
       "  3612,\n",
       "  2106,\n",
       "  2000,\n",
       "  1996,\n",
       "  3332,\n",
       "  2001,\n",
       "  3338,\n",
       "  2009,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2718, 1996, 2962, 2114, 1996, 2813, 1012, 102],\n",
       " [101, 2198, 2718, 1996, 2813, 2007, 1996, 2962, 1012, 102],\n",
       " [101, 2198, 10410, 2070, 4511, 2013, 1037, 8460, 1012, 102],\n",
       " [101, 2198, 10410, 1037, 8460, 1997, 2070, 4511, 1012, 102],\n",
       " [101, 2198, 4201, 1996, 2338, 2006, 1996, 2795, 1012, 102],\n",
       " [101, 2198, 2443, 2010, 2171, 1999, 1996, 2862, 1012, 102],\n",
       " [101, 2198, 8209, 1996, 14219, 3031, 1996, 4744, 1012, 102],\n",
       " [101, 2198, 8209, 1996, 4744, 2007, 14219, 1012, 102],\n",
       " [101, 2198, 7349, 5785, 2000, 1996, 3336, 1012, 102],\n",
       " [101, 2198, 7349, 1996, 3336, 5785, 1012, 102],\n",
       " [101, 2198, 7349, 1996, 3336, 2039, 2007, 5785, 1012, 102],\n",
       " [101, 2198, 7349, 1996, 3336, 5785, 2039, 1012, 102],\n",
       " [101, 1996, 3608, 3658, 3294, 1999, 1996, 3482, 1012, 102],\n",
       " [101, 1996, 3482, 3294, 3397, 1996, 3608, 1012, 102],\n",
       " [101, 1996, 3345, 2288, 2000, 1996, 2276, 3929, 1012, 102],\n",
       " [101, 1996, 3345, 2584, 1996, 2276, 3929, 1012, 102],\n",
       " [101, 2811, 1996, 11359, 2114, 1996, 11687, 3294, 1012, 102],\n",
       " [101, 2811, 1996, 11687, 2007, 1996, 11359, 3294, 1012, 102],\n",
       " [101, 12509, 1996, 6773, 3031, 1996, 2813, 3294, 1012, 102],\n",
       " [101, 12509, 2035, 1996, 6773, 3031, 1996, 2813, 3294, 1012, 102],\n",
       " [101, 12509, 1996, 2813, 2007, 2035, 1996, 6773, 1012, 102],\n",
       " [101, 12509, 1996, 2878, 2813, 2007, 1996, 6773, 1012, 102],\n",
       " [101, 2054, 2198, 2106, 2000, 1996, 2813, 2001, 6773, 2009, 1012, 102],\n",
       " [101, 2054, 2198, 2106, 2000, 1996, 2878, 2813, 2001, 6773, 2009, 1012, 102],\n",
       " [101, 2054, 2198, 2106, 2000, 1996, 2813, 2001, 2718, 2009, 1012, 102],\n",
       " [101, 2054, 1996, 2962, 2106, 2000, 1996, 2813, 2001, 2718, 2009, 1012, 102],\n",
       " [101,\n",
       "  2054,\n",
       "  1996,\n",
       "  2962,\n",
       "  2106,\n",
       "  2000,\n",
       "  1996,\n",
       "  2878,\n",
       "  2813,\n",
       "  2001,\n",
       "  2718,\n",
       "  2009,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2165, 3021, 2000, 2022, 1037, 7966, 1012, 102],\n",
       " [101, 2198, 5531, 3021, 2000, 2022, 1037, 7966, 1012, 102],\n",
       " [101, 2507, 1996, 5835, 2000, 1996, 3336, 2440, 1012, 102],\n",
       " [101, 2507, 1996, 5835, 2000, 1996, 3336, 8300, 1012, 102],\n",
       " [101, 2507, 1996, 3336, 1996, 5835, 2440, 1012, 102],\n",
       " [101, 2507, 1996, 3336, 1996, 5835, 8300, 1012, 102],\n",
       " [101, 14548, 1996, 8416, 2006, 1996, 3336, 7950, 1012, 102],\n",
       " [101, 14548, 1996, 8416, 2006, 1996, 3336, 6680, 1012, 102],\n",
       " [101, 14548, 1996, 3336, 2007, 1996, 8416, 7950, 1012, 102],\n",
       " [101, 14548, 1996, 3336, 2007, 1996, 8416, 6680, 1012, 102],\n",
       " [101, 4318, 1996, 3336, 2007, 1996, 8416, 6680, 1012, 102],\n",
       " [101, 4318, 1996, 3336, 2007, 1996, 8416, 7950, 1012, 102],\n",
       " [101, 1996, 2452, 6573, 1996, 2962, 4237, 1012, 102],\n",
       " [101, 1996, 2962, 6573, 1996, 2452, 4237, 1012, 102],\n",
       " [101, 1996, 2452, 14368, 4237, 2114, 1996, 2962, 1012, 102],\n",
       " [101, 1996, 2962, 14368, 1996, 2452, 4237, 1012, 102],\n",
       " [101, 1996, 4951, 3561, 2007, 17141, 2041, 1997, 1996, 10216, 1012, 102],\n",
       " [101, 1996, 2452, 21764, 1997, 2300, 3031, 1996, 2598, 1012, 102],\n",
       " [101, 2198, 2443, 2014, 2171, 1999, 1996, 2862, 1012, 102],\n",
       " [101, 2198, 4565, 1996, 3608, 2013, 1996, 3392, 2000, 1996, 5747, 1012, 102],\n",
       " [101, 2198, 10410, 1996, 5835, 1997, 2070, 2300, 1012, 102],\n",
       " [101, 2198, 2435, 3021, 1996, 2338, 1012, 102],\n",
       " [101, 2198, 2288, 1996, 2338, 2013, 3021, 1012, 102],\n",
       " [101, 2198, 2435, 3021, 1997, 1996, 2338, 1012, 102],\n",
       " [101, 2057, 2031, 2619, 1999, 1996, 2542, 2282, 1012, 102],\n",
       " [101, 2198, 2003, 2200, 13545, 1997, 2984, 1012, 102],\n",
       " [101, 2984, 4191, 2012, 2198, 1012, 102],\n",
       " [101, 1996, 2911, 7569, 4218, 1996, 5975, 1012, 102],\n",
       " [101,\n",
       "  2984,\n",
       "  10592,\n",
       "  2198,\n",
       "  1037,\n",
       "  7966,\n",
       "  1998,\n",
       "  3021,\n",
       "  1037,\n",
       "  15536,\n",
       "  8737,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 12362, 12655, 2004, 4326, 1998, 8801, 2004, 17109, 1012, 102],\n",
       " [101,\n",
       "  9790,\n",
       "  2404,\n",
       "  1996,\n",
       "  2808,\n",
       "  2006,\n",
       "  1996,\n",
       "  2795,\n",
       "  1998,\n",
       "  1996,\n",
       "  2636,\n",
       "  2006,\n",
       "  1996,\n",
       "  3242,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  14207,\n",
       "  2435,\n",
       "  1037,\n",
       "  14757,\n",
       "  2000,\n",
       "  2198,\n",
       "  1998,\n",
       "  1037,\n",
       "  18982,\n",
       "  2000,\n",
       "  6819,\n",
       "  13469,\n",
       "  2078,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 5987, 2198, 2000, 2663, 1998, 4302, 2000, 4558, 1012, 102],\n",
       " [101, 2017, 4521, 1996, 3869, 6315, 1998, 1996, 12486, 12984, 1012, 102],\n",
       " [101,\n",
       "  2027,\n",
       "  2409,\n",
       "  9790,\n",
       "  2040,\n",
       "  2000,\n",
       "  2831,\n",
       "  2000,\n",
       "  1998,\n",
       "  3448,\n",
       "  2043,\n",
       "  2000,\n",
       "  2681,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3044,\n",
       "  13190,\n",
       "  1010,\n",
       "  1998,\n",
       "  2010,\n",
       "  7794,\n",
       "  2101,\n",
       "  6955,\n",
       "  1010,\n",
       "  1037,\n",
       "  7070,\n",
       "  3074,\n",
       "  1997,\n",
       "  10485,\n",
       "  2000,\n",
       "  1996,\n",
       "  3075,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  9790,\n",
       "  2333,\n",
       "  1010,\n",
       "  1998,\n",
       "  2984,\n",
       "  2036,\n",
       "  4015,\n",
       "  1010,\n",
       "  2014,\n",
       "  2449,\n",
       "  2000,\n",
       "  1037,\n",
       "  2367,\n",
       "  3295,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  4594,\n",
       "  1999,\n",
       "  13359,\n",
       "  1010,\n",
       "  2130,\n",
       "  2295,\n",
       "  2198,\n",
       "  2018,\n",
       "  3478,\n",
       "  2000,\n",
       "  13984,\n",
       "  1010,\n",
       "  2984,\n",
       "  2025,\n",
       "  2000,\n",
       "  2681,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  3391,\n",
       "  2066,\n",
       "  1010,\n",
       "  2021,\n",
       "  6600,\n",
       "  8823,\n",
       "  1010,\n",
       "  1996,\n",
       "  3869,\n",
       "  6315,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  13109,\n",
       "  2080,\n",
       "  9652,\n",
       "  4122,\n",
       "  1010,\n",
       "  2295,\n",
       "  2016,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  2428,\n",
       "  5987,\n",
       "  1010,\n",
       "  1996,\n",
       "  5631,\n",
       "  13600,\n",
       "  2000,\n",
       "  2022,\n",
       "  1999,\n",
       "  1996,\n",
       "  2377,\n",
       "  1011,\n",
       "  12446,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 4342, 2413, 6669, 1012, 102],\n",
       " [101, 3021, 24843, 2010, 3210, 9996, 1012, 102],\n",
       " [101, 2984, 3248, 1996, 6710, 17950, 1012, 102],\n",
       " [101, 2198, 6669, 4342, 2413, 1012, 102],\n",
       " [101, 3021, 9996, 24843, 2010, 3210, 1012, 102],\n",
       " [101, 2198, 4342, 2413, 3202, 1012, 102],\n",
       " [101, 3021, 24843, 2010, 3210, 3254, 1012, 102],\n",
       " [101, 2984, 2097, 2377, 1996, 6710, 2574, 1012, 102],\n",
       " [101, 2198, 3202, 4342, 2413, 1012, 102],\n",
       " [101, 3021, 3254, 24843, 2010, 3210, 1012, 102],\n",
       " [101, 2984, 2097, 2574, 2377, 1996, 6710, 1012, 102],\n",
       " [101, 2198, 3202, 4342, 2413, 6669, 1012, 102],\n",
       " [101, 2198, 4342, 2413, 6669, 2471, 3202, 1012, 102],\n",
       " [101, 2198, 4342, 2413, 6669, 3202, 1012, 102],\n",
       " [101, 2198, 6669, 4342, 2413, 3202, 1012, 102],\n",
       " [101, 2198, 4342, 2413, 3202, 6669, 1012, 102],\n",
       " [101, 4415, 1010, 2198, 3202, 2097, 2763, 4553, 2413, 6669, 1012, 102],\n",
       " [101, 3202, 1010, 2198, 2763, 2097, 4415, 4553, 2413, 6669, 1012, 102],\n",
       " [101, 4415, 1010, 2198, 6669, 2097, 3202, 4553, 2413, 2763, 1012, 102],\n",
       " [101, 2198, 6669, 4565, 1996, 3608, 2091, 1996, 2940, 1012, 102],\n",
       " [101, 2198, 4565, 1996, 3608, 6669, 2091, 1996, 2940, 1012, 102],\n",
       " [101, 2198, 4565, 1996, 3608, 2091, 1996, 2940, 6669, 1012, 102],\n",
       " [101, 2198, 6669, 2915, 1996, 3608, 1012, 102],\n",
       " [101, 2198, 2915, 1996, 3608, 6669, 1012, 102],\n",
       " [101, 2198, 29024, 3764, 2000, 2984, 1012, 102],\n",
       " [101, 2198, 3764, 29024, 2000, 2984, 1012, 102],\n",
       " [101, 2198, 3764, 2000, 2984, 29024, 1012, 102],\n",
       " [101, 2198, 3764, 2413, 29024, 2000, 2984, 1012, 102],\n",
       " [101, 2198, 3764, 2413, 2000, 2984, 29024, 1012, 102],\n",
       " [101, 2984, 5598, 1996, 3586, 6669, 2058, 1996, 2197, 8638, 1012, 102],\n",
       " [101, 2984, 5598, 1996, 3586, 2058, 1996, 2197, 8638, 6669, 1012, 102],\n",
       " [101, 2198, 3764, 29024, 2413, 2000, 2984, 1012, 102],\n",
       " [101, 2198, 3764, 2000, 2984, 2413, 1012, 102],\n",
       " [101, 2984, 11766, 2000, 2681, 2198, 1012, 102],\n",
       " [101, 1996, 7212, 8823, 6315, 1996, 6240, 1012, 102],\n",
       " [101, 2984, 11766, 2008, 2002, 2323, 2717, 3021, 1012, 102],\n",
       " [101, 2057, 5136, 1996, 2273, 2035, 18656, 1012, 102],\n",
       " [101, 2057, 5136, 1996, 2273, 2035, 6135, 4689, 1012, 102],\n",
       " [101, 1045, 2387, 1996, 2273, 2035, 1012, 102],\n",
       " [101, 1996, 2273, 2020, 4727, 2035, 1012, 102],\n",
       " [101, 1996, 2273, 3369, 2035, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  3836,\n",
       "  3641,\n",
       "  1996,\n",
       "  2048,\n",
       "  3337,\n",
       "  2119,\n",
       "  2000,\n",
       "  3477,\n",
       "  2485,\n",
       "  3086,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 2513, 1996, 2808, 2035, 2000, 2037, 5608, 1012, 102],\n",
       " [101, 2057, 4993, 1996, 8397, 2035, 2417, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  10365,\n",
       "  7349,\n",
       "  1996,\n",
       "  21475,\n",
       "  2015,\n",
       "  2035,\n",
       "  2000,\n",
       "  1996,\n",
       "  7212,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 3021, 7098, 1997, 2370, 2198, 2987, 1005, 1056, 5136, 1012, 102],\n",
       " [101, 2188, 2001, 2908, 2011, 2198, 1012, 102],\n",
       " [101, 2984, 2187, 1996, 2282, 4854, 1012, 102],\n",
       " [101, 1996, 2282, 2001, 2187, 4854, 2011, 2984, 1012, 102],\n",
       " [101, 1996, 2282, 2001, 2187, 4854, 1012, 102],\n",
       " [101, 2198, 12950, 3021, 1012, 102],\n",
       " [101, 3021, 2003, 15881, 2011, 2198, 1012, 102],\n",
       " [101, 1996, 7427, 12781, 2184, 6053, 1012, 102],\n",
       " [101, 2184, 6053, 2001, 12781, 2011, 1996, 7427, 1012, 102],\n",
       " [101, 2023, 2338, 3465, 1002, 2184, 1012, 102],\n",
       " [101, 1002, 2184, 2001, 3465, 2011, 2023, 2338, 1012, 102],\n",
       " [101, 1996, 2338, 3465, 2198, 1002, 2184, 1012, 102],\n",
       " [101, 2198, 2001, 3465, 1002, 2184, 2011, 1996, 2338, 1012, 102],\n",
       " [101, 2198, 2003, 7622, 2011, 3021, 2004, 13433, 8737, 3560, 1012, 102],\n",
       " [101, 1996, 3337, 2020, 2081, 1037, 2204, 2388, 1012, 102],\n",
       " [101, 1996, 3337, 2020, 2081, 1037, 2204, 2388, 2011, 5916, 2984, 1012, 102],\n",
       " [101, 1996, 4268, 2020, 3478, 2011, 4098, 2004, 1037, 2269, 1012, 102],\n",
       " [101, 1996, 4268, 2020, 3478, 2004, 1037, 2269, 1012, 102],\n",
       " [101, 1996, 2273, 2020, 4930, 2011, 1996, 2801, 2004, 14652, 1012, 102],\n",
       " [101, 1996, 2273, 2020, 5763, 2000, 2681, 1012, 102],\n",
       " [101,\n",
       "  2002,\n",
       "  17894,\n",
       "  2229,\n",
       "  2010,\n",
       "  2814,\n",
       "  2035,\n",
       "  2004,\n",
       "  13433,\n",
       "  8737,\n",
       "  3560,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 5916, 2984, 2081, 1996, 3337, 2035, 1037, 2204, 2388, 1012, 102],\n",
       " [101, 4098, 3478, 1996, 4268, 2035, 2004, 1037, 2269, 1012, 102],\n",
       " [101, 3581, 5763, 1996, 2273, 2035, 2000, 2681, 1012, 102],\n",
       " [101, 2057, 10116, 2000, 1996, 2270, 2198, 2000, 2022, 1037, 5394, 1012, 102],\n",
       " [101, 2057, 10116, 2198, 2000, 1996, 2270, 2000, 2022, 1037, 5394, 1012, 102],\n",
       " [101, 2057, 10116, 25664, 2198, 2000, 2022, 1037, 5394, 1012, 102],\n",
       " [101, 2057, 10116, 2198, 25664, 2000, 2022, 1037, 5394, 1012, 102],\n",
       " [101,\n",
       "  2057,\n",
       "  10116,\n",
       "  25664,\n",
       "  2000,\n",
       "  1996,\n",
       "  2270,\n",
       "  2198,\n",
       "  2000,\n",
       "  2022,\n",
       "  1037,\n",
       "  5394,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  10116,\n",
       "  2198,\n",
       "  25664,\n",
       "  2000,\n",
       "  1996,\n",
       "  2270,\n",
       "  2000,\n",
       "  2022,\n",
       "  1037,\n",
       "  5394,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  3421,\n",
       "  2000,\n",
       "  1996,\n",
       "  4670,\n",
       "  2984,\n",
       "  2004,\n",
       "  1037,\n",
       "  10218,\n",
       "  22978,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2027,\n",
       "  3421,\n",
       "  2984,\n",
       "  2000,\n",
       "  1996,\n",
       "  4670,\n",
       "  2004,\n",
       "  1037,\n",
       "  10218,\n",
       "  22978,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 3421, 5667, 2984, 2004, 1037, 10218, 22978, 1012, 102],\n",
       " [101, 2027, 3421, 2984, 5667, 2004, 1037, 10218, 22978, 1012, 102],\n",
       " [101,\n",
       "  2027,\n",
       "  3421,\n",
       "  2984,\n",
       "  5667,\n",
       "  2000,\n",
       "  1996,\n",
       "  4670,\n",
       "  2004,\n",
       "  1037,\n",
       "  10218,\n",
       "  22978,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2057, 4928, 2000, 1996, 4614, 3044, 2000, 2022, 1996, 12383, 1012, 102],\n",
       " [101,\n",
       "  2057,\n",
       "  4928,\n",
       "  9530,\n",
       "  23633,\n",
       "  2135,\n",
       "  3044,\n",
       "  2000,\n",
       "  2022,\n",
       "  1996,\n",
       "  12383,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  4928,\n",
       "  3044,\n",
       "  9530,\n",
       "  23633,\n",
       "  2135,\n",
       "  2000,\n",
       "  2022,\n",
       "  1996,\n",
       "  12383,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  4928,\n",
       "  9530,\n",
       "  23633,\n",
       "  2135,\n",
       "  2000,\n",
       "  1996,\n",
       "  4614,\n",
       "  3044,\n",
       "  2000,\n",
       "  2022,\n",
       "  1996,\n",
       "  12383,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  4928,\n",
       "  3044,\n",
       "  9530,\n",
       "  23633,\n",
       "  2135,\n",
       "  2000,\n",
       "  1996,\n",
       "  4614,\n",
       "  2000,\n",
       "  2022,\n",
       "  1996,\n",
       "  12383,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 19785, 27129, 1996, 10722, 15000, 2015, 4257, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  24665,\n",
       "  10085,\n",
       "  2121,\n",
       "  2598,\n",
       "  1996,\n",
       "  4157,\n",
       "  13435,\n",
       "  2000,\n",
       "  1037,\n",
       "  2986,\n",
       "  9898,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 4993, 2037, 2160, 1037, 22293, 8703, 1997, 2665, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  8183,\n",
       "  13327,\n",
       "  2015,\n",
       "  2743,\n",
       "  2037,\n",
       "  18368,\n",
       "  2015,\n",
       "  11689,\n",
       "  8237,\n",
       "  2063,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 4268, 4191, 3209, 2046, 1037, 21517, 1012, 102],\n",
       " [101, 2002, 19055, 2010, 23975, 3294, 2061, 22772, 1012, 102],\n",
       " [101, 2027, 7349, 1996, 6240, 2000, 1996, 7212, 6315, 1012, 102],\n",
       " [101, 1996, 7212, 8823, 2012, 1996, 6240, 6315, 1012, 102],\n",
       " [101, 2057, 2293, 2068, 1012, 102],\n",
       " [101, 2057, 2293, 2027, 1012, 102],\n",
       " [101, 2057, 2293, 2037, 1012, 102],\n",
       " [101, 2149, 2293, 2037, 1012, 102],\n",
       " [101, 2256, 2293, 2027, 1012, 102],\n",
       " [101, 2256, 2293, 2068, 1012, 102],\n",
       " [101, 2256, 2293, 2037, 1012, 102],\n",
       " [101, 2002, 6772, 2008, 2984, 4782, 3021, 2003, 13534, 1012, 102],\n",
       " [101, 2032, 6772, 2008, 2984, 4782, 3021, 2003, 13534, 1012, 102],\n",
       " [101, 2010, 6772, 2008, 2984, 4782, 3021, 2003, 13534, 1012, 102],\n",
       " [101, 2984, 7459, 2032, 1012, 102],\n",
       " [101, 2984, 2003, 13545, 1997, 2032, 1012, 102],\n",
       " [101, 2984, 2003, 13545, 2032, 1012, 102],\n",
       " [101, 2984, 6367, 2032, 1012, 102],\n",
       " [101, 2984, 1005, 1055, 6256, 2032, 2001, 10311, 1012, 102],\n",
       " [101, 2984, 1005, 1055, 6256, 1997, 2032, 2001, 10311, 1012, 102],\n",
       " [101, 2008, 2198, 7459, 2984, 2003, 21888, 1012, 102],\n",
       " [101, 2198, 2000, 2293, 2984, 2052, 2022, 21888, 1012, 102],\n",
       " [101, 2005, 2198, 2000, 2293, 2984, 2052, 2022, 21888, 1012, 102],\n",
       " [101, 2000, 2175, 6917, 2052, 2022, 3835, 1012, 102],\n",
       " [101, 2198, 1005, 1055, 2933, 2000, 2175, 6917, 2003, 3835, 1012, 102],\n",
       " [101, 2984, 3373, 2198, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2641, 2198, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2988, 2198, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2641, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2699, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 3832, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 3266, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 9059, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 2699, 2198, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 3266, 2198, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 9059, 2198, 2000, 2175, 6917, 1012, 102],\n",
       " [101, 2984, 3373, 2032, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2641, 2032, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 3373, 2002, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2641, 2002, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2988, 2002, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 3373, 2010, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2641, 2010, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2984, 2988, 2010, 2000, 2031, 3866, 2014, 1012, 102],\n",
       " [101, 2009, 2003, 3056, 2008, 2198, 2038, 3866, 2984, 1012, 102],\n",
       " [101, 2009, 2003, 3497, 2008, 2198, 2038, 3866, 2984, 1012, 102],\n",
       " [101, 2045, 2024, 12358, 1999, 2008, 3871, 1012, 102],\n",
       " [101, 2045, 2003, 12358, 1999, 2008, 3871, 1012, 102],\n",
       " [101, 2045, 2003, 7194, 2093, 2273, 2012, 2008, 2276, 1012, 102],\n",
       " [101, 2045, 2024, 7194, 2093, 2273, 2012, 2008, 2276, 1012, 102],\n",
       " [101, 1045, 5136, 2045, 2000, 2022, 1037, 2158, 1999, 2008, 3871, 1012, 102],\n",
       " [101, 1045, 5136, 2045, 1037, 2158, 1999, 2008, 3871, 1012, 102],\n",
       " [101,\n",
       "  2027,\n",
       "  6884,\n",
       "  2045,\n",
       "  2000,\n",
       "  2031,\n",
       "  2042,\n",
       "  2116,\n",
       "  12358,\n",
       "  1999,\n",
       "  2008,\n",
       "  3871,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2027, 6884, 2116, 12358, 2000, 2031, 2042, 1999, 2008, 3871, 1012, 102],\n",
       " [101,\n",
       "  2198,\n",
       "  11897,\n",
       "  5596,\n",
       "  2045,\n",
       "  2000,\n",
       "  2031,\n",
       "  2042,\n",
       "  1037,\n",
       "  7985,\n",
       "  1999,\n",
       "  2008,\n",
       "  11171,\n",
       "  2160,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  11897,\n",
       "  5596,\n",
       "  1037,\n",
       "  7985,\n",
       "  2000,\n",
       "  2031,\n",
       "  2042,\n",
       "  1999,\n",
       "  2008,\n",
       "  11171,\n",
       "  2160,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2699, 2000, 3610, 2984, 1012, 102],\n",
       " [101, 2198, 11766, 2984, 2000, 3610, 2032, 1012, 102],\n",
       " [101, 2198, 2409, 2984, 2000, 3610, 2032, 1012, 102],\n",
       " [101, 2009, 2003, 6206, 2000, 2380, 2182, 1012, 102],\n",
       " [101, 1045, 4622, 2032, 2383, 4782, 2984, 1012, 102],\n",
       " [101, 1045, 2988, 2032, 2383, 4782, 2984, 1012, 102],\n",
       " [101, 1045, 2988, 2383, 4782, 2984, 1012, 102],\n",
       " [101, 1045, 5959, 2635, 1037, 7198, 1012, 102],\n",
       " [101, 1045, 20010, 4355, 2635, 1037, 7198, 1012, 102],\n",
       " [101, 1045, 5959, 2032, 2635, 1037, 7198, 1012, 102],\n",
       " [101, 1045, 20010, 4355, 2032, 2635, 1037, 7198, 1012, 102],\n",
       " [101, 1045, 2387, 2032, 7618, 2984, 1012, 102],\n",
       " [101, 1045, 4384, 2032, 7618, 2984, 1012, 102],\n",
       " [101, 1045, 4384, 7618, 2984, 1012, 102],\n",
       " [101, 2045, 2001, 2124, 2000, 3071, 1012, 102],\n",
       " [101, 2198, 1005, 1055, 11193, 1996, 3749, 2003, 16880, 1012, 102],\n",
       " [101, 1996, 4099, 1005, 1055, 9846, 1996, 2103, 2001, 23512, 1012, 102],\n",
       " [101, 2198, 1005, 1055, 13948, 1997, 1996, 3749, 2001, 16880, 1012, 102],\n",
       " [101, 1996, 4099, 1005, 1055, 6215, 1997, 1996, 2103, 2001, 23512, 1012, 102],\n",
       " [101,\n",
       "  2198,\n",
       "  2359,\n",
       "  2000,\n",
       "  2681,\n",
       "  1996,\n",
       "  2282,\n",
       "  3407,\n",
       "  1998,\n",
       "  2681,\n",
       "  1996,\n",
       "  2282,\n",
       "  2002,\n",
       "  2106,\n",
       "  3407,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2411,\n",
       "  4604,\n",
       "  2984,\n",
       "  2188,\n",
       "  7144,\n",
       "  1010,\n",
       "  1998,\n",
       "  2016,\n",
       "  4152,\n",
       "  2045,\n",
       "  2074,\n",
       "  2986,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 6315, 4521, 3869, 7144, 1012, 102],\n",
       " [101, 1045, 2069, 4521, 3869, 7144, 6315, 1012, 102],\n",
       " [101, 1045, 2123, 1005, 1056, 2228, 5965, 2097, 1010, 2593, 1012, 102],\n",
       " [101, 4560, 7777, 28540, 1010, 1998, 9079, 2515, 2205, 1012, 102],\n",
       " [101, 4560, 8823, 28540, 1010, 1998, 9079, 2038, 2205, 1012, 102],\n",
       " [101, 4560, 2003, 5983, 28540, 1010, 1998, 9079, 2003, 2205, 1012, 102],\n",
       " [101, 2198, 2003, 2975, 2021, 2984, 1005, 1055, 2025, 1012, 102],\n",
       " [101, 1045, 5136, 3021, 9414, 1998, 1045, 5136, 8836, 2025, 1012, 102],\n",
       " [101,\n",
       "  8836,\n",
       "  2318,\n",
       "  2770,\n",
       "  2091,\n",
       "  1996,\n",
       "  2395,\n",
       "  1010,\n",
       "  2021,\n",
       "  2069,\n",
       "  2044,\n",
       "  4560,\n",
       "  2318,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 8836, 2081, 3021, 4756, 1010, 1998, 2059, 4560, 2081, 1012, 102],\n",
       " [101,\n",
       "  2984,\n",
       "  2234,\n",
       "  2000,\n",
       "  3191,\n",
       "  5965,\n",
       "  1005,\n",
       "  1055,\n",
       "  2466,\n",
       "  1010,\n",
       "  1998,\n",
       "  1045,\n",
       "  2036,\n",
       "  2234,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  4122,\n",
       "  2000,\n",
       "  2175,\n",
       "  2006,\n",
       "  10885,\n",
       "  1010,\n",
       "  2021,\n",
       "  2002,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  2113,\n",
       "  2043,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  2001,\n",
       "  2409,\n",
       "  2000,\n",
       "  3288,\n",
       "  2242,\n",
       "  2000,\n",
       "  1996,\n",
       "  2283,\n",
       "  1010,\n",
       "  2061,\n",
       "  2016,\n",
       "  2356,\n",
       "  9790,\n",
       "  2054,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2057,\n",
       "  2453,\n",
       "  2175,\n",
       "  2006,\n",
       "  10885,\n",
       "  2065,\n",
       "  2057,\n",
       "  2064,\n",
       "  2412,\n",
       "  3275,\n",
       "  2041,\n",
       "  2043,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  6902,\n",
       "  2359,\n",
       "  2000,\n",
       "  4929,\n",
       "  1037,\n",
       "  10722,\n",
       "  19068,\n",
       "  2080,\n",
       "  2000,\n",
       "  1996,\n",
       "  2283,\n",
       "  1010,\n",
       "  2021,\n",
       "  25222,\n",
       "  19362,\n",
       "  2481,\n",
       "  1005,\n",
       "  1056,\n",
       "  5630,\n",
       "  3251,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  5807,\n",
       "  1005,\n",
       "  1056,\n",
       "  2377,\n",
       "  2007,\n",
       "  9494,\n",
       "  2138,\n",
       "  2000,\n",
       "  2003,\n",
       "  4795,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 2003, 2108, 6936, 1998, 8836, 2003, 2108, 2205, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  3342,\n",
       "  2198,\n",
       "  2108,\n",
       "  6936,\n",
       "  1010,\n",
       "  2021,\n",
       "  2017,\n",
       "  9131,\n",
       "  8836,\n",
       "  2108,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  8836,\n",
       "  2453,\n",
       "  2031,\n",
       "  8828,\n",
       "  28540,\n",
       "  1010,\n",
       "  2021,\n",
       "  9079,\n",
       "  5807,\n",
       "  1005,\n",
       "  1056,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  4560,\n",
       "  5176,\n",
       "  2008,\n",
       "  2057,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3116,\n",
       "  1010,\n",
       "  1998,\n",
       "  8836,\n",
       "  2097,\n",
       "  2425,\n",
       "  2149,\n",
       "  2043,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  2057,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3116,\n",
       "  1010,\n",
       "  2008,\n",
       "  8836,\n",
       "  2097,\n",
       "  2425,\n",
       "  2149,\n",
       "  2043,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  2000,\n",
       "  2984,\n",
       "  2008,\n",
       "  3533,\n",
       "  2056,\n",
       "  9079,\n",
       "  2064,\n",
       "  2831,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2984, 3555, 2008, 8828, 28540, 1010, 9079, 8440, 1005, 1056, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 5983, 28540, 1010, 9079, 1005, 1055, 2025, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 4521, 28540, 1010, 9079, 4122, 2000, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 2052, 4521, 28540, 1010, 9079, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 8440, 1005, 1056, 8828, 28540, 1010, 9079, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 5983, 28540, 1010, 9079, 2318, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 4521, 28540, 1010, 9079, 2081, 2033, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 2031, 8828, 28540, 1010, 9079, 2323, 1012, 102],\n",
       " [101, 2984, 3555, 2008, 9414, 1010, 1045, 5136, 9079, 2025, 1012, 102],\n",
       " [101,\n",
       "  14765,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  3342,\n",
       "  2138,\n",
       "  9079,\n",
       "  2018,\n",
       "  2036,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  8182,\n",
       "  3533,\n",
       "  1005,\n",
       "  1055,\n",
       "  3535,\n",
       "  2000,\n",
       "  2424,\n",
       "  9079,\n",
       "  2096,\n",
       "  2017,\n",
       "  8182,\n",
       "  4560,\n",
       "  1005,\n",
       "  1055,\n",
       "  3535,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2984,\n",
       "  8781,\n",
       "  3533,\n",
       "  1005,\n",
       "  1055,\n",
       "  4792,\n",
       "  2000,\n",
       "  4521,\n",
       "  28540,\n",
       "  1010,\n",
       "  2021,\n",
       "  2069,\n",
       "  2044,\n",
       "  1045,\n",
       "  2018,\n",
       "  8781,\n",
       "  8836,\n",
       "  1005,\n",
       "  1055,\n",
       "  4792,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  8836,\n",
       "  4541,\n",
       "  1996,\n",
       "  3535,\n",
       "  2000,\n",
       "  6545,\n",
       "  9079,\n",
       "  1010,\n",
       "  2021,\n",
       "  2069,\n",
       "  2044,\n",
       "  1045,\n",
       "  2018,\n",
       "  6380,\n",
       "  1996,\n",
       "  3247,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2198,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  2718,\n",
       "  1037,\n",
       "  2188,\n",
       "  2448,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2113,\n",
       "  1037,\n",
       "  2450,\n",
       "  2040,\n",
       "  2106,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2008,\n",
       "  22396,\n",
       "  2180,\n",
       "  1996,\n",
       "  9640,\n",
       "  4410,\n",
       "  2003,\n",
       "  2025,\n",
       "  11341,\n",
       "  1010,\n",
       "  2021,\n",
       "  2008,\n",
       "  2848,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  2113,\n",
       "  2016,\n",
       "  2106,\n",
       "  2003,\n",
       "  11341,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  5807,\n",
       "  1005,\n",
       "  1056,\n",
       "  2031,\n",
       "  2209,\n",
       "  2007,\n",
       "  9494,\n",
       "  2138,\n",
       "  2000,\n",
       "  2031,\n",
       "  2003,\n",
       "  4795,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  6902,\n",
       "  2359,\n",
       "  2000,\n",
       "  2022,\n",
       "  4147,\n",
       "  1037,\n",
       "  10722,\n",
       "  19068,\n",
       "  2080,\n",
       "  2000,\n",
       "  1996,\n",
       "  2283,\n",
       "  1010,\n",
       "  2021,\n",
       "  25222,\n",
       "  19362,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  2113,\n",
       "  3251,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  14765,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  2022,\n",
       "  4622,\n",
       "  2138,\n",
       "  9079,\n",
       "  2018,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 14765, 2787, 2008, 5983, 28540, 1010, 2016, 2323, 2022, 1012, 102],\n",
       " [101, 14765, 2787, 5983, 28540, 1010, 2000, 2022, 1012, 102],\n",
       " [101, 3191, 5965, 1005, 1055, 2466, 1010, 1045, 2036, 2215, 2000, 1012, 102],\n",
       " [101,\n",
       "  2017,\n",
       "  5807,\n",
       "  1005,\n",
       "  1056,\n",
       "  2377,\n",
       "  2007,\n",
       "  9494,\n",
       "  2138,\n",
       "  2377,\n",
       "  2007,\n",
       "  9494,\n",
       "  2000,\n",
       "  2003,\n",
       "  4795,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  6902,\n",
       "  2359,\n",
       "  2000,\n",
       "  4929,\n",
       "  1037,\n",
       "  10722,\n",
       "  19068,\n",
       "  2080,\n",
       "  2000,\n",
       "  1996,\n",
       "  2283,\n",
       "  1010,\n",
       "  2021,\n",
       "  4929,\n",
       "  1037,\n",
       "  10722,\n",
       "  19068,\n",
       "  2080,\n",
       "  2000,\n",
       "  1996,\n",
       "  2283,\n",
       "  25222,\n",
       "  19362,\n",
       "  2481,\n",
       "  1005,\n",
       "  1056,\n",
       "  5630,\n",
       "  3251,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  7004,\n",
       "  9957,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  3342,\n",
       "  2138,\n",
       "  3342,\n",
       "  9079,\n",
       "  2018,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  23848,\n",
       "  3748,\n",
       "  3702,\n",
       "  2234,\n",
       "  2000,\n",
       "  8970,\n",
       "  1996,\n",
       "  15812,\n",
       "  2021,\n",
       "  1045,\n",
       "  2234,\n",
       "  2025,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  23848,\n",
       "  3748,\n",
       "  3702,\n",
       "  2234,\n",
       "  2000,\n",
       "  8970,\n",
       "  1996,\n",
       "  15812,\n",
       "  2021,\n",
       "  1045,\n",
       "  2234,\n",
       "  10785,\n",
       "  2025,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2017,\n",
       "  2323,\n",
       "  4895,\n",
       "  11066,\n",
       "  9494,\n",
       "  2138,\n",
       "  2025,\n",
       "  2000,\n",
       "  1055,\n",
       "  2003,\n",
       "  4795,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2065,\n",
       "  6902,\n",
       "  4282,\n",
       "  3251,\n",
       "  2000,\n",
       "  4929,\n",
       "  1037,\n",
       "  10722,\n",
       "  19068,\n",
       "  2080,\n",
       "  1010,\n",
       "  1998,\n",
       "  25222,\n",
       "  19362,\n",
       "  4282,\n",
       "  3251,\n",
       "  2025,\n",
       "  2000,\n",
       "  1010,\n",
       "  2079,\n",
       "  2027,\n",
       "  2113,\n",
       "  2367,\n",
       "  2477,\n",
       "  1029,\n",
       "  102],\n",
       " [101,\n",
       "  7004,\n",
       "  22906,\n",
       "  1037,\n",
       "  2466,\n",
       "  2000,\n",
       "  3342,\n",
       "  2138,\n",
       "  9079,\n",
       "  2018,\n",
       "  22906,\n",
       "  2004,\n",
       "  2466,\n",
       "  2025,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 2097, 1010, 2065, 1045, 2064, 2147, 2006, 2009, 1012, 102],\n",
       " [101, 2106, 4302, 2681, 1029, 102],\n",
       " [101, 2515, 3533, 6170, 1029, 102],\n",
       " [101, 1037, 6947, 2008, 2643, 4839, 2515, 1012, 102],\n",
       " [101, 1037, 6947, 2008, 2643, 2515, 6526, 1012, 102],\n",
       " [101, 1045, 4716, 2296, 2237, 1999, 2296, 2406, 1045, 2018, 2000, 1012, 102],\n",
       " [101, 2296, 2158, 2040, 2056, 2002, 2052, 4965, 2070, 11840, 2106, 1012, 102],\n",
       " [101, 1045, 4716, 2296, 2237, 1045, 2018, 2000, 1012, 102],\n",
       " [101, 2296, 2237, 1999, 2296, 2406, 1045, 2018, 2000, 1045, 4716, 1012, 102],\n",
       " [101,\n",
       "  2296,\n",
       "  2158,\n",
       "  2040,\n",
       "  2056,\n",
       "  2002,\n",
       "  2052,\n",
       "  4965,\n",
       "  2070,\n",
       "  11840,\n",
       "  2106,\n",
       "  4965,\n",
       "  2070,\n",
       "  11840,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 14765, 2323, 4965, 11840, 1998, 2984, 2323, 2205, 1012, 102],\n",
       " [101,\n",
       "  14765,\n",
       "  2323,\n",
       "  4965,\n",
       "  11840,\n",
       "  1998,\n",
       "  2984,\n",
       "  2323,\n",
       "  4965,\n",
       "  11840,\n",
       "  2205,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3533,\n",
       "  1005,\n",
       "  1055,\n",
       "  11265,\n",
       "  10976,\n",
       "  8583,\n",
       "  8572,\n",
       "  2010,\n",
       "  13497,\n",
       "  1010,\n",
       "  1998,\n",
       "  8836,\n",
       "  1005,\n",
       "  1055,\n",
       "  11265,\n",
       "  10976,\n",
       "  8583,\n",
       "  2079,\n",
       "  2205,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3533,\n",
       "  7777,\n",
       "  2010,\n",
       "  3347,\n",
       "  1010,\n",
       "  1998,\n",
       "  8836,\n",
       "  1005,\n",
       "  1055,\n",
       "  13497,\n",
       "  2079,\n",
       "  2205,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2296, 3861, 1997, 2993, 3369, 1012, 102],\n",
       " [101,\n",
       "  2026,\n",
       "  4470,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  2031,\n",
       "  1037,\n",
       "  18591,\n",
       "  2021,\n",
       "  2115,\n",
       "  5916,\n",
       "  2515,\n",
       "  1998,\n",
       "  2002,\n",
       "  2003,\n",
       "  4688,\n",
       "  2006,\n",
       "  1996,\n",
       "  2723,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2026,\n",
       "  4470,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  4965,\n",
       "  2505,\n",
       "  2005,\n",
       "  4234,\n",
       "  1010,\n",
       "  2021,\n",
       "  2026,\n",
       "  5916,\n",
       "  2106,\n",
       "  2009,\n",
       "  2005,\n",
       "  2032,\n",
       "  1998,\n",
       "  2009,\n",
       "  2001,\n",
       "  4408,\n",
       "  2417,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  4098,\n",
       "  3191,\n",
       "  1010,\n",
       "  1998,\n",
       "  2029,\n",
       "  2338,\n",
       "  7436,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2003,\n",
       "  1996,\n",
       "  2338,\n",
       "  1997,\n",
       "  2029,\n",
       "  3021,\n",
       "  14300,\n",
       "  2015,\n",
       "  1010,\n",
       "  1998,\n",
       "  2023,\n",
       "  2003,\n",
       "  1996,\n",
       "  2028,\n",
       "  1997,\n",
       "  2029,\n",
       "  2002,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  23848,\n",
       "  3191,\n",
       "  1010,\n",
       "  1998,\n",
       "  2029,\n",
       "  2338,\n",
       "  3960,\n",
       "  2356,\n",
       "  2339,\n",
       "  2017,\n",
       "  2910,\n",
       "  1005,\n",
       "  1056,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  23848,\n",
       "  3191,\n",
       "  1010,\n",
       "  1998,\n",
       "  2029,\n",
       "  2338,\n",
       "  3960,\n",
       "  6936,\n",
       "  2044,\n",
       "  1045,\n",
       "  2018,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 10634, 2229, 6878, 3071, 2040, 6466, 2669, 2106, 1012, 102],\n",
       " [101, 2096, 3960, 3191, 5965, 1010, 2002, 2134, 1005, 1056, 19675, 1012, 102],\n",
       " [101, 8836, 6878, 3533, 1010, 2021, 2002, 2134, 1005, 1056, 9079, 1012, 102],\n",
       " [101,\n",
       "  2348,\n",
       "  23848,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  8288,\n",
       "  24759,\n",
       "  11390,\n",
       "  1010,\n",
       "  8836,\n",
       "  20323,\n",
       "  28540,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2348,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  3520,\n",
       "  2106,\n",
       "  1010,\n",
       "  1045,\n",
       "  2079,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  8836,\n",
       "  3191,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2379, 3071, 6466, 2669, 2106, 1010, 10634, 2229, 2768, 1012, 102],\n",
       " [101,\n",
       "  8836,\n",
       "  2097,\n",
       "  3233,\n",
       "  2379,\n",
       "  23848,\n",
       "  1010,\n",
       "  2021,\n",
       "  2002,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  9079,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  9079,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  6848,\n",
       "  1037,\n",
       "  3189,\n",
       "  2055,\n",
       "  2296,\n",
       "  2879,\n",
       "  1010,\n",
       "  2016,\n",
       "  2106,\n",
       "  2296,\n",
       "  2611,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 8836, 2097, 3233, 2379, 2296, 2450, 2008, 2017, 2097, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  2113,\n",
       "  2029,\n",
       "  2450,\n",
       "  9079,\n",
       "  2097,\n",
       "  6848,\n",
       "  1037,\n",
       "  3189,\n",
       "  2055,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2113,\n",
       "  2029,\n",
       "  2450,\n",
       "  2017,\n",
       "  2097,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3520,\n",
       "  2768,\n",
       "  2379,\n",
       "  7483,\n",
       "  2296,\n",
       "  2028,\n",
       "  1997,\n",
       "  1996,\n",
       "  2308,\n",
       "  2057,\n",
       "  1005,\n",
       "  1040,\n",
       "  2042,\n",
       "  10537,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 15237, 4716, 7483, 2017, 1012, 102],\n",
       " [101, 15237, 2409, 1996, 2466, 3960, 1012, 102],\n",
       " [101,\n",
       "  2096,\n",
       "  15237,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  3942,\n",
       "  2033,\n",
       "  1010,\n",
       "  2002,\n",
       "  2106,\n",
       "  2017,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  15237,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  2425,\n",
       "  2033,\n",
       "  1037,\n",
       "  2466,\n",
       "  1010,\n",
       "  2002,\n",
       "  2106,\n",
       "  13174,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  4560,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  2831,\n",
       "  2055,\n",
       "  23848,\n",
       "  1010,\n",
       "  2002,\n",
       "  2453,\n",
       "  2055,\n",
       "  9079,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2348,\n",
       "  9986,\n",
       "  2453,\n",
       "  2425,\n",
       "  2009,\n",
       "  2000,\n",
       "  2017,\n",
       "  1010,\n",
       "  2002,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  2000,\n",
       "  2033,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2228,\n",
       "  2017,\n",
       "  2342,\n",
       "  2000,\n",
       "  2265,\n",
       "  4426,\n",
       "  2062,\n",
       "  2084,\n",
       "  2017,\n",
       "  2079,\n",
       "  3087,\n",
       "  2842,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  15237,\n",
       "  2987,\n",
       "  1005,\n",
       "  1056,\n",
       "  2215,\n",
       "  2000,\n",
       "  3942,\n",
       "  2296,\n",
       "  2103,\n",
       "  1010,\n",
       "  2002,\n",
       "  2515,\n",
       "  7623,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  13174,\n",
       "  2453,\n",
       "  2681,\n",
       "  1999,\n",
       "  2344,\n",
       "  2000,\n",
       "  3531,\n",
       "  23848,\n",
       "  1010,\n",
       "  2002,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  2010,\n",
       "  2269,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  9986,\n",
       "  2453,\n",
       "  4366,\n",
       "  2008,\n",
       "  3960,\n",
       "  2018,\n",
       "  3191,\n",
       "  2010,\n",
       "  2338,\n",
       "  1010,\n",
       "  2002,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  1996,\n",
       "  3259,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  1005,\n",
       "  2222,\n",
       "  2735,\n",
       "  1996,\n",
       "  2557,\n",
       "  2091,\n",
       "  1010,\n",
       "  2021,\n",
       "  1045,\n",
       "  2180,\n",
       "  1005,\n",
       "  1056,\n",
       "  2039,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  5965,\n",
       "  7777,\n",
       "  8288,\n",
       "  24759,\n",
       "  11390,\n",
       "  1010,\n",
       "  2348,\n",
       "  2002,\n",
       "  7777,\n",
       "  28540,\n",
       "  2205,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2348,\n",
       "  2002,\n",
       "  7777,\n",
       "  28540,\n",
       "  2205,\n",
       "  1010,\n",
       "  5965,\n",
       "  7777,\n",
       "  8288,\n",
       "  24759,\n",
       "  11390,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 5965, 2435, 4870, 2000, 2010, 22872, 2138, 3581, 2018, 1012, 102],\n",
       " [101,\n",
       "  2859,\n",
       "  2003,\n",
       "  1037,\n",
       "  2406,\n",
       "  2008,\n",
       "  3533,\n",
       "  4122,\n",
       "  2000,\n",
       "  3942,\n",
       "  1010,\n",
       "  1998,\n",
       "  2002,\n",
       "  2097,\n",
       "  2205,\n",
       "  1010,\n",
       "  2065,\n",
       "  2002,\n",
       "  4152,\n",
       "  2438,\n",
       "  2769,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  6128,\n",
       "  2876,\n",
       "  1005,\n",
       "  1056,\n",
       "  3191,\n",
       "  1037,\n",
       "  2338,\n",
       "  2011,\n",
       "  11561,\n",
       "  2140,\n",
       "  1010,\n",
       "  2021,\n",
       "  21442,\n",
       "  8516,\n",
       "  2038,\n",
       "  2589,\n",
       "  2061,\n",
       "  1998,\n",
       "  2009,\n",
       "  2001,\n",
       "  3492,\n",
       "  2204,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2113,\n",
       "  2029,\n",
       "  2338,\n",
       "  4098,\n",
       "  3191,\n",
       "  1010,\n",
       "  1998,\n",
       "  2029,\n",
       "  2338,\n",
       "  7436,\n",
       "  8440,\n",
       "  1005,\n",
       "  1056,\n",
       "  2589,\n",
       "  2061,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  3533,\n",
       "  2453,\n",
       "  4299,\n",
       "  2002,\n",
       "  2018,\n",
       "  1010,\n",
       "  2021,\n",
       "  2023,\n",
       "  3475,\n",
       "  1005,\n",
       "  1056,\n",
       "  1037,\n",
       "  2406,\n",
       "  2002,\n",
       "  2038,\n",
       "  4716,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2096,\n",
       "  1045,\n",
       "  2453,\n",
       "  2215,\n",
       "  2000,\n",
       "  1010,\n",
       "  2023,\n",
       "  2003,\n",
       "  1996,\n",
       "  2785,\n",
       "  1997,\n",
       "  2518,\n",
       "  2008,\n",
       "  5671,\n",
       "  2038,\n",
       "  2525,\n",
       "  4081,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2057, 2066, 2256, 2814, 1998, 2027, 2079, 2205, 1012, 102],\n",
       " [101, 2057, 2066, 2256, 2814, 1998, 2027, 2066, 2256, 2814, 2205, 1012, 102],\n",
       " [101,\n",
       "  2057,\n",
       "  2066,\n",
       "  2256,\n",
       "  2814,\n",
       "  1998,\n",
       "  2027,\n",
       "  2066,\n",
       "  2037,\n",
       "  2814,\n",
       "  1010,\n",
       "  2205,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 13174, 5720, 2055, 2370, 2069, 2044, 9079, 2106, 1012, 102],\n",
       " [101,\n",
       "  13174,\n",
       "  5720,\n",
       "  2055,\n",
       "  2370,\n",
       "  2069,\n",
       "  2044,\n",
       "  2984,\n",
       "  2106,\n",
       "  2831,\n",
       "  2055,\n",
       "  2370,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1045, 2071, 2424, 2053, 5576, 1010, 2021, 9079, 2453, 1012, 102],\n",
       " [101, 5965, 5720, 2055, 2673, 2077, 13174, 2106, 1012, 102],\n",
       " [101,\n",
       "  3533,\n",
       "  2097,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3573,\n",
       "  1010,\n",
       "  2130,\n",
       "  2295,\n",
       "  5965,\n",
       "  2525,\n",
       "  2038,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2651,\n",
       "  2045,\n",
       "  2003,\n",
       "  2210,\n",
       "  2030,\n",
       "  2053,\n",
       "  2880,\n",
       "  16011,\n",
       "  1997,\n",
       "  11690,\n",
       "  2015,\n",
       "  1998,\n",
       "  5637,\n",
       "  2015,\n",
       "  2011,\n",
       "  1996,\n",
       "  2120,\n",
       "  2231,\n",
       "  1010,\n",
       "  2348,\n",
       "  8392,\n",
       "  6867,\n",
       "  2453,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  4018,\n",
       "  2001,\n",
       "  28844,\n",
       "  2098,\n",
       "  2011,\n",
       "  5571,\n",
       "  1997,\n",
       "  1999,\n",
       "  20740,\n",
       "  18605,\n",
       "  1998,\n",
       "  9992,\n",
       "  1996,\n",
       "  4433,\n",
       "  1010,\n",
       "  2030,\n",
       "  2012,\n",
       "  2560,\n",
       "  2667,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2585,\n",
       "  2003,\n",
       "  1037,\n",
       "  2307,\n",
       "  3063,\n",
       "  1010,\n",
       "  1998,\n",
       "  2043,\n",
       "  2002,\n",
       "  2515,\n",
       "  1010,\n",
       "  2010,\n",
       "  2159,\n",
       "  5490,\n",
       "  20023,\n",
       "  2102,\n",
       "  2012,\n",
       "  2017,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  4018,\n",
       "  2001,\n",
       "  28844,\n",
       "  2098,\n",
       "  2011,\n",
       "  5571,\n",
       "  1997,\n",
       "  1999,\n",
       "  20740,\n",
       "  18605,\n",
       "  1010,\n",
       "  2030,\n",
       "  2012,\n",
       "  2560,\n",
       "  2667,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  2592,\n",
       "  2071,\n",
       "  2031,\n",
       "  2042,\n",
       "  2207,\n",
       "  2011,\n",
       "  2175,\n",
       "  28483,\n",
       "  16179,\n",
       "  1010,\n",
       "  2021,\n",
       "  2002,\n",
       "  4900,\n",
       "  2025,\n",
       "  2000,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1037,\n",
       "  2843,\n",
       "  1997,\n",
       "  2023,\n",
       "  3430,\n",
       "  2064,\n",
       "  2022,\n",
       "  3591,\n",
       "  1999,\n",
       "  1037,\n",
       "  7199,\n",
       "  11900,\n",
       "  1998,\n",
       "  7801,\n",
       "  4827,\n",
       "  1010,\n",
       "  1998,\n",
       "  2411,\n",
       "  1045,\n",
       "  2079,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 2198, 7777, 2025, 2984, 1012, 102],\n",
       " [101, 2198, 2515, 2025, 2066, 2984, 1012, 102],\n",
       " [101, 2198, 6010, 2411, 2984, 1012, 102],\n",
       " [101, 2198, 5363, 2000, 2411, 3113, 2984, 1012, 102],\n",
       " [101, 2198, 5363, 2000, 3113, 2411, 2984, 1012, 102],\n",
       " [101, 2198, 5363, 2025, 2000, 3113, 2984, 1012, 102],\n",
       " [101, 2198, 5363, 2000, 3113, 2025, 2984, 1012, 102],\n",
       " [101, 2003, 2984, 2770, 1996, 8589, 1029, 102],\n",
       " [101, 3216, 2984, 1996, 8589, 1029, 102],\n",
       " [101, 2984, 2003, 2411, 2770, 1996, 8589, 1012, 102],\n",
       " [101, 2984, 3216, 2411, 1996, 8589, 1012, 102],\n",
       " [101, 2984, 2003, 2025, 2770, 1996, 8589, 1012, 102],\n",
       " [101,\n",
       "  1045,\n",
       "  2134,\n",
       "  1005,\n",
       "  1056,\n",
       "  1010,\n",
       "  2004,\n",
       "  3021,\n",
       "  2018,\n",
       "  2245,\n",
       "  1010,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3573,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2106,\n",
       "  1010,\n",
       "  2004,\n",
       "  3021,\n",
       "  2018,\n",
       "  2245,\n",
       "  1010,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3573,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1045,\n",
       "  2106,\n",
       "  2025,\n",
       "  1010,\n",
       "  2004,\n",
       "  3021,\n",
       "  2018,\n",
       "  2245,\n",
       "  1010,\n",
       "  2175,\n",
       "  2000,\n",
       "  1996,\n",
       "  3573,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 4898, 2071, 2061, 2903, 1996, 2879, 1012, 102],\n",
       " [101, 1996, 4898, 2061, 3373, 1996, 2879, 1012, 102],\n",
       " [101, 1996, 4898, 2106, 2061, 2903, 1996, 2879, 1012, 102],\n",
       " [101, 1996, 4898, 2134, 1005, 1056, 2061, 2903, 1996, 2879, 1012, 102],\n",
       " [101, 4199, 3908, 21959, 1012, 102],\n",
       " [101, 4199, 1005, 1055, 6215, 1997, 21959, 2001, 23512, 1012, 102],\n",
       " [101, 2198, 4149, 1996, 3861, 1997, 2370, 2008, 3021, 2387, 1012, 102],\n",
       " [101, 1996, 10617, 1997, 1996, 3291, 2003, 3243, 16030, 1012, 102],\n",
       " [101, 1996, 3716, 1997, 1996, 3291, 2003, 3243, 16030, 1012, 102],\n",
       " [101, 1996, 3291, 1005, 1055, 10617, 2003, 3243, 16030, 1012, 102],\n",
       " [101, 1996, 3291, 1005, 1055, 3716, 2003, 3243, 16030, 1012, 102],\n",
       " [101, 1996, 3291, 4282, 4089, 1012, 102],\n",
       " [101, 1996, 2911, 7569, 2000, 8145, 1996, 5427, 1012, 102],\n",
       " [101, 1996, 10186, 1997, 1996, 2911, 2001, 2200, 14386, 3560, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  10186,\n",
       "  1997,\n",
       "  1996,\n",
       "  2911,\n",
       "  2000,\n",
       "  8145,\n",
       "  1996,\n",
       "  5427,\n",
       "  2001,\n",
       "  2200,\n",
       "  14386,\n",
       "  3560,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 2911, 1005, 1055, 10186, 2001, 2200, 14386, 3560, 1012, 102],\n",
       " [101,\n",
       "  1996,\n",
       "  2911,\n",
       "  1005,\n",
       "  1055,\n",
       "  10186,\n",
       "  2000,\n",
       "  8145,\n",
       "  1996,\n",
       "  5427,\n",
       "  2001,\n",
       "  2200,\n",
       "  14386,\n",
       "  3560,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  1996,\n",
       "  5604,\n",
       "  1997,\n",
       "  2107,\n",
       "  5850,\n",
       "  2006,\n",
       "  25763,\n",
       "  2003,\n",
       "  2205,\n",
       "  19188,\n",
       "  1012,\n",
       "  102],\n",
       " [101,\n",
       "  2023,\n",
       "  4319,\n",
       "  1005,\n",
       "  1055,\n",
       "  5604,\n",
       "  2006,\n",
       "  25763,\n",
       "  2003,\n",
       "  2205,\n",
       "  19188,\n",
       "  1012,\n",
       "  102],\n",
       " [101, 1996, 2911, 2001, 10417, 2000, 8145, 1996, 5427, 1012, 102],\n",
       " [101, 2023, 4319, 2442, 2034, 2022, 7718, 2006, 25763, 1012, 102],\n",
       " [101, 1996, 2343, 1005, 1055, 7191, 6215, 2003, 3143, 1012, 102],\n",
       " [101, 1996, 7191, 6215, 1997, 1996, 2343, 2001, 5121, 2025, 14044, 1012, 102],\n",
       " [101, 2984, 4122, 2000, 4929, 3835, 2630, 2446, 4377, 1012, 102],\n",
       " [101, 12851, 2020, 3107, 1999, 2885, 2044, 17332, 2475, 1012, 102],\n",
       " [101, 2057, 4138, 2031, 17727, 8586, 21170, 5510, 1012, 102],\n",
       " [101, 4138, 2057, 2031, 17727, 8586, 21170, 5510, 1012, 102],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#101å’Œ102æ˜¯ç‰¹æ®Šçš„èµ·å§‹å’Œç»ˆæ­¢ç¬¦å·ï¼Œè¡¨ç¤ºæ–‡æœ¬çš„å¼€å¤´[cls]å’Œç»“å°¾[sep]ã€‚å…¶ä»–æ•°å­—è¡¨ç¤ºæ–‡æœ¬ä¸­çš„å•è¯æˆ–å­è¯å¯¹åº”çš„ç¼–å·ã€‚\n",
    "max_len = 0\n",
    "input_id = []\n",
    "for sent in sentences:\n",
    "    input_ids = tokenizer.encode(sent,add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "    input_id .append(input_ids)\n",
    "print('max sentence len', max_len)\n",
    "\n",
    "input_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "1 Split the sentence into tokens.\n",
    "2 Add the special [CLS] and [SEP] tokens.\n",
    "3 Map the tokens to their IDs.\n",
    "4 Pad or truncate all sentences to the same length.\n",
    "5 Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids= []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    ecoded_dict = tokenizer.encode_plus(\n",
    "                                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    input_ids.append(ecoded_dict['input_ids'])\n",
    "    attention_masks.append(ecoded_dict['attention_mask'])\n",
    "\n",
    "#print(input_ids)\n",
    "#print(attention_masks)\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0]) #set the maximum length to 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Training & Validation Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide up our training set to use 90% for training and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,695 training samples\n",
      "  856 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset,random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size=32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train Our Classification Model\n",
    "\n",
    "4.1. BertForSequenceClassification\n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "\n",
    "BertModel\n",
    "BertForPreTraining\n",
    "BertForMaskedLM\n",
    "BertForNextSentencePrediction\n",
    "BertForSequenceClassification - The one we'll use.\n",
    "BertForTokenClassification\n",
    "BertForQuestionAnswering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using BertForSequenceClassification. This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printed out the names and dimensions of the weights for:\n",
    "\n",
    "\n",
    "1 The embedding layer.\n",
    "2 The first of the twelve transformers.\n",
    "3 The output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " recommend choosing from the following values\n",
    "\n",
    "\n",
    "Batch size: 16, 32\n",
    "Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "Number of epochs: 2, 3, 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size: 32 (set when creating our DataLoaders)\n",
    "Learning rate: 2e-5\n",
    "Epochs: 4 (we'll see that this is probably too many...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    #è¿™æ®µä»£ç ä½¿ç”¨äº†NumPyåº“ä¸­çš„argmaxå‡½æ•°æ¥èŽ·å–åœ¨predsçŸ©é˜µä¸­æ¯è¡Œä¸­æœ€å¤§å…ƒç´ çš„ç´¢å¼•ï¼Œ\n",
    "    # ç„¶åŽä½¿ç”¨flattenå‡½æ•°å°†å…¶å±•å¹³ä¸ºä¸€ç»´æ•°ç»„pred_flatã€‚å…·ä½“æ¥è¯´ï¼Œ\n",
    "    # argmaxå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°axisæŒ‡å®šäº†åœ¨å“ªä¸ªè½´å‘ä¸ŠæŸ¥æ‰¾æœ€å¤§å€¼ï¼Œ\n",
    "    # è¿™é‡Œè®¾ç½®ä¸º1è¡¨ç¤ºåœ¨æ¯è¡Œä¸­æŸ¥æ‰¾æœ€å¤§å€¼ã€‚å› æ­¤ï¼Œargmaxè¿”å›žä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼Œ\n",
    "    # å…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”è¡Œä¸­æœ€å¤§å…ƒç´ çš„ç´¢å¼•ã€‚\n",
    "    # ç„¶åŽï¼Œä½¿ç”¨flattenå‡½æ•°å°†äºŒç»´çš„argmaxæ•°ç»„å±•å¹³ä¸ºä¸€ç»´ï¼Œä»¥ä¾¿åŽç»­çš„å¤„ç†å’Œåˆ†æžã€‚\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kick off the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:19.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:37.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:56.\n",
      "  Batch   160  of    241.    Elapsed: 0:01:15.\n",
      "  Batch   200  of    241.    Elapsed: 0:01:35.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:54.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 0:01:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation Loss: 0.66\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:19.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:39.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:58.\n",
      "  Batch   160  of    241.    Elapsed: 0:01:17.\n",
      "  Batch   200  of    241.    Elapsed: 0:01:36.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:56.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:01:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation Loss: 0.66\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:19.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:39.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:58.\n",
      "  Batch   160  of    241.    Elapsed: 0:01:18.\n",
      "  Batch   200  of    241.    Elapsed: 0:01:37.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:56.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation Loss: 0.66\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:39.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:58.\n",
      "  Batch   160  of    241.    Elapsed: 0:01:18.\n",
      "  Batch   200  of    241.    Elapsed: 0:01:38.\n",
      "  Batch   240  of    241.    Elapsed: 0:01:57.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:01:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.82\n",
      "  Validation Loss: 0.66\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:08:04 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Training Loss': 0.0831904000220086,\n",
       "  'Valid. Loss': 0.6603913285114147,\n",
       "  'Valid. Accur.': 0.82445987654321,\n",
       "  'Training Time': '0:01:54',\n",
       "  'Validation Time': '0:00:05'},\n",
       " {'epoch': 2,\n",
       "  'Training Loss': 0.11231077240231249,\n",
       "  'Valid. Loss': 0.6603913285114147,\n",
       "  'Valid. Accur.': 0.82445987654321,\n",
       "  'Training Time': '0:01:56',\n",
       "  'Validation Time': '0:00:05'},\n",
       " {'epoch': 3,\n",
       "  'Training Loss': 0.10991361728363142,\n",
       "  'Valid. Loss': 0.6603913296152044,\n",
       "  'Valid. Accur.': 0.82445987654321,\n",
       "  'Training Time': '0:01:57',\n",
       "  'Validation Time': '0:00:05'},\n",
       " {'epoch': 4,\n",
       "  'Training Loss': 0.11490771080912149,\n",
       "  'Valid. Loss': 0.6603913185773073,\n",
       "  'Valid. Accur.': 0.82445987654321,\n",
       "  'Training Time': '0:01:57',\n",
       "  'Validation Time': '0:00:05'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0:01:54</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0:01:56</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0:01:57</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0:01:57</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.08         0.66           0.82       0:01:54         0:00:05\n",
       "2               0.11         0.66           0.82       0:01:56         0:00:05\n",
       "3               0.11         0.66           0.82       0:01:57         0:00:05\n",
       "4               0.11         0.66           0.82       0:01:57         0:00:05"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.è“è‰²åœ†å½¢ï¼Œç»¿è‰²åœ†å½¢\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Performance On Test Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/DELL/Desktop/cola_public/raw/out_of_domain_dev.tsv',delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32 \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. Evaluate on Test Set\n",
    "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "    DONE.\n",
      "[array([[-1.6245862 ,  1.6909013 ],\n",
      "       [-2.076171  ,  2.0534031 ],\n",
      "       [-2.4781494 ,  2.4372704 ],\n",
      "       [-2.1259592 ,  2.157166  ],\n",
      "       [-1.7303714 ,  1.8149956 ],\n",
      "       [-2.5833545 ,  2.497748  ],\n",
      "       [-0.7663958 ,  0.8694747 ],\n",
      "       [-1.6527071 ,  1.6872635 ],\n",
      "       [-2.4592803 ,  2.4063418 ],\n",
      "       [-2.5042977 ,  2.4651384 ],\n",
      "       [-0.7369052 ,  0.9151673 ],\n",
      "       [ 0.92674476, -0.7505584 ],\n",
      "       [-2.5608535 ,  2.513698  ],\n",
      "       [-0.71423686,  0.8423876 ],\n",
      "       [-1.8106947 ,  1.7950352 ],\n",
      "       [-1.640652  ,  1.6612793 ],\n",
      "       [-1.6444349 ,  1.704366  ],\n",
      "       [ 2.3374572 , -2.3082864 ],\n",
      "       [-2.194101  ,  2.2065647 ],\n",
      "       [-1.2966113 ,  1.4002564 ],\n",
      "       [-2.194101  ,  2.2065647 ],\n",
      "       [-1.1105722 ,  1.1990575 ],\n",
      "       [-1.547154  ,  1.6045339 ],\n",
      "       [-1.838447  ,  1.8685473 ],\n",
      "       [-1.3963268 ,  1.448772  ],\n",
      "       [-1.8942145 ,  1.9336442 ],\n",
      "       [-1.2811569 ,  1.3798242 ],\n",
      "       [-1.7643503 ,  1.8014096 ],\n",
      "       [-1.8877548 ,  1.9077989 ],\n",
      "       [-1.3758452 ,  1.457403  ],\n",
      "       [-1.45096   ,  1.5138352 ],\n",
      "       [-1.1632859 ,  1.2384373 ]], dtype=float32), array([[-1.3351134 ,  1.371009  ],\n",
      "       [-1.1192337 ,  1.2727584 ],\n",
      "       [-1.3081464 ,  1.4052001 ],\n",
      "       [-2.5544167 ,  2.4571848 ],\n",
      "       [-1.821933  ,  1.8096668 ],\n",
      "       [-2.08762   ,  2.0275857 ],\n",
      "       [-2.3068259 ,  2.3408182 ],\n",
      "       [-2.5817587 ,  2.5210464 ],\n",
      "       [-1.0743359 ,  1.1772845 ],\n",
      "       [-1.5254941 ,  1.5459862 ],\n",
      "       [-1.4452136 ,  1.4536543 ],\n",
      "       [ 0.86893487, -0.66343045],\n",
      "       [-1.7674257 ,  1.7600414 ],\n",
      "       [-1.4421926 ,  1.4893068 ],\n",
      "       [-1.1656723 ,  1.2581494 ],\n",
      "       [-0.04753058,  0.3586443 ],\n",
      "       [-1.3305988 ,  1.3951933 ],\n",
      "       [-2.4911191 ,  2.4336782 ],\n",
      "       [-1.9038146 ,  1.9130124 ],\n",
      "       [-1.4553657 ,  1.4682924 ],\n",
      "       [ 1.9964108 , -1.9317764 ],\n",
      "       [ 1.8960046 , -1.8198345 ],\n",
      "       [-2.3915243 ,  2.3146162 ],\n",
      "       [-2.5142565 ,  2.383952  ],\n",
      "       [-1.9520512 ,  1.9708121 ],\n",
      "       [-1.9520512 ,  1.9708121 ],\n",
      "       [-1.9250855 ,  1.9619007 ],\n",
      "       [-1.1551951 ,  1.2729167 ],\n",
      "       [-1.157342  ,  1.2130904 ],\n",
      "       [-1.7061981 ,  1.7428223 ],\n",
      "       [-1.1551951 ,  1.2729167 ],\n",
      "       [-2.0567894 ,  2.1193845 ]], dtype=float32), array([[-2.1566281 ,  2.1909225 ],\n",
      "       [-2.4062228 ,  2.353059  ],\n",
      "       [-2.3456352 ,  2.3537133 ],\n",
      "       [-2.217882  ,  2.2345252 ],\n",
      "       [-2.365985  ,  2.3098881 ],\n",
      "       [-1.8782643 ,  1.8832844 ],\n",
      "       [-0.82004786,  0.93923545],\n",
      "       [-1.479407  ,  1.5238682 ],\n",
      "       [-2.547     ,  2.5370092 ],\n",
      "       [-2.2135487 ,  2.1291406 ],\n",
      "       [-2.522238  ,  2.5142698 ],\n",
      "       [-2.1645002 ,  2.0952404 ],\n",
      "       [-1.0663666 ,  1.1778774 ],\n",
      "       [ 2.4516487 , -2.412033  ],\n",
      "       [-1.7653211 ,  1.7577125 ],\n",
      "       [-1.5047755 ,  1.5821626 ],\n",
      "       [-1.3384748 ,  1.4035196 ],\n",
      "       [ 1.5832647 , -1.4584485 ],\n",
      "       [-2.4043124 ,  2.359703  ],\n",
      "       [-2.5002434 ,  2.400882  ],\n",
      "       [-2.5114195 ,  2.4444067 ],\n",
      "       [-2.3865683 ,  2.2570605 ],\n",
      "       [ 2.5043414 , -2.5719082 ],\n",
      "       [ 1.0040512 , -0.80113876],\n",
      "       [-2.4117804 ,  2.39821   ],\n",
      "       [-2.2529812 ,  2.2268486 ],\n",
      "       [-2.5043638 ,  2.463911  ],\n",
      "       [ 2.4515862 , -2.4934142 ],\n",
      "       [ 0.8728315 , -0.6558918 ],\n",
      "       [ 2.520787  , -2.5688272 ],\n",
      "       [-2.0456707 ,  2.05003   ],\n",
      "       [ 2.4459188 , -2.523109  ]], dtype=float32), array([[-2.5021124e+00,  2.4318480e+00],\n",
      "       [ 2.5208502e+00, -2.5488603e+00],\n",
      "       [ 2.5002060e+00, -2.5326028e+00],\n",
      "       [-2.2064118e+00,  2.2008750e+00],\n",
      "       [-2.4897866e+00,  2.4178016e+00],\n",
      "       [-2.3374946e+00,  2.2757955e+00],\n",
      "       [-2.3907187e+00,  2.3326955e+00],\n",
      "       [-1.0722237e-01,  3.6361617e-01],\n",
      "       [-2.4278126e+00,  2.3818090e+00],\n",
      "       [-1.7845130e+00,  1.8367785e+00],\n",
      "       [-1.3502114e+00,  1.3533274e+00],\n",
      "       [-2.0162106e+00,  1.9819957e+00],\n",
      "       [-2.2926710e+00,  2.2681658e+00],\n",
      "       [-1.6397269e+00,  1.5669082e+00],\n",
      "       [-6.6824213e-02,  1.8208563e-01],\n",
      "       [-1.7572018e+00,  1.7159225e+00],\n",
      "       [-2.3304548e+00,  2.3064475e+00],\n",
      "       [-2.1453137e+00,  2.0954025e+00],\n",
      "       [-2.4402299e+00,  2.3446355e+00],\n",
      "       [-2.0910301e+00,  2.0535781e+00],\n",
      "       [-2.5080309e+00,  2.4326530e+00],\n",
      "       [ 1.5382357e-01,  9.1031067e-02],\n",
      "       [ 1.1276853e+00, -9.9070364e-01],\n",
      "       [-3.3651638e-01,  5.3941596e-01],\n",
      "       [-2.5152245e+00,  2.4240835e+00],\n",
      "       [-2.4866588e+00,  2.4192791e+00],\n",
      "       [-2.2375429e+00,  2.2059276e+00],\n",
      "       [-1.9925578e+00,  1.9990413e+00],\n",
      "       [ 1.6244576e+00, -1.5058258e+00],\n",
      "       [ 2.1383164e+00, -2.1130116e+00],\n",
      "       [-2.3646243e+00,  2.2942908e+00],\n",
      "       [ 1.9127420e-01, -2.4351797e-03]], dtype=float32), array([[-1.0204297 ,  1.0594138 ],\n",
      "       [-0.20041114,  0.46565127],\n",
      "       [-2.2700353 ,  2.2565439 ],\n",
      "       [-0.26579547,  0.41491067],\n",
      "       [-1.2563349 ,  1.3272499 ],\n",
      "       [-1.7354798 ,  1.7840492 ],\n",
      "       [ 0.69658697, -0.54101443],\n",
      "       [-2.453502  ,  2.3898294 ],\n",
      "       [-1.3785769 ,  1.393621  ],\n",
      "       [-1.5471575 ,  1.5492603 ],\n",
      "       [-1.5299183 ,  1.5246909 ],\n",
      "       [-2.52105   ,  2.4795783 ],\n",
      "       [-1.8368784 ,  1.6819245 ],\n",
      "       [-2.0912519 ,  2.1205332 ],\n",
      "       [-2.0795197 ,  2.1144092 ],\n",
      "       [-1.8219206 ,  1.8152114 ],\n",
      "       [-1.0422744 ,  1.0997328 ],\n",
      "       [ 1.1077946 , -0.9220108 ],\n",
      "       [-1.3994963 ,  1.4787366 ],\n",
      "       [-1.1415123 ,  1.276945  ],\n",
      "       [ 0.0645528 ,  0.13020793],\n",
      "       [ 0.7108418 , -0.5927579 ],\n",
      "       [-1.5103287 ,  1.5681318 ],\n",
      "       [-1.5386943 ,  1.534914  ],\n",
      "       [-1.8720661 ,  1.8707045 ],\n",
      "       [-2.4852793 ,  2.38817   ],\n",
      "       [-2.5216076 ,  2.4467518 ],\n",
      "       [-2.5355217 ,  2.4898784 ],\n",
      "       [-2.5680623 ,  2.4789526 ],\n",
      "       [-1.8684963 ,  1.8901572 ],\n",
      "       [ 1.2389553 , -1.0069562 ],\n",
      "       [-2.4579647 ,  2.4952085 ]], dtype=float32), array([[-1.1500126 ,  1.3074816 ],\n",
      "       [-2.4515352 ,  2.4577715 ],\n",
      "       [-2.3984165 ,  2.4200602 ],\n",
      "       [-1.6711534 ,  1.6852463 ],\n",
      "       [-2.323816  ,  2.330981  ],\n",
      "       [ 1.4700248 , -1.4048756 ],\n",
      "       [ 2.5578876 , -2.6378548 ],\n",
      "       [ 2.5750017 , -2.518079  ],\n",
      "       [ 2.3061419 , -2.2071104 ],\n",
      "       [ 1.9337614 , -1.795178  ],\n",
      "       [-2.493342  ,  2.4443505 ],\n",
      "       [-1.6168927 ,  1.6417091 ],\n",
      "       [-1.8432621 ,  1.8316369 ],\n",
      "       [ 2.6059725 , -2.5866542 ],\n",
      "       [-2.070157  ,  1.9975659 ],\n",
      "       [ 1.3722457 , -1.1625541 ],\n",
      "       [-2.1822479 ,  2.176914  ],\n",
      "       [-2.3408167 ,  2.2570503 ],\n",
      "       [-2.4312873 ,  2.3734114 ],\n",
      "       [-2.5513668 ,  2.4577453 ],\n",
      "       [ 2.4302576 , -2.4354696 ],\n",
      "       [ 2.5330918 , -2.5369437 ],\n",
      "       [ 1.3712153 , -1.2137748 ],\n",
      "       [-2.5503914 ,  2.5322447 ],\n",
      "       [-2.396346  ,  2.4305165 ],\n",
      "       [-2.4588768 ,  2.5004346 ],\n",
      "       [-2.3397832 ,  2.3628356 ],\n",
      "       [ 0.16419011,  0.05223664],\n",
      "       [-2.4861822 ,  2.4409223 ],\n",
      "       [-2.5448585 ,  2.5253348 ],\n",
      "       [-2.519619  ,  2.5339496 ],\n",
      "       [-1.3588539 ,  1.3830657 ]], dtype=float32), array([[-2.4905493 ,  2.4415617 ],\n",
      "       [ 2.3830695 , -2.3858578 ],\n",
      "       [-2.5360315 ,  2.5031908 ],\n",
      "       [-2.463229  ,  2.3942015 ],\n",
      "       [-1.8948196 ,  1.9654812 ],\n",
      "       [-2.4500597 ,  2.4671302 ],\n",
      "       [-1.7155464 ,  1.7666788 ],\n",
      "       [-2.2603827 ,  2.2876866 ],\n",
      "       [-2.2214446 ,  2.268573  ],\n",
      "       [-2.4336686 ,  2.3977406 ],\n",
      "       [-1.0120687 ,  1.078087  ],\n",
      "       [-1.8103565 ,  1.7934688 ],\n",
      "       [-2.1693819 ,  2.1875613 ],\n",
      "       [-2.377776  ,  2.2637928 ],\n",
      "       [-0.09531441,  0.28342482],\n",
      "       [-2.0572486 ,  2.0685341 ],\n",
      "       [-2.5017664 ,  2.432471  ],\n",
      "       [-2.5081177 ,  2.4544377 ],\n",
      "       [-2.2245889 ,  2.175715  ],\n",
      "       [-2.5122378 ,  2.4459534 ],\n",
      "       [-2.5304022 ,  2.461635  ],\n",
      "       [ 0.14337936,  0.1455183 ],\n",
      "       [-1.4681902 ,  1.4643037 ],\n",
      "       [-2.4272816 ,  2.3972218 ],\n",
      "       [-2.4122782 ,  2.4043803 ],\n",
      "       [-2.4703274 ,  2.428128  ],\n",
      "       [-2.4996622 ,  2.4441023 ],\n",
      "       [ 0.64060235, -0.37758702],\n",
      "       [-2.4413123 ,  2.4100168 ],\n",
      "       [-2.4767756 ,  2.4339237 ],\n",
      "       [ 1.4264778 , -1.2886497 ],\n",
      "       [-2.4674914 ,  2.466059  ]], dtype=float32), array([[-0.99868363,  1.1009935 ],\n",
      "       [-2.3868165 ,  2.2867708 ],\n",
      "       [-2.559575  ,  2.4720392 ],\n",
      "       [-2.157423  ,  2.1291285 ],\n",
      "       [-2.2685385 ,  2.2824671 ],\n",
      "       [-2.4537945 ,  2.4533684 ],\n",
      "       [ 0.2593118 ,  0.00348788],\n",
      "       [-2.4024093 ,  2.3827443 ],\n",
      "       [-2.4067903 ,  2.397037  ],\n",
      "       [-2.5849066 ,  2.4441001 ],\n",
      "       [-2.4547408 ,  2.4141276 ],\n",
      "       [-2.4433281 ,  2.4235718 ],\n",
      "       [-2.2453234 ,  2.2865498 ],\n",
      "       [-2.5119026 ,  2.4277923 ],\n",
      "       [-2.3892436 ,  2.3203664 ],\n",
      "       [-2.4837875 ,  2.4287412 ],\n",
      "       [-2.3464062 ,  2.2897387 ],\n",
      "       [-2.4085376 ,  2.4225194 ],\n",
      "       [-2.5147076 ,  2.441451  ],\n",
      "       [-2.545566  ,  2.4383366 ],\n",
      "       [-2.4591792 ,  2.306064  ],\n",
      "       [-2.4232528 ,  2.4269512 ],\n",
      "       [-1.5732524 ,  1.6313279 ],\n",
      "       [-2.551515  ,  2.4753654 ],\n",
      "       [-2.5164385 ,  2.4153857 ],\n",
      "       [-2.4803243 ,  2.461359  ],\n",
      "       [-2.2670076 ,  2.281731  ],\n",
      "       [-2.4834514 ,  2.3969364 ],\n",
      "       [ 0.30584913, -0.02726205],\n",
      "       [-1.963525  ,  1.8795283 ],\n",
      "       [-1.4455547 ,  1.3589954 ],\n",
      "       [-1.6380029 ,  1.5821034 ]], dtype=float32), array([[ 1.9099703 , -1.8488208 ],\n",
      "       [-2.10343   ,  2.12593   ],\n",
      "       [ 0.8156997 , -0.55382055],\n",
      "       [-2.5697007 ,  2.5085166 ],\n",
      "       [-0.42740262,  0.59874845],\n",
      "       [-1.6210895 ,  1.6277623 ],\n",
      "       [-2.4130528 ,  2.2689898 ],\n",
      "       [-2.5291452 ,  2.4220228 ],\n",
      "       [-2.5179741 ,  2.4259913 ],\n",
      "       [-2.5324242 ,  2.4393847 ],\n",
      "       [-2.5048273 ,  2.3909187 ],\n",
      "       [-2.5045795 ,  2.378229  ],\n",
      "       [-2.5309014 ,  2.413156  ],\n",
      "       [-2.462554  ,  2.3851047 ],\n",
      "       [-2.5132465 ,  2.4230523 ],\n",
      "       [-2.4666803 ,  2.4060366 ],\n",
      "       [-2.444093  ,  2.357456  ],\n",
      "       [-2.3649566 ,  2.3077571 ],\n",
      "       [-2.494027  ,  2.4187572 ],\n",
      "       [-2.3730173 ,  2.3018746 ],\n",
      "       [-2.5010505 ,  2.445813  ],\n",
      "       [-2.3099089 ,  2.2423856 ],\n",
      "       [-2.5226786 ,  2.501107  ],\n",
      "       [-1.815092  ,  1.8146074 ],\n",
      "       [-0.06462174,  0.33958334],\n",
      "       [-2.5400484 ,  2.4186542 ],\n",
      "       [ 2.324857  , -2.3054788 ],\n",
      "       [ 1.9726366 , -2.0415514 ],\n",
      "       [-2.5298288 ,  2.3616822 ],\n",
      "       [ 2.4672978 , -2.5244687 ],\n",
      "       [ 1.7024455 , -1.7408508 ],\n",
      "       [-2.1588182 ,  2.1842558 ]], dtype=float32), array([[ 1.9686285 , -1.9286941 ],\n",
      "       [-1.3143561 ,  1.3897139 ],\n",
      "       [-2.5232184 ,  2.4595335 ],\n",
      "       [ 2.2357805 , -2.2939308 ],\n",
      "       [ 2.5384822 , -2.574919  ],\n",
      "       [-2.4564571 ,  2.3947663 ],\n",
      "       [-2.4254556 ,  2.3512733 ],\n",
      "       [-2.4919248 ,  2.4340727 ],\n",
      "       [ 2.4260354 , -2.4785037 ],\n",
      "       [-1.2925442 ,  1.1990014 ],\n",
      "       [-2.4369407 ,  2.3162835 ],\n",
      "       [-2.4537237 ,  2.3933144 ],\n",
      "       [ 2.3202426 , -2.3906844 ],\n",
      "       [ 1.8419265 , -1.8238568 ],\n",
      "       [-1.0815547 ,  1.152647  ],\n",
      "       [-2.481568  ,  2.3651206 ],\n",
      "       [-2.3146324 ,  2.3020184 ],\n",
      "       [ 1.7053635 , -1.6417925 ],\n",
      "       [-2.5025272 ,  2.3979437 ],\n",
      "       [-2.2879856 ,  2.2411792 ],\n",
      "       [-2.5863588 ,  2.495549  ],\n",
      "       [ 2.0408785 , -1.9953452 ],\n",
      "       [-2.4766414 ,  2.4024634 ],\n",
      "       [-2.4740982 ,  2.3842306 ],\n",
      "       [-0.85527694,  0.8303395 ],\n",
      "       [-2.3987398 ,  2.3549182 ],\n",
      "       [-1.3472084 ,  1.3829038 ],\n",
      "       [-1.7438018 ,  1.7723808 ],\n",
      "       [-2.4090898 ,  2.369786  ],\n",
      "       [-0.99104935,  1.101848  ],\n",
      "       [-0.66556615,  0.8139404 ],\n",
      "       [-2.4493039 ,  2.3370168 ]], dtype=float32), array([[-2.5020788,  2.4211829],\n",
      "       [ 2.1833248, -2.1323898],\n",
      "       [-2.0430918,  2.0097795],\n",
      "       [ 2.472379 , -2.508325 ],\n",
      "       [-2.503734 ,  2.4787867],\n",
      "       [ 2.2217445, -2.163348 ],\n",
      "       [-2.4144793,  2.3447323],\n",
      "       [-2.4922879,  2.4326224],\n",
      "       [-2.395289 ,  2.3258712],\n",
      "       [-1.5525483,  1.5203419],\n",
      "       [-1.6890666,  1.660647 ],\n",
      "       [-2.5084174,  2.4099889],\n",
      "       [ 2.3519495, -2.4191692],\n",
      "       [ 1.2109307, -1.1044147],\n",
      "       [-2.5476177,  2.4323127],\n",
      "       [-2.2767627,  2.215791 ],\n",
      "       [-2.4793656,  2.4283373],\n",
      "       [-1.4525582,  1.5139177],\n",
      "       [-2.3871737,  2.3095868],\n",
      "       [-2.1200612,  2.1616092],\n",
      "       [-2.6169612,  2.4205737],\n",
      "       [ 2.1981633, -2.251197 ],\n",
      "       [ 1.9850576, -1.9667455],\n",
      "       [-1.2681463,  1.2123811],\n",
      "       [-2.4505262,  2.372473 ],\n",
      "       [-2.1359744,  2.1256561],\n",
      "       [-2.0392103,  2.049003 ],\n",
      "       [-2.590698 ,  2.5059168],\n",
      "       [-2.52252  ,  2.4674895],\n",
      "       [-2.5133073,  2.4194577],\n",
      "       [-1.4300132,  1.4796798],\n",
      "       [-2.6212356,  2.4913847]], dtype=float32), array([[-2.5051603 ,  2.401288  ],\n",
      "       [-1.0159405 ,  1.022436  ],\n",
      "       [-2.4564896 ,  2.4743984 ],\n",
      "       [-2.5601628 ,  2.4859326 ],\n",
      "       [-2.4342248 ,  2.4138415 ],\n",
      "       [-2.3685062 ,  2.322317  ],\n",
      "       [-2.5660512 ,  2.5341434 ],\n",
      "       [-2.470721  ,  2.378969  ],\n",
      "       [ 2.2629864 , -2.28963   ],\n",
      "       [-2.462252  ,  2.3868785 ],\n",
      "       [ 1.6447881 , -1.659545  ],\n",
      "       [ 0.27056062, -0.1579659 ],\n",
      "       [ 1.6353732 , -1.558037  ],\n",
      "       [-2.5560484 ,  2.4115465 ],\n",
      "       [-2.4496171 ,  2.3499248 ],\n",
      "       [-2.436134  ,  2.3348815 ],\n",
      "       [-2.3993769 ,  2.3213058 ],\n",
      "       [-2.0093133 ,  2.0443337 ],\n",
      "       [-0.46766356,  0.5077332 ],\n",
      "       [-2.1319158 ,  2.1326945 ],\n",
      "       [ 1.2911909 , -1.0879623 ],\n",
      "       [-2.2371542 ,  2.2367961 ],\n",
      "       [-2.4412506 ,  2.3865821 ],\n",
      "       [-2.3702796 ,  2.3124733 ],\n",
      "       [-2.5505636 ,  2.5342357 ],\n",
      "       [-2.273121  ,  2.3250055 ],\n",
      "       [-2.5796387 ,  2.4956107 ],\n",
      "       [ 2.4596925 , -2.4428825 ],\n",
      "       [ 2.46564   , -2.4354913 ],\n",
      "       [-2.4385393 ,  2.319161  ],\n",
      "       [-2.434903  ,  2.3331163 ],\n",
      "       [-2.4914691 ,  2.341242  ]], dtype=float32), array([[ 2.1367848 , -2.1289055 ],\n",
      "       [ 1.9920596 , -1.9247173 ],\n",
      "       [-1.2262744 ,  1.2580842 ],\n",
      "       [-2.572315  ,  2.5399148 ],\n",
      "       [ 1.751383  , -1.6816579 ],\n",
      "       [-2.4636009 ,  2.4198153 ],\n",
      "       [-2.2858229 ,  2.2539346 ],\n",
      "       [-2.4759436 ,  2.4180381 ],\n",
      "       [ 2.3473225 , -2.2992399 ],\n",
      "       [-2.452726  ,  2.3172119 ],\n",
      "       [ 1.2987285 , -1.2709398 ],\n",
      "       [ 2.4510639 , -2.4776194 ],\n",
      "       [-0.630681  ,  0.7031715 ],\n",
      "       [-2.468772  ,  2.3543155 ],\n",
      "       [-2.47726   ,  2.3647866 ],\n",
      "       [-0.23963758,  0.17694649],\n",
      "       [-2.4294221 ,  2.3919258 ],\n",
      "       [-2.4549005 ,  2.406223  ],\n",
      "       [-2.5273309 ,  2.406892  ],\n",
      "       [ 2.36299   , -2.4481993 ],\n",
      "       [-2.5074332 ,  2.4423742 ],\n",
      "       [-2.3626733 ,  2.3251467 ],\n",
      "       [-2.371854  ,  2.3080778 ],\n",
      "       [ 1.0920554 , -0.9438219 ],\n",
      "       [-2.453721  ,  2.3677611 ],\n",
      "       [-2.418655  ,  2.3856053 ],\n",
      "       [-2.5097985 ,  2.3904018 ],\n",
      "       [ 2.420096  , -2.4447196 ],\n",
      "       [ 1.719556  , -1.6399854 ],\n",
      "       [-2.536521  ,  2.4478185 ],\n",
      "       [-2.4931383 ,  2.376063  ],\n",
      "       [-2.3719537 ,  2.3007205 ]], dtype=float32), array([[-2.285349  ,  2.3062904 ],\n",
      "       [-2.1884851 ,  2.1950872 ],\n",
      "       [-2.587551  ,  2.5299048 ],\n",
      "       [-2.4413211 ,  2.4077353 ],\n",
      "       [ 2.4507937 , -2.5054455 ],\n",
      "       [ 2.4898021 , -2.512142  ],\n",
      "       [-2.4999218 ,  2.3825169 ],\n",
      "       [-2.4470725 ,  2.3637218 ],\n",
      "       [-2.5657692 ,  2.4904513 ],\n",
      "       [-2.524794  ,  2.4612148 ],\n",
      "       [-2.5411923 ,  2.5376818 ],\n",
      "       [-1.7635074 ,  1.8215026 ],\n",
      "       [-2.396584  ,  2.3746707 ],\n",
      "       [-0.7931899 ,  0.83324087],\n",
      "       [-2.3909035 ,  2.2781718 ],\n",
      "       [-2.4050136 ,  2.3334687 ],\n",
      "       [-2.5255678 ,  2.482548  ],\n",
      "       [-2.3878255 ,  2.3042784 ],\n",
      "       [-2.4003184 ,  2.2975178 ],\n",
      "       [-2.260112  ,  2.2055886 ],\n",
      "       [ 2.6022954 , -2.652036  ],\n",
      "       [-0.9144218 ,  0.9819165 ],\n",
      "       [-2.4088523 ,  2.2872107 ],\n",
      "       [-2.5139225 ,  2.4560635 ],\n",
      "       [-0.5762545 ,  0.59955305],\n",
      "       [ 1.7033477 , -1.555945  ],\n",
      "       [-2.2311518 ,  2.2056167 ],\n",
      "       [-2.38571   ,  2.2941048 ],\n",
      "       [-2.4588478 ,  2.4532135 ],\n",
      "       [ 2.431796  , -2.3788183 ],\n",
      "       [ 2.6024592 , -2.6729395 ],\n",
      "       [ 2.5879576 , -2.6538227 ]], dtype=float32), array([[-2.4947917 ,  2.4647217 ],\n",
      "       [-2.5293257 ,  2.4140685 ],\n",
      "       [-2.4781892 ,  2.3888314 ],\n",
      "       [-2.5327063 ,  2.3757226 ],\n",
      "       [ 1.7038388 , -1.644483  ],\n",
      "       [-2.4724119 ,  2.4067442 ],\n",
      "       [-2.3480594 ,  2.266757  ],\n",
      "       [-2.4652102 ,  2.4539602 ],\n",
      "       [-2.541971  ,  2.5508344 ],\n",
      "       [-2.6016955 ,  2.5827188 ],\n",
      "       [ 2.3076782 , -2.2751055 ],\n",
      "       [-2.6022053 ,  2.580222  ],\n",
      "       [-2.4463832 ,  2.3498385 ],\n",
      "       [-2.5527952 ,  2.4193494 ],\n",
      "       [-2.5770805 ,  2.483435  ],\n",
      "       [-2.3835971 ,  2.2950666 ],\n",
      "       [-1.9558575 ,  1.9361445 ],\n",
      "       [ 2.553165  , -2.5749705 ],\n",
      "       [-2.5207784 ,  2.4742627 ],\n",
      "       [-2.386135  ,  2.3061533 ],\n",
      "       [-2.5296652 ,  2.503673  ],\n",
      "       [-2.5543842 ,  2.4725018 ],\n",
      "       [-2.442164  ,  2.3094318 ],\n",
      "       [-2.4891288 ,  2.4230554 ],\n",
      "       [ 1.9236301 , -1.8874724 ],\n",
      "       [-0.34913346,  0.33645475],\n",
      "       [ 1.970589  , -1.9069642 ],\n",
      "       [-2.4394553 ,  2.4940603 ],\n",
      "       [-2.3262482 ,  2.2420065 ],\n",
      "       [ 1.3539661 , -1.2215198 ],\n",
      "       [-2.4144437 ,  2.3279202 ],\n",
      "       [-2.4469697 ,  2.3996875 ]], dtype=float32), array([[-1.6538209 ,  1.6800531 ],\n",
      "       [-2.348857  ,  2.3349364 ],\n",
      "       [-1.782829  ,  1.7711589 ],\n",
      "       [-2.3250892 ,  2.3312414 ],\n",
      "       [-2.4285388 ,  2.3572574 ],\n",
      "       [ 2.4335115 , -2.3657668 ],\n",
      "       [-1.0443436 ,  0.97830474],\n",
      "       [-1.4568049 ,  1.4166692 ],\n",
      "       [-2.3069825 ,  2.2875054 ],\n",
      "       [ 1.0242671 , -0.92396843],\n",
      "       [ 0.1381196 , -0.08800765],\n",
      "       [-2.555293  ,  2.459485  ],\n",
      "       [-2.207567  ,  2.2618496 ],\n",
      "       [ 2.6264176 , -2.6268222 ],\n",
      "       [-2.4009595 ,  2.3812382 ],\n",
      "       [-2.4312127 ,  2.368969  ],\n",
      "       [-2.006804  ,  1.9849011 ],\n",
      "       [-2.4564543 ,  2.4597883 ],\n",
      "       [ 1.2278799 , -1.1206796 ],\n",
      "       [-2.4827902 ,  2.4237373 ],\n",
      "       [-2.5587971 ,  2.4780872 ],\n",
      "       [-0.6797764 ,  0.7156377 ],\n",
      "       [-2.6227055 ,  2.5390766 ],\n",
      "       [-1.4183095 ,  1.4439906 ],\n",
      "       [ 0.71012425, -0.5898335 ],\n",
      "       [-1.7482442 ,  1.732767  ],\n",
      "       [-2.467086  ,  2.3732364 ],\n",
      "       [-2.37418   ,  2.3223088 ],\n",
      "       [-2.402548  ,  2.3524153 ],\n",
      "       [-2.2834394 ,  2.2417316 ],\n",
      "       [-2.066649  ,  2.0091069 ],\n",
      "       [-2.5200887 ,  2.3635433 ]], dtype=float32), array([[-2.5495162,  2.3969214],\n",
      "       [-2.4147885,  2.354276 ],\n",
      "       [-2.430902 ,  2.370263 ],\n",
      "       [-2.526484 ,  2.473145 ]], dtype=float32)]\n",
      "[array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64), array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1], dtype=int64), array([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0], dtype=int64), array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1], dtype=int64), array([1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1], dtype=int64), array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0], dtype=int64), array([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1], dtype=int64), array([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64), array([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1], dtype=int64), array([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1], dtype=int64), array([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64), array([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1], dtype=int64), array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1], dtype=int64), array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int64), array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=int64), array([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64), array([1, 0, 1, 1], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    b_input_ids,b_input_mask,b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "        result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "print(predictions)\n",
    "print(true_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use MCC here because the classes are imbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:870: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAGXCAYAAAAK8R4aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABTUUlEQVR4nO3de3yO9ePH8fc2O2jTmEhsZpHTHJvDlzmfDyFTzflYKEW0msnPt4MwyTHfSo5zDpHTlBGK+goRpZWGjcphM9mw4/X7w2/3z20Hw7b7Yq/n47HHwz7X4fPejd3vXfvc121nGIYhAAAAAKZjb+sAAAAAALJGWQcAAABMirIOAAAAmBRlHQAAADApyjoAAABgUpR1AAAAwKQo6wAKpbFjx6pKlSqqVq2a4uList2va9euqlKlisaOHZtpW0JCghYuXKiAgAD5+fmpTp06euaZZ7R69Wqlp6dneb67OeZWycnJmjdvnrp27ao6deroySefVEBAgObNm6ekpKTcPQDQnDlzVKVKFasPX19fNW3aVMHBwfr777/v+tzJyck6d+7cXeU5c+bMXc8L4MFTxNYBAMCW0tPT9fXXX6tHjx6ZtsXExCgyMjLL46KiovTiiy/q7Nmz6tKli3r06KGkpCTt2LFDEyZM0A8//KD3339fdnZ293TMrVJTUzVkyBAdPnxYTz/9tAIDA5WWlqYDBw5o+vTp2rlzp8LCwuTk5HTvD04hMXz4cD3++OOSbpTsM2fOaNWqVTp48KA2bNggNze3Ozrf2bNnNXjwYA0bNkwBAQH5ERlAIUJZB1CoeXp6aseOHVmW9YiICHl4eGS68p6UlKSXXnpJ8fHxWrt2rapWrWrZNnjwYL399ttasWKFatWqpf79+9/1MVkJDw/X/v37NWfOHLVr184y3r9/f82fP1/vv/++1q5dq969e9/1Y1LYNG7cWA0bNrQae/LJJzV06FBt2LBBffv2vaPznTlzRqdOncrDhAAKM5bBACjUWrdurX379un69euZtm3fvl2tWrXKNL5ixQqdPHlSISEhVqU7Q3BwsNzd3bVq1ap7OiYrP/74oyTJ398/07Y+ffrI0dFRhw8fzvEcuL1//etfkqQTJ07YOAmAwo6yDqBQa9Omja5du6Z9+/ZZjcfGxurHH3+0unqdYcuWLXrooYfUuXPnLM/p4uKizz77TBs2bLinY7Li6uoqSVq9enWmbUWLFtWhQ4c0depUq/E//vhDo0aNUsOGDeXn56d+/frpwIEDVvtERkbqpZdeUr169VSrVi0999xzioiIsNqnX79+GjJkiGbMmKG6deuqUaNGlmVCJ06c0IgRI1SvXj3Vrl1bPXv21DfffJPj15JxzoEDB2rnzp3q1KmTatWqpaefflpffvllpn1zM0dOGe/EX3/9JUny8vKyGv/uu+/0/PPPq2HDhpb17RMmTNA///wjSfr8888tvxkJCQlRlSpVLMcmJCRo0qRJatGihWrXrq0uXbpozZo1meaOjo7W8OHDVbduXTVo0EBjx45VfHz8HX8NAB4MlHUAhZqfn59KlCihHTt2WI3v2LFDRYsWVaNGjazGDcPQ8ePHVaNGDTk6OmZ73goVKljWjd/NMdnp2rWrHB0dFRoaqqeeekozZ87Uf//7XyUnJ0tSpuNPnTql5557Tt9//7369u2rMWPGKD4+XoMGDdJPP/0kSfrpp58UGBion376SYMGDdKYMWOUkpKiESNGaPny5VbnO3TokLZs2aLXX39d3bt3V6VKlRQZGanAwECdOHFCw4YN0+jRo5WamqqhQ4dq69atOX490o0fJkaOHKn69esrKChI9vb2GjlypDZt2mTZ507myCpjTq5cuaK4uDjFxcXpwoULOnTokMaOHauyZctaLY/69ttvNXjwYF27dk0jR47Um2++qVq1amn16tWaPHmyJKl+/foaPny4JCkwMNDyg1NycrL69OmjZcuWqUWLFgoJCZGnp6fGjx+vsLAwqzwvvfSSXF1dNXbsWLVs2VLr16/XuHHjbvs4AnhAGQBQCAUHBxuVK1c2DMMwxo4dazRq1MhIS0uzbH/++eeN0aNHG4ZhGJUrVzaCg4MNwzCM2NhYo3LlypZtuXE3x+Tk66+/Nho1amRUrlzZ8lGnTh1jzJgxRlRUlNW+o0aNMmrVqmWcOnXKMhYXF2f4+fkZI0eONAzDMJ599lmjTp06xl9//WXZ5/r160b37t2NWrVqGbGxsYZhGEbfvn2NypUrG99//73VHH379jXatGljJCYmWsZSUlKM3r17G40bNzaSkpKy/Voyzrlo0SLL2LVr14y2bdsaTZo0sfyd5HaO7DJmZfbs2VaP4c0fVatWNbZv3261/5AhQ4yWLVtm+nqee+45o27dupbPv//+e6Ny5crGunXrLGPLly83KleubGzcuNEylp6ebvTu3dvw9/c3UlNTLXneffddq/P369fP8PX1zfFxBPDg4so6gEKvdevWio2Ntaz1TkhI0Hfffac2bdpk2tfe/sa3zbS0tFyf/26OyUmLFi309ddfa8aMGerWrZtKlSqlq1evavPmzerWrZv2798v6cadbnbv3q3mzZvL29vbcnyJEiW0YsUKjR8/XhcvXtSRI0fUrVs3lSlTxrKPs7OzhgwZouvXr1stEXJxcVH9+vUtn1+6dEn79+9X8+bNdf36dcsV6n/++Udt27bVxYsXdfTo0Ry/nmLFilm9INbFxUW9evXS+fPndezYsTue49aMtxMcHKxFixZp0aJF+vTTTzVx4kTVrl1bL7/8stavX2/Z75NPPtG6deusfntx6dIlubm56erVqznOsWvXLnl4eOipp56yjNnZ2Wnq1Klavny55d+IJKt9JKlmzZpKSUnRpUuXcv01AXhwcDcYAIVekyZNVLRoUe3cuVNPPvmkdu/eLXt7ezVv3jzTvu7u7nJ0dMzx3ux5ccztODs7q1OnTurUqZMk6eeff9bChQu1efNm/fvf/1Z4eLji4+N19epVq6KeoXLlypKkI0eOSJJ8fHwy7VOxYkVJ0p9//mkZK168uFWxjImJkSQtXbpUS5cuzTJrxvrv7JQvXz7T8p2MzGfPnrWM5XaOWzPejq+vb6a7wXTt2lVdunTRlClT1LFjR7m4uMjBwUExMTGaNWuWTpw4oejo6FzfS/3s2bMqX758pttylitXLtO+JUuWtPrcxcVFkpSSkpLrrwnAg4OyDqDQc3FxUePGjbVjxw4FBQVp+/btaty4seXFnDezs7NT3bp1dezYMaWmpqpIkay/jc6YMUMxMTEKCQlRqVKl7uqYW129elWffPKJfH19M73w1dfXVx988IH++ecf7dmzR5cuXbJcyc+puBqGke22jDdpunmdvYODg9U+GXP06dMny99ESLrtmvGs1vFnzO3g4HDHc9ya8W44OzurZcuWWrx4saKiolS9enWtWrVK//73v+Xj46N69eqpXbt2ql27tpYuXWq1vj4raWlpOd4//2a53Q9A4UBZBwDduCtMSEiIfvvtN+3Zs0dvvvlmtvu2bdtW+/fv19atW9W1a9dM269fv661a9cqLS1NxYsXv+tjbuXs7KwFCxaobt26Wd6lRrpRWr/55hu5uLjI0dFRLi4uOn36dKb9FixYoIsXL2rw4MGSbrxh061OnjwpSVbLY26VcWXYwcFBjRs3ttp24sQJnTlzRkWLFs32eOnGfckNw7AqqRn3Kff29laJEiXueY67kfEDg729vZKSkjRlyhQ1bNhQCxcutPqBa9asWbc9V9myZbO8K83u3bu1detWvf7663kXHMADhTXrACCpZcuWcnBwUGhoqK5fv57l/dUzBAYGqly5cgoNDdVvv/1mtS0tLU1vvfWWLl68qBdeeMFy1fhujrmVg4ODOnXqpP379+uLL77ItD0+Pl5ffvmlGjdurKJFi6pIkSLy9/fX7t27rZaJXL58WQsWLFB0dLRKlSqlGjVqaOPGjfr7778t+yQnJ2vRokVycnLK8p7uGUqXLq0aNWpo/fr1VktCUlJSNG7cOI0cOVKpqanZHi9JFy9eVHh4uOXza9euaeXKlapQoYKqVKmSJ3PcqevXr2vHjh3y8PBQpUqVdP36dV27dk0VKlSwKurHjx+3vEYgI0PGlf2Msi9JzZo108WLF7V9+3areZYsWaJdu3ZZfiABgFtxZR0AdONFl35+fvr222/VsGHDHMuTs7OzPvzwQw0ePFjPPPOMunTpopo1ayo+Pl7btm3T8ePH1aFDBw0aNOiejsnK2LFj9dNPP+mNN97Qxo0b1bRpU7m5uSk6Olqff/65UlJSNGHCBMv+r732mp599lk9++yz6tOnj9zc3PTZZ5/p6tWrevXVVyVJ48eP14ABA/TMM8+oV69ecnV11caNG/Xzzz9r/Pjxevjhh3PMlHF8jx491KtXLxUvXlxbtmzRkSNH9Nprr922iDo6OiokJEQ///yzSpcurXXr1uncuXP6+OOP82yOnOzbt8/qB5W4uDitW7dOZ8+e1TvvvKMiRYrI3d1dtWvX1ueffy43Nzf5+Pjo999/15o1ayzLjBITE+Xu7m7JsnHjRhmGoe7du6tnz55at26dRo8erT59+sjHx0e7du3S3r17NWnSpDxZugPgwURZB4D/07p1a+3fvz/bJSY3q169ur744gstXrxYe/bs0datW2UYhqpUqaJJkyYpICAg09rjuznmVh4eHvr888+1ePFi7dixQ3PnztW1a9dUunRptWvXTsOHD1fp0qUt+1esWFGrV6/W9OnTNX/+fNnb26tWrVoKDQ3VE088IUmqW7euVq5cqdmzZ2vhwoVKT09X1apVNXfu3GzXiN8s4/g5c+Zo0aJFSk1NlY+Pj6ZMmaLu3bvf9vjSpUtr3LhxCg0N1YULF+Tr66tFixZZ3dHlXufIyc0/FNjb26tYsWKqWrWqZs2apQ4dOli2zZo1S5MnT9a6deuUnJyscuXKaejQoapYsaJeeeUVff/992rfvr0qVqyofv366fPPP9fRo0fVsGFDlS9fXkuXLtXMmTO1ZcsWXblyRRUrVtTMmTPVsWPHe8oP4MFmZ+T06iIAAPJRv379dPbsWe3cudPWUQDAlFizDgAAAJgUZR0AAAAwKco6AAAAYFKsWQcAAABMiivrAAAAgElR1gEAAACT4j7rt3HpUqLS01kpBAAAgPxhb2+nEiVcs9xGWb+N9HSDsg4AAACbYBkMAAAAYFKUdQAAAMCkKOsAAACASVHWAQAAAJOirAMAAAAmRVkHAAAATIqyDgAAAJgUZR0AAAAwKco6AAAAYFKUdQAAAMCkKOsAAACASVHWAQAAAJMqYusAAAA8KIoVLyoXR9s8tV5PSdWV+Gs2mRtA/qGsAwCQR1wci6j7uq9tMvf6Hi11xSYzA8hPLIMBAAAATIqyDgAAAJgUy2AAAFaKFXeRi6Ojzea/npKiK/HXbTY/AJgJZR0AYMXF0VFPrVtgs/k39xiiK6KsA4DEMhgAAADAtO6Lsr5582Z17txZtWrVUseOHbVhw4Yc94+Li1NISIiaNGmiBg0aaNiwYTp16lSBZAUAAADyiunLenh4uIKCguTv76+5c+eqQYMGCg4O1rZt27Lc3zAMjRgxQnv27FFQUJCmTp2qCxcuqH///rp8+XIBpwcAAADununXrE+fPl0dO3bUuHHjJElNmzbV5cuXNWvWLHXo0CHT/qdOndKhQ4cUGhqqp59+WpJUsWJFtWnTRjt37lT37t0LMj4AAMgF9+KucnK0zTXE5JR0XY5PtMncwO2YuqzHxMQoOjpaY8aMsRpv3769wsPDFRMTIy8vL6ttSUlJkiRXV1fLmLu7uyQpPj4+fwMDAIC74uRor3mfn7fJ3EMDSttkXiA3TL0MJioqSpLk4+NjNe7t7S1JOnnyZKZjqlatqoYNG2ru3Ln6448/FBcXp4kTJ+qhhx5SmzZt8j80AAAAkEdMfWX9ypUbb5zs5uZmNZ5x1TwhISHL49566y09//zz6tSpkyTJyclJc+fOzXQVHgAAADAzU5d1wzAkSXZ2dlmO29tn/sXAH3/8oZ49e6p8+fIaN26cXFxc9Nlnn2nkyJGaP3++6tWrd0cZSpZ0u/1OAIA8VapUMVtHuC/xuN09HjuYlanLerFiN/7j3HoFPTEx0Wr7zRYvXixJWrhwoWWtur+/v3r37q1Jkybp888/v6MMsbEJSk837jQ6ANy3zFBaLly4YusId8XWj939+rhJPHYo3Ozt7bK9QGzqNesZa9Wjo6Otxk+fPm21/WZ//vmnKlasaCnq0o0r835+fjpx4kQ+pgUAAADylqnLure3tzw9PTPdU/2rr75ShQoVVLZs2UzH+Pj46Pfff890T/UjR46oXLly+ZoXAAAAyEumXgYjSSNGjFBISIjc3d3VokUL7dy5U+Hh4ZoxY4akG+9WGh0drUqVKsnNzU0DBw7Uxo0bNWTIEA0dOlQuLi764osvtH//fssxAAAAwP3A9GU9ICBAycnJWrhwodasWSMvLy+FhoZa7vSya9cuhYSEKCwsTA0bNpSnp6dWrlyp999/X2PHjpW9vb0qV66sRYsWqXHjxjb+agAAAIDcM31Zl6SePXuqZ8+eWW4LCAhQQECA1VjFihX18ccfF0Q0AAAAIN+Yes06AAAAUJhR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgEndF+9gCsCc3Is7ysnRxSZzJ6dc1+X4FJvMDdyPihV/SC6ODjab/3pKmq7EX7XZ/MD9irIO4K45Obpo4ur2Npl7fOCXkijrQG65ODoocN1vNpt/dY/KumKz2YH7F8tgAAAAAJOirAMAAAAmRVkHAAAATIqyDgAAAJgUZR0AAAAwKco6AAAAYFLcuhEAACAHxYu7ytHRdtc3U1LSFR+faLP5YVuUdQAAgBw4Otpr5/ILNpu/VZ9SNpsbtscyGAAAAMCkKOsAAACASVHWAQAAAJOirAMAAAAmRVkHAAAATIqyDgAAAJgUZR0AAAAwKco6AAAAYFKUdQAAAMCkKOsAAACASVHWAQAAAJOirAMAAAAmRVkHAAAATIqyDgAAAJgUZR0AAAAwKco6AAAAYFKUdQAAAMCkKOsAAACASVHWAQAAAJOirAMAAAAmRVkHAAAATIqyDgAAAJgUZR0AAAAwKco6AAAAYFJ3XNZTUlJ05swZHT16VL/88ovOnTuntLS0/MhmsXnzZnXu3Fm1atVSx44dtWHDhhz3T09P10cffaTWrVurVq1a6tKli7Zs2ZKvGQEAAIC8ViQ3O126dElr1qzR7t27dfToUaWkpFhtd3JyUr169dSsWTN16dJFHh4eeRYwPDxcQUFB6t+/v5o2baqIiAgFBwfLxcVFHTp0yPKYSZMmafXq1RozZoyqVq2qLVu26LXXXpObm5uaN2+eZ9kAAAWvWPGicnHM1dNXnruekqor8ddsMjeAwinH73YXL17UzJkztWnTJqWmpqpWrVoKCAiQl5eX3NzclJ6ervj4eP399986cuSIpk6dqhkzZqhbt2568cUXVaZMmXsOOH36dHXs2FHjxo2TJDVt2lSXL1/WrFmzsizr0dHRWr58ud555x09++yzkqRGjRrp1KlT+uabbyjrAHCfc3Esoi5r19lk7k3P9NAVm8wMoLDKtqwvW7ZMM2fOVM2aNTVhwgS1atVKJUqUyPFkV65cUXh4uL744gt17txZr776qvr163fX4WJiYhQdHa0xY8ZYjbdv317h4eGKiYmRl5eX1baIiAi5uLjo6aefzvT1AAAAAPeTbNes79ixQwsXLtSiRYvUo0eP2xZ1SSpWrJiee+45LV++XJ988om2b99+T+GioqIkST4+Plbj3t7ekqSTJ09mOiYyMlI+Pj7at2+funbtqurVq6tdu3baunXrPWUBAAAAClq2V9YXLVp0TyeuV6+ewsLC7ukcV67c+GWjm5ub1birq6skKSEhIdMxcXFx+uuvvzRu3DiNGjVKnp6eWrNmjUaPHi0PDw/961//uqdMAAAAQEGxzSt0cskwDEmSnZ1dluP29pl/MZCSkqK4uDh9/PHHatmypaQba9ajoqL04Ycf3nFZL1nS7fY7AbCJUqWK2ToC8omZ/27JdvfMnM/M2STz50P+MXVZL1bsxj/MW6+gJyYmWm2/maurqxwcHOTv728Zs7OzU+PGjbV27do7zhAbm6D0dOOOjwMKA1s/eVy4wEv98oOt/16lnP9ubZ2PbHfPzPnMnE3i+92Dzt7eLtsLxKZ+U6SMterR0dFW46dPn7bafjNvb2+lp6crNTXVajwlJSXTFXoAAADAzLK9sh4SEnLHJ7Ozs9OkSZPuKdDNvL295enpqW3btqlt27aW8a+++koVKlRQ2bJlMx3TtGlTLViwQOHh4erRo4ckKTU1Vd988438/PzyLBsAAACQ37It6+fOndO+fftkZ2dnWSN+O3ld1iVpxIgRCgkJkbu7u1q0aKGdO3cqPDxcM2bMkHTjBaXR0dGqVKmS3Nzc1KhRIzVv3lwTJ07U1atXVaFCBa1YsUJnz57VBx98kKfZAAAAgPyUbVlfuHChZs2apY8++kjDhg3T6NGjCzKXRUBAgJKTk7Vw4UKtWbNGXl5eCg0NVadOnSRJu3btUkhIiMLCwtSwYUNJ0uzZszVr1izNmzdPly9fVvXq1bVw4ULVqFHDJl8DAAAAcDdyfIHpqFGjFBcXp08//VT+/v5q0KBBQeWy0rNnT/Xs2TPLbQEBAQoICLAac3FxUXBwsIKDgwsiHgAAAJAvbvsC0zfffFNlypTRe++9VxB5AAAAAPyf29660cnJSatWrVJcXJzS0tLk4OBQELkAAACAQi9X91kvXbq0Spcund9ZAAAAANzE1PdZBwAAAAqzOy7r//zzj1q3bq0ff/wxP/IAAAAA+D93XNbT0tJ09uxZXb9+PT/yAAAAAPg/LIMBAAAATCpXLzDdsGGD5c+JiYmSpL179+rcuXOW8aeffjpPgwEAAACFXa7K+tixYzONzZ8/3/JnOzs7yjoAAACQx3JV1nfs2GH58+XLlxUQEKBp06apbt26+RYMAAAAKOxyVdbLlStn+fNDDz0kSSpZsqTVOAAAAIC8xQtMAQAAAJO647Lu7Oys7t27846mAAAAQD7L1TKYmz300EOaPHlyfmQBAAAAcJM7LusACpZ7cUc5ObrYZO7klOu6HJ9ik7kBAABlHTA9J0cXLVzSziZzDx7wlSTKOgAAtsILTAEAAACToqwDAAAAJkVZBwAAAEzqjtesf/PNN4qIiNCff/4pR0dHPfbYY2rZsqWaNGmSH/kAAACAQivXZT09PV1BQUEKDw+XYRh6+OGHlZ6eroSEBK1YsULt2rXTzJkzZWdnl595AQAAgEIj18tg5s+fr61bt6pXr1769ttvtX//fh04cEDffvut+vbtqy+//FJLlizJz6wAAABAoZLrK+uff/652rRpowkTJliNP/LII3rzzTf1999/a+3atRo4cGBeZwQAAMB9yMP9ITk4Odhk7rTkNMVdvmqTufNSrsv62bNnNWDAgGy3N2rUSHv27MmTUAAAALj/OTg56O/pP9tk7jJjfG0yb17L9TKYEiVK6NSpU9luP3XqlIoVK5YXmQAAAADoDsp6q1attHLlSu3cuTPTth07dmjVqlVq1apVnoYDAAAACrNcL4N59dVX9d1332nEiBGqWLGifHx8JElRUVGKiopSuXLl9Oqrr+ZXTgAAAKDQyfWV9eLFi2vNmjUaMmSIDMPQnj17tHv3bqWnp2vQoEFat26dPDw88jMrAAAAUKjc0ZsiPfzwwwoKClJQUFCmbenp6YqJiZGXl1eehQMAAAAKs1xfWa9WrZo2b96c7fbPP/9cTz/9dF5kAgAAAKAcrqyfO3dO3333neVzwzD0ww8/KDU1NdO+6enp2rRpE+9eCgAAAOShbMu6h4eHPv74Y8vtGu3s7LR69WqtXr0625P169cvzwMCAAAAhVW2Zd3R0VELFy7UmTNnZBiGBgwYoGHDhsnf3z/Tvvb29vLw8NDjjz+er2EBAACAwiTHF5iWLVtWZcuWlSRNnjxZ9evXl6enZ4EEAwAAAAq7XN8Npnv37vmZAwAAAMAtcn03GAAAAAAFi7IOAAAAmBRlHQAAADApyjoAAABgUpR1AAAAwKQo6wAAAIBJUdYBAAAAk8r2PutVq1aVnZ3dHZ3Mzs5Ov/zyyz2HutXmzZv10UcfKSYmRuXKldOwYcP09NNP5+rYv/76S0899ZSGDBmil156Kc+zAQAAAPkl27I+depUvf3227p69aoaN26s0qVLF2Qui/DwcAUFBal///5q2rSpIiIiFBwcLBcXF3Xo0CHHYw3D0Lhx45SQkFBAaQEAAIC8k21Z79q1q5544gn169dPly9f1ieffKIiRXL9hqd5Zvr06erYsaPGjRsnSWratKkuX76sWbNm3basr1ixQlFRUQURE4DJFCvuJBdHZ5vNfz0lSVfik202PwDgwZBj+65WrZqmTJmil19+WfPnz9fw4cMLKpckKSYmRtHR0RozZozVePv27RUeHq6YmBh5eXlle+y0adM0a9YsvfDCCwURF4CJuDg6q+MXvWw2f3i3lboiyjoA4N7c9gWmbdq00XPPPae9e/cqNTW1IDJZZFwV9/HxsRr39vaWJJ08eTLL49LT0zV27Fh17NhRzZo1y9+QAAAAQD7J1bqWd955J79zZOnKlSuSJDc3N6txV1dXScp2LfqSJUsUExOjjz/+OH8DItdKuDupiJNtliSkJifp0mWucAIAgPtPwS9CvwOGYUhSprvSZIzb22f+xUBUVJRmzpyp2bNnq1ixYvecoWRJt9vvhFz58eMuNpm37vBNKlXKdmuX73elSt37/6P8YuZskvnzmZmZHzuy3T0z5zNzNsn8+czqQXjc7rqsJyQk6L333tPzzz+vihUr5mUmi4yyfesV9MTERKvtGdLS0jR27Fh16NBB/v7+Vst20tPTlZqaescvko2NTVB6unE38XETW/9nuXDhik3nvxdmfuzIlrP79d+d2R87W+cj290zcz4zZ5P4fnK37pfHzd7eLtsLxHf9pkjXr1/Xhg0bdP78+bsOdjsZa9Wjo6Otxk+fPm21PcNff/2lI0eOaMOGDfL19bV8SNKcOXMsfwYAAADuB/e0DCZjOUp+8fb2lqenp7Zt26a2bdtaxr/66itVqFBBZcuWtdq/dOnSWrt2babzPPPMM+rVq5d69OiRr3kBAACAvGTqNeuSNGLECIWEhMjd3V0tWrTQzp07FR4erhkzZkiS4uLiFB0drUqVKsnNzU01a9bM8jylS5fOdhsAAABgRne9DKagBAQE6O2339a3336rESNGaP/+/QoNDVWnTp0kSbt27VJgYKB+/vlnGycFAAAA8tZdX1l3d3dXWFiYqlWrlpd5stSzZ0/17Nkzy20BAQEKCAjI8fjIyMj8iAUAAADkq2yvrB8+fDjHAx0dHdWgQYMcb4944MCBuw4GAAAAFHbZlvXRo0dr+PDh+umnn+74pN9//70GDx6s119//Z7CAQAAAIVZtstgtm7dqtmzZ6t379567LHH1KZNGzVv3lxVqlRRiRIlrPaNjY3VkSNHdODAAW3btk3nz59Xr169NGfOnHz/AgAAAIAHVbZlvWjRogoODlbv3r21dOlSrV27VosXL5Ykubi4qFixYkpPT9fly5eVmpoqwzD08MMPq3v37ho4cKAee+yxgvoaAAAAgAfSbV9g6uXlpXHjxum1117TgQMHdOjQIcXExCg+Pl729vYqWbKkypYtq3/961+qW7eu7O1Nf4MZAAAA4L6Q67vBODs7y9/fX/7+/vmZBwAAAMD/4TI4AAAAYFKUdQAAAMCkKOsAAACASVHWAQAAAJOirAMAAAAmleu7wWRITU3V0aNH9ddff6lBgwZycXFRWlqa3N3d8yMfAAAAUGjd0ZX18PBwtWjRQr1799Zrr72m33//XQcPHlTz5s01f/78/MoIAAAAFEq5LuvffvutXnvtNVWoUEHBwcEyDEOS5OnpqcqVK+uDDz7QF198kW9BAQAAgMIm12V97ty5qlGjhsLCwtStWzfLeMWKFbVixQrVrVtXS5YsyZeQAAAAQGGU67J+/Phxde7cWfb2mQ8pUqSInnrqKZ08eTJPwwEAAACFWa7LuqOjo1JTU7PdHh8fL0dHxzwJBQAAAOAOynqDBg20du1aJSUlZdp2/vx5rVixQn5+fnkaDgAAACjMcn3rxtGjR6tnz57q2rWrmjVrJjs7O+3YsUO7du3S+vXrlZycrJEjR+ZnVgAAAKBQyfWV9UqVKmn58uUqXbq0li5dKsMwtGzZMi1ZskTly5fX4sWLVa1atfzMCgAAABQqub6y/vvvv6ty5cpaunSp4uPjFR0drfT0dJUrV06lSpXKz4wAAABAoZTrsj5w4EB1795dQUFBKl68uIoXL56PsQAAAADkehnM1atX5enpmZ9ZAAAAANwk11fWBwwYoIULF6pSpUqqV69efmYCgAdeseIucrHR7W6vp6ToSvx1m8wNALgzuS7rx44d04ULF9SvXz+5uLioePHimd4gyc7OThEREXkeEgAeNC6Ojuq0PtQmc2/tHqwroqwDwP0g12U9KSlJNWrUyM8sAAAAAG6S67K+dOnS/MwBAAAA4Ba5LusZ4uPjtW/fPp09e1aOjo4qW7asGjduLDc3t/zIBwAAABRad1TWV6xYoffff1/Xr1+XYRiWcWdnZ73xxhvq06dPngcEAAAACqtcl/WIiAi98847ql69up5//nk9/vjjMgxDUVFRWrRokSZOnKiyZcuqZcuW+ZkXAAAAKDRyXdY//fRTVa9eXatWrZKTk5NlvFq1amrXrp0CAwM1f/58yjoAAACQR3L9pki//vqrunXrZlXUMzg6Oqpbt246fvx4noYDAAAACrNcl3UnJyddu3Yt2+2JiYlycHDIk1AAAAAA7qCs169fX8uXL9f58+czbTt37pxWrFghPz+/PA0HAAAAFGa5XrP+6quvKjAwUB07dtTTTz+tChUqSJKioqK0ceNGpaWladSoUfmVEwAAACh0cl3WK1eurCVLlmjixIlavny51bYaNWpo/PjxqlatWp4HBAAAAAqrO7rPeq1atfTZZ58pNjZWZ8+elWEYKleunB555JH8ygcAAAAUWrlesy5Jx44d0+jRoyXdKO61a9fWggULNHLkSP3xxx/5EhAAAAAorHJd1g8cOKDevXtr7969unTpkmW8VKlSOnjwoJ555hn9+uuv+RISAAAAKIxyXdZnzZolHx8fffXVV6pUqZJlfPDgwdq6dau8vLz0wQcf5EtIAAAAoDDKdVk/fvy4AgMDVbx48Uzb3N3d9dxzz+mnn37Ky2wAAABAoZbrsl6kSBGr5S+3SkhIUHp6ep6EAgAAAHAHZb1hw4ZatmyZYmJiMm07d+6cli1bpgYNGuRpOAAAAKAwy/WtG0eNGqVnn31WXbt2VbNmzVShQgXZ2dkpOjpau3fvlp2dncaMGZMvITdv3qyPPvpIMTExKleunIYNG6ann3462/0vXLigWbNmae/evYqPj5ePj49eeOEFdezYMV/yAQAAAPkh12X98ccf1+eff64ZM2Zoz549+vLLLyVJLi4u8vf315gxY1SxYsU8DxgeHq6goCD1799fTZs2VUREhIKDg+Xi4qIOHTpk2j85OVnPP/+8rly5opEjR6p06dL68ssv9eqrryotLU1PPfVUnmcEAAAA8sMdvSmSt7e3Zs6cKcMwdOnSJaWnp6tEiRJycHDIr3yaPn26OnbsqHHjxkmSmjZtqsuXL2vWrFlZlvU9e/bo119/1Zo1a1SrVi1Jkr+/v/788099+umnlHUAAADcN+7oTZEy2NnZycPDQ46OjkpNTc3rTBYxMTGKjo5Wu3btrMbbt2+vqKioLNfPu7q6KjAwUDVr1rQaf/zxxxUdHZ1vWQEAAIC8lmNZT0lJ0apVqxQSEmI1fuDAAXXu3Fn/+te/VLduXT3//PP5UoSjoqIkST4+Plbj3t7ekqSTJ09mOqZRo0Z65513ZGdnZxlLSUnR7t279cQTT+R5RgAAACC/ZFvWk5OTNWDAAL311lvavHmz5Qr6qVOnNGTIEEVFRalp06YaOHCgTp48qZ49e+rixYt5Gu7KlSuSJDc3N6txV1dXSTduF5kb06ZN06lTpzR06NA8zQcAAADkp2zXrC9ZskQ//vijXn/9dfXp00dFitzYdc6cOUpKStJTTz2ladOmSZKGDh2qLl266OOPP9b48ePzLJxhGJJkdZX85nF7+5xX8RiGoffff1+LFy/WkCFD1KZNmzvOULKk2+13gumVKlXM1hHuW2Z+7MycTTJ3PjNnk8ydj2x3z8z5zJxNMn8+s3oQHrdsy3p4eLjat2+vIUOGWMaSk5O1c+dO2dnZWY0XL15cAQEB2rJlS56W9WLFbjzAt15BT0xMtNqeleTkZI0dO1ZbtmzRkCFD9MYbb9xVhtjYBKWnG3d1LP6frf+zXLhwxabz3wszP3Zky5mZ85k5m2TufGS7e2bOZ+Zs0v37PGbrx+5+edzs7e2yvUCc7aXp06dPq169elZjhw8f1rVr11SqVClVq1bNalv58uV1/vz5PIj7/zLWqt+6Hv706dNW22+VkJCgQYMGKTw8XOPGjbvrog4AAADYUrZlPT09PdMtGb/77jtJUuPGjTPtf+XKFRUtWjRPw3l7e8vT01Pbtm2zGv/qq69UoUIFlS1bNtMxaWlpevHFF3XkyBFNnz5dAwYMyNNMAAAAQEHJdhlM+fLldfz4cauxiIgI2dnZqUWLFpn2//bbb1W+fPk8DzhixAiFhITI3d1dLVq00M6dOxUeHq4ZM2ZIkuLi4hQdHa1KlSrJzc1Nq1at0v79+xUYGKjHHntMhw8ftpzLzs5OtWvXzvOMAAAAQH7Itqx37txZc+fOVbNmzeTv76/Vq1fr999/1yOPPKJWrVpZ7btx40bt3btXo0aNyvOAAQEBSk5O1sKFC7VmzRp5eXkpNDRUnTp1kiTt2rVLISEhCgsLU8OGDS3vrLp69WqtXr3a6lwODg765Zdf8jwjAAAAkB+yLesDBw7UN998o5dffll2dnYyDEOOjo5677335OTkJEnavn27li1bpv3798vHx0cDBw7Ml5A9e/ZUz549s9wWEBCggIAAy+dhYWH5kgEAAMBsSri7qojTXb3HZZ5ITU7XpcuJNpu/MMi2rDs5OWnx4sXaunWrDh8+LFdXV3Xt2lWVKlWy7HPs2DEdOnRIXbt21dixY+Xi4lIgoQEAACAVcbLX7x+es9n8T7z8qM3mLiyyLevSjWUjXbp0UZcuXbLcPnz4cI0aNeq29zsHzKy4u5McnZxtNn9KcpLiLyfbbH4AAGBeOZb128nru78AtuDo5KytCzrZbP5OQ7ZKoqwDAIDMuCQOAAAAmBRlHQAAADApyjoAAABgUpR1AAAAwKTuqazHxsYqLS0tr7IAAAAAuMlty/qyZcvUpUsXpaamZto2adIkNW3aVIsXL86PbAAAAEChlm1ZNwxDb7zxhiZOnKjz58/rzz//zLSPp6en7O3tFRoaqjFjxuRrUAAAAKCwybasr1mzRhs3blTv3r21Z88elS9fPtM+o0eP1o4dO9StWzeFh4drw4YN+ZkVAAAAKFRyLOv169fXhAkT5Oyc/bs7Ojs7a9KkSapatapWrVqVLyEBAACAwijbsn7ixAm1bt06dyext1f79u0VGRmZZ8EAAACAwi7bsu7g4CAnJ6dcn6hEiRKyt+dOkAAAAEBeybZde3t769ixY7k+0dGjR1W2bNk8CQUAAAAgh7LeuXNnbdq0Sb///vttT/L7779r06ZNatasWZ6GAwAAAAqzbMt6YGCgypYtq379+mnjxo1ZvvlRenq6Nm/erEGDBsnV1VUDBgzI17AAAABAYVIkuw2urq766KOP9NJLLyk4OFhvv/22fH19VapUKaWnpys2NlY///yzrl69qscee0xz585V6dKlCzI7AAAA8EDLtqxL0uOPP66NGzdq+fLl2rJliw4dOmR5J1NHR0fVqVNH7dq1U2Bg4B29GBUAAADA7eVY1iXJyclJgwYN0qBBgyRJcXFxcnBwkLu7e76HAwAAAAqzO77XooeHh6Wox8bGZrmWHQAAAMC9u21ZX7Zsmbp06WJZ/nKzSZMmqWnTplq8eHF+ZAMAAAAKtWzLumEYeuONNzRx4kSdP39ef/75Z6Z9PD09ZW9vr9DQUI0ZMyZfgwIAAACFTbZlfc2aNdq4caN69+6tPXv2qHz58pn2GT16tHbs2KFu3bopPDxcGzZsyM+sAAAAQKGSY1mvX7++JkyYIGdn52xP4OzsrEmTJqlq1apatWpVvoQEAAAACqNsy/qJEyfUunXr3J3E3l7t27dXZGRkngUDAAAACrtsy7qDg8Md3Tu9RIkSsre/45vLAAAAAMhGtu3a29tbx44dy/WJjh49qrJly+ZJKAAAAAA5lPXOnTtr06ZN+v333297kt9//12bNm1Ss2bN8jQcAAAAUJhlW9YDAwNVtmxZ9evXTxs3bszyzY/S09O1efNmDRo0SK6urhowYEC+hgUAAAAKkyLZbXB1ddVHH32kl156ScHBwXr77bfl6+urUqVKKT09XbGxsfr555919epVPfbYY5o7d65Kly5dkNkBAACAB1q2ZV2SHn/8cW3cuFHLly/Xli1bdOjQIcs7mTo6OqpOnTpq166dAgMD7+jFqAAAAABuL8eyLklOTk4aNGiQBg0aJEmKi4uTg4OD3N3d8z0cAAAAUJjdtqzfysPDIz9yAAAAALhFtmU9JCTkjk9mZ2enSZMm3VMgAAAAADdkW9bXr18vOzs7SZJhGLk62YNe1j3cXeTg5Giz+dOSUxR3+brN5gcAAEDByrasV65cWb/99ps8PDzUunVrtW3bVo0aNZKjo+3Kqq05ODnqwkfLbDZ/qRf7SqKsAwAAFBbZlvWNGzfqzJkzioiI0Pbt2zV8+HA99NBDatGihdq2bavmzZvLxcWlILMCAAAAhUqOLzD19PTUwIEDNXDgQMXFxSkiIkIREREKCgqSg4ODGjdurLZt26pVq1bcHQYAAADIY9m+g+mtPDw89Nxzz2nevHn67rvv9N5778nZ2VkTJ06Uv7+/Bg4cqBUrVuRnVgAAAKBQueNbN0qSm5ubOnfurM6dO+v3339XaGiovv32W/33v/9V79698zojAAAAUCjdVVk/fPiwdu7cqR07digqKkr29vaqX7++2rRpk9f5AAAAgEIrV2U9OTlZ+/bt044dO/T1118rNjZWLi4uaty4sZ5//nm1bNlSxYsXz+eoAAAAQOGSbVm/dOmSdu3apR07dmjv3r26du2aSpQooRYtWqhNmzZq0qSJnJ2dCyTk5s2b9dFHHykmJkblypXTsGHD9PTTT2e7f2JioqZNm6avvvpKV69eVb169fTmm2+qQoUKBZIXAAAAyAvZlnV/f38ZhiFPT08FBgaqTZs28vPzs7xRUkEJDw9XUFCQ+vfvr6ZNmyoiIkLBwcFycXFRhw4dsjxm9OjROnr0qN544w25urrqww8/VP/+/bVlyxYVK1asQPMDAAAAdyvbsp6eni5JiomJ0ZIlS7RkyZLbnszOzk6//PJL3qWTNH36dHXs2FHjxo2TJDVt2lSXL1/WrFmzsizrBw4c0O7du/Xpp5+qWbNmkqR69eqpdevWWrlypYYOHZqn+QAAAID8km1Z7969e0HmyFJMTIyio6M1ZswYq/H27dsrPDxcMTEx8vLystq2d+9eubq6yt/f3zLm4eGh+vXra8+ePZR1AAAA3DeyLeuTJ08uyBxZioqKkiT5+PhYjXt7e0uSTp48mamsR0VFydvbWw4ODlbj5cuXV3h4eD6mBQAAAPJWrt8UyRauXLki6cZ93W/m6uoqSUpISMh0TEJCQqb9M47Jan8AAADArOwMwzBsHSI7mzZtUlBQkHbu3Kly5cpZxk+dOqX27dtnuW598ODBSklJ0dKlS63GZ8yYobCwMP344493ncdITZNdEYfb75hPcprfSE2RXRHHAk6U+/nTU5NlX8SpABPlfu601GQ52ChbbuZPTUtWEQfb5Lvd3GbOlpyWLCcbZcvN/MlpqXJyuKu3urhnt5vbltlyM39yWpqcHGzzvfh2c5s7W7qcHGx3je5286emGSriULA3scjt3GlphhxslO1286enGrIvYrtst5vfSE2XXRHb/Luz5dx5yXbfjXMh484tt14RT0xMtNp+Mzc3N505cybTeGJiYpZX3G8nNjZB6emm/XnGolSpYvrrP2/abP7HXnpPFy5cuc1eSQWS5e7mtmW23MzPY3d3c5v97xUAAMne3k4lS2bdU03940bGWvXo6Gir8dOnT1ttv/WYmJgY3foLg9OnT2e5PwAAAGBWpi7r3t7e8vT01LZt26zGv/rqK1WoUEFly5bNdEyTJk30zz//aN++fZaxuLg4HThwQI0bN873zAAAAEBeMfUyGEkaMWKEQkJC5O7urhYtWmjnzp0KDw/XjBkzJN0o4tHR0apUqZLc3NxUv359NWjQQGPGjFFQUJCKFy+uOXPmqFixYurVq5eNvxoAAAAg90xf1gMCApScnKyFCxdqzZo18vLyUmhoqDp16iRJ2rVrl0JCQhQWFqaGDRtKkj788ENNmTJFU6dOVXp6uvz8/DRz5ky5u7vb8ksBAAAA7oip7wZjBrzANHdy9wJTAAAA3Oq+fYEpAAAAUJhR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJmX6sp6YmKi3335b/v7+qlu3rl544QWdOnXqtsd999136tu3r+rXry9/f3+98soriomJyf/AAAAAQB4xfVkfPXq0tm3bpqCgIIWGhurcuXPq37+/rly5ku0xhw4d0pAhQ1SiRAlNmzZN48eP16lTp9SrVy9dunSpANMDAAAAd6+IrQPk5MCBA9q9e7c+/fRTNWvWTJJUr149tW7dWitXrtTQoUOzPG7+/PmqWLGiZs2aJXv7Gz+PPPnkk2rRooW++OILDRw4sKC+BAAAAOCumfrK+t69e+Xq6ip/f3/LmIeHh+rXr689e/Zke1ytWrU0YMAAS1GXpEcffVTFihVjKQwAAADuG6a+sh4VFSVvb285ODhYjZcvX17h4eHZHjd8+PBMY/v379fly5dVqVKlPM8JAAAA5AeblfXU1FRt2bIl2+2PPPKIEhIS5Obmlmmbq6urEhIScj1XXFyc/ud//kdlypRRt27d7iovAAAAUNBsVtaTkpL0xhtvZLu9QYMGcnR0zHb7zUtccnL+/HkNGTJE58+f1+LFi/XQQw/dUc6SJTP/sICslSpVzNYRAAAAHig2K+uurq6KjIzMcZ+RI0fqzJkzmcYTExOzvOJ+q8jISA0fPlyJiYmaP3++ateufcc5Y2MTlJ5u3PFxBc0MRfnChezv0AMAAICs2dvbZXuB2NQvMPXx8VFMTIwMw7osnz59Wj4+Pjkeu3//fvXu3VuGYWj58uXy8/PLz6gAAABAnjN1WW/SpIn++ecf7du3zzIWFxenAwcOqHHjxtke9+uvv2rYsGF67LHHtHr1aj3xxBMFERcAAADIU3bGrZetTaZfv3767bffFBQUpOLFi2vOnDmKj4/Xpk2b5O7uLkk6ceKEkpOTVb16dUnSM888o19//VXTpk1TmTJlrM5XsmRJeXl55Xr++2UZjIe7sxycnGw2f1pysuIuJ9lsfgAAgPtVTstgTF/WL1++rClTpigiIkLp6eny8/PT2LFj9fjjj1v26devn86ePaudO3fqzz//VMuWLbM93zPPPKP33nsv1/PfL2UdAAAA96f7uqzbGmUdAAAA+em+fYEpAAAAUJhR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJlXE1gHMzt7eztYRAAAA8ADLqW/aGYZhFGAWAAAAALnEMhgAAADApCjrAAAAgElR1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrBWDz5s3q3LmzatWqpY4dO2rDhg22jpTJ8ePH5evrq7///tvWUSzS09O1cuVKdenSRXXr1lWbNm00efJkJSQk2DqaDMPQ4sWL1b59e9WqVUtdu3bVpk2bbB0rSy+//LLatm1r6xgWqampqlWrlqpUqWL1UbduXVtHkyT98MMP6tWrl2rXrq0mTZro3XffVWJioq1j6b///W+mx+zmj/Xr19s6olauXKmOHTuqTp066tKlizZu3GjrSJKk69evKzQ0VE2aNFHt2rUVGBio3bt32zpWtt93v/32W/Xo0UO1a9dWq1attHDhQlPlk6Rdu3bJ19fXBqluyC5beHi4evToobp166p58+YKCQlRbGysKbJt3LhRXbp0Ue3atdW+fXuFhYXJFm8in5vn+0mTJql69eoFmOqG7LK1bds2y+97cXFxpsgXGRmpIUOGqG7dumrUqJFef/11Xbx4Mc/mLZJnZ0KWwsPDFRQUpP79+6tp06aKiIhQcHCwXFxc1KFDB1vHkyRFRUVp2LBhSk1NtXUUK/Pnz9fMmTM1ZMgQNWrUSCdPntTs2bN14sQJLViwwKbZPvnkE82ePVuvvPKK6tSpoz179igoKEgODg7q1KmTTbPd7IsvvtD27dtVvnx5W0exOHnypJKSkhQaGqoKFSpYxu3tbX/t4PDhwxo0aJBatWqljz76SKdPn9b06dMVFxenGTNm2DSbr6+vVq9ebTVmGIbefPNNXb16Vc2bN7dRshtWr16tt956S4MHD1bTpk21e/duvf7663J0dFTHjh1tmm3UqFHau3evhg4dqnr16unAgQN6+eWXNW3aNLVv394mmbL7vnvo0CENHz5cHTt21KhRo3Tw4EFNnTpVhmFoyJAhNs+XkfG1116zSdGUss+2detWjR49WoGBgRo9erQuXLig2bNna+DAgVq3bp2cnJxslm3Tpk16/fXXNWjQII0bN05HjhzRlClTlJSUpBdeeCHfc90u381++OEHLV26VHZ2dgWWS8o+W2JiomJiYvTaa6+pQYMGVtsefvhhm+eLiYlRnz59VK1aNc2cOVPx8fH64IMPNGLEiEzfs++agXzVpk0b49VXX7UaGzVqlNGhQwcbJfp/KSkpxrJly4y6desaDRo0MCpXrmz89ddfto5lGIZhpKenG/Xr1zfeeustq/EtW7YYlStXNn755RcbJTOM5ORko379+sY777xjNd63b1+jV69eNkqV2d9//23Ur1/faNasmdGmTRtbx7HYuHGjUbVqVePq1au2jpJJnz59jD59+hjp6emWsWXLlhmtW7c2Zd7FixcbVatWNQ4fPmzrKEZgYKDRr18/q7HevXsbffv2tVGiG44dO2ZUrlzZ+PTTT63Gp06dajRr1sxIS0sr0Dy3+747YMAA49lnn82UtV69ekZSUpJN8127ds2YO3eu4evrazRo0MCoVq1avufJbTbDMIyuXbsaL7zwgtUxhw8fNipXrmxs377dptk6d+5sDBs2zOqY4OBgo1mzZvmaK7f5MiQmJhqtW7c2mjVrVmB/v7fLdvDgQaNy5crGiRMnCiTPneZ74403jLZt2xrXr1+3jO3YscNo1qyZER0dnScZbH8p6wEWExOj6OhotWvXzmq8ffv2ioqKUkxMjI2S3XDw4EFNmzZNgwcPVlBQkE2z3CoxMVFdu3bVU089ZTX++OOPS5Kio6NtEUuS5ODgoKVLl2ro0KFW446OjkpKSrJRqszGjx8vf39/NWrUyNZRrBw/flzly5dX0aJFbR3FSlxcnA4cOKBevXpZXVHq06ePIiIiTJf34sWLmjVrlmXJjq0lJSXJ1dXVaqx48eKKj4+3TaD/c/LkSUlSy5Ytrcbr16+vv//+W5GRkQWaJ6fvu0lJSTpw4ECWzxn//POPDh06ZNN8W7du1ZIlSxQSEqK+ffvme5Y7yWYYhho3bqznnnvOarygnjNu93w6Z84cvfnmm1ZjBfmckdvn+9DQUD3yyCMKCAgokFy5yXb8+HE5Oztb/Sa2IN3u311ERISeeeYZOTs7W8ZbtWql3bt3y8vLK08yUNbzUVRUlCTJx8fHatzb21vS/z+J2ErFihUVERGhl19+WQ4ODjbNcis3NzeNHz9efn5+VuMRERGSpEqVKtkilqQbyzWqVKmiRx99VIZh6OLFi5o3b5727dunwMBAm+W62Zo1a/Tzzz/rf/7nf2wdJZPIyEg5OTlZ1vfVr19fEyZMsPlrEX777TcZhiF3d3e9+uqrqlOnjvz8/PTvf/9b169ft2m2rMyePVv29vZ69dVXbR1FktS/f3998803Cg8PV0JCgrZt26Zdu3apW7duNs312GOPSZLOnj1rNZ5xsaSgL5rk9H03JiZGKSkpNn3OyClfw4YNtWPHDvXp0yffc9xpNjs7OwUHB6tNmzZW4wX1nHG751MfHx9LcYuPj9eaNWu0YcOGAnvOyM3z/d69e/XFF19o8uTJBbos8XbZIiMjVbx4cY0ZM0b16tVT3bp1LcucbJ3vzJkzSkhIUJkyZTRhwgTVq1dPtWvX1pgxY3Tp0qU8y8Ca9Xx05coVSTeK580yrj7Zupw88sgjNp3/Th05ckTz5s1TmzZtVLFiRVvHkSR99dVXGjlypCSpRYsW6tq1q40T3SglkydP1uTJk+Xh4WHrOJn8+uuvSkhI0LPPPqvhw4fr2LFjmjNnjk6ePKmwsLACXyeZIeOFSmPHjlXbtm310UcfKTIyUjNnzlRSUpKmTJlik1xZiYuL04YNGzR48OACXbOZk86dO+v777+3+uGhe/fuev75520XSlLNmjVVqVIlvfvuu5o0aZKqVaumQ4cOWV73cvXq1QLNk9P3XTM8Z+SUr1y5cvk+f07u9DkrOjpaoaGh8vX1VZMmTfIp1Q25zXbs2DH16NFDklSjRg0NGjQoP2NZ3C7flStX9Oabb2rkyJGZfljMb7fL9uuvv+rixYt64okn1K9fP0VFRWn27Nnq37+/1q9fLxcXF5vlyyjkU6dOlZ+fn2bNmqU///xT06ZN08iRI7V06dI8yUBZz0fG/7345tbykTFuhhfU3S8OHjyo4cOHy9PTUxMnTrR1HIvq1atr2bJlioyM1KxZszR06FCFhYXZLI9hGBo3bpyaN29usxfO3c6MGTPk7u6uKlWqSLqxHKFkyZJ6/fXXtW/fPvn7+9skV0pKiiTpySef1L///W9JUqNGjWQYhkJDQzVixIg8+5Xmvfrss8+Unp6u/v372zqKxYsvvqgff/xRISEhql69uo4cOaL//Oc/lt+S2YqTk5M+/PBDBQcHW5ZueHp66tVXX1VwcLCpljdl95yRgeeM3Pvjjz80ZMgQFSlSRDNnzjTNY1emTBmFhYXp7Nmzmjlzpnr37q3169dbLaGwhUmTJqlMmTIaOHCgTXNkZfz48TIMw7Lcr169eqpYsaJ69+6tjRs3Zlr6VJCSk5MlSY8++qhmzpxp+b/r7u6uV155Rd9//73+9a9/3fM8lPV8VKxYMUmZr4Zk3AYuYztytnXrVo0dO1YVKlTQ/PnzVaJECVtHsvDy8pKXl5fq168vNzc3BQcH68cff7TZbQiXL1+uyMhIbdq0yfKK9YwCkJqaKgcHB5tduc5w66v5pRu/lZBuXEGxVVnPuHrZrFkzq/EmTZpoypQpioyMNE1Z//LLL9W0aVPT/Obk0KFD+vbbbzV58mTLWtcGDRro4Ycf1oQJE/Tss89afjizBR8fH3322We6cOGCrly5ogoVKujgwYOSbjypmkV2zxkZn/OckTv//e9/9corr+ihhx7SkiVLTHU3rEceecRypdbLy0t9+/bV9u3bM70+qyB9/fXX2rJli9atW6f09HTLh3TjecPe3t6mP+zUqlUr05ifn5+KFSumX3/91QaJ/l/Gb8GaNWtm9dya8TwWGRmZJ2XdHD9qPqAyfpV06wtbTp8+bbUd2Vu0aJHGjBmjOnXqaPny5SpdurStIyk+Pl4bNmzQuXPnrMYz7kl763hB+vLLL3Xp0iU1adJEvr6+8vX11YYNGxQdHS1fX1+b34s7NjZWa9asybROOGNNuC1/EMt48VLGlZIMGVfcbf1DToZz587pl19+sfntEG/2559/SrrxW4mb1atXT9KNq5y2cv36dX3xxRc6e/asSpUqpccff1z29vb6+eefZWdnp2rVqtks263Kly8vBweHTM8ZGZ/znHF7W7du1ZAhQ/Too49q9erVplgymZSUpM2bN1tex5bBDM8Z0o3njaSkJD311FOW543//Oc/SktLk6+vr+bOnWuzbFevXtW6desylXLDMJSSkmLzi3deXl6ys7PL9LyRlpYmKe+eNyjr+cjb21uenp7atm2b1fhXX32lChUqqGzZsjZKdn9Ys2aNpkyZoo4dO2r+/PmmuaqUnp6usWPHZrp/6t69eyVJlStXtkUsSdLbb7+ttWvXWn20bNlSZcqUsfzZluzs7DRhwgQtW7bManzr1q1ycHDI9ILiglSxYkWVK1dOW7dutRr/+uuvVaRIEdO8adORI0ckyaaP1a0ySuQPP/xgNX748GFJtl3r7OjoqHfeeUfr1q2zjF2/fl2rV69W/fr1TXVl3dnZWfXq1dNXX31ldQ/zL7/8UsWKFVONGjVsmM78vvnmG73++uuqW7euVq5cqUcffdTWkSRJRYoU0dtvv61PPvnEatwMzxnSjTfOu/V547nnnpODg4Plz7bi7Oys0NBQffjhh1bjO3bs0PXr17P8TW1BcnV1lZ+fn7Zv3265sCNJO3fulPT/FyzuFctg8tmIESMUEhIid3d3tWjRQjt37lR4eLjN32DF7GJjY/Xee++pXLly6tOnj3755Rer7eXLl7fZEgAPDw/17t1b8+bNk4uLi2rWrKmDBw/qk08+0bPPPmu5VZgtZDV38eLF5eTkpJo1a9ogkTUPDw/16dNHS5culZubm+rVq6eDBw/q448/Vp8+fSx3vbAFOzs7BQUFacyYMQoKClJAQICOHTumjz76SP369TPNkpPffvtNRYsWtfmL/W7m6+urNm3aaNKkSUpMTFS1atV07NgxzZ07V82aNbPprSUdHBzUs2dPLVq0SKVLl5anp6fmz5+vP//8U6GhoTbLlZ0XX3xRgwYN0ujRo9W9e3f9+OOPWrBggV577TVTra83m+TkZL355pt66KGHNHz4cJ04ccJq+2OPPWaz8u7g4KDhw4dr6tSpKlWqlPz9/RUZGakPP/xQ/v7++f7i19vx9PSUp6en1diuXbskyebPGw4ODnrxxRc1ZcoUTZw4Ua1atdJvv/2mOXPmqHXr1mrYsKFN80nS6NGjNXDgQA0fPlwDBw7UmTNnNG3aNLVt2zbP3gWWsp7PAgIClJycrIULF2rNmjXy8vJSaGioqd7l0oy++eYbXbt2TWfPns3yNmFTp0616S3hQkJC9Nhjj2nt2rWaM2eOypQpo1deecXmd764HwQHB+vRRx/VunXrNG/ePD366KMaOXKkKR67Tp06ycnJSXPnztWwYcNUsmRJjRgxQsOGDbN1NIuLFy+a5g4wN5sxY4Y+/PBDLV68WLGxsSpXrpwGDx6c6f0IbGHUqFGyt7fXf/7zHyUkJKhmzZpavHhxlmthba1Ro0aaM2eOZs+erREjRujRRx/VG2+8ocGDB9s6mqkdOXLEspwkq8dq1KhReumllwo6lsWQIUP08MMPKywsTGFhYSpRooQCAwM1cuRI0yyxM6tBgwbJzc1NYWFhWrNmjdzd3dWzZ0+98sorto4m6cbV88WLF2v69OkaMWKEihUrpmeeeUZjxozJsznsDMNG7xcMAAAAIEesWQcAAABMirIOAAAAmBRlHQAAADApyjoAAABgUpR1AAAAwKQo6wAAAIBJUdYB4AE1duxYValSxeqjRo0aatWqld59911dvnz5rs+dkJCguLi4u8pzL3bv3q2qVasqMTFRkvTLL7+oSpUqOnny5D2dFwDMijdFAoAHXEhIiEqUKCFJSkpK0okTJ7R69WodPXpUK1eulIODwx2d79ixY3rxxRc1bdq0An8HwePHj8vb21uurq6SbpR1V1dXVahQoUBzAEBBoawDwAOuTZs2md5OvEKFCnr77be1Z88etWzZ8o7O99tvv+n8+fN5GTHXfvnlF6u38D5+/LiqVavGu0ACeGCxDAYACqGMK+InTpywcZI7k1HOM9xa3gHgQUNZB4BC6O+//5YkeXl5WY1v27ZNffv2lZ+fn2V9+9SpU5WcnCxJmjNnjkJCQiRJ/fv3V6tWrSzHnjt3TuPGjVOTJk1Ut25d9ejRQxEREZnmPnr0qPr166datWrJ399fkyZNUlJSUrZZb157Hx0drQ8++MDy+aFDhxQWFnbPa+EBwKxYBgMAD7h//vnH8mLQlJQU/fHHH5o4caJ8fX2tyvaaNWs0fvx4tWrVSkFBQUpJSdH27du1YMECPfTQQ3r55ZfVtm1bXbhwQatXr9bw4cNVs2ZNSVJ8fLyee+45xcfHq0+fPvLy8tLmzZv18ssv68MPP1SbNm0s8wwYMEBdu3ZV586dtWvXLi1ZskSGYejNN9/MMn9gYKAaNWqk3377TfPnz9fEiRPl5OSkv/76SzNmzNDrr7+uUqVK5eMjCAC2Y2cYhmHrEACAvDd27FitX78+y20uLi4KCwtT7dq1LWMdO3aUu7u7Vq5caVkDnpqaqtatW+vhhx/Wpk2bJEmff/65QkJCFBYWZllO8/7772v+/PlasWKF/Pz8JN14MetTTz0ld3d3rV271pInJCREAwcOlCSlp6erQ4cOSk5O1q5du3L8esLCwvTpp5/qm2++kSRt3bpVb7zxhg4dOiQnJ6e7fpwAwMy4sg4AD7j3339fjzzyiKQbV9bPnj2r5cuXq0+fPvrkk0/k7+8vSdq4caOuXbtm9WLN2NhYPfzww7p69WqOc+zatUu+vr6Woi5Jzs7Omjdvnpydna327dy5s+XP9vb2ql69epbLZW7166+/qmrVqpbPIyMjVbFiRYo6gAcaZR0AHnBPPvlkprvBdOzYUe3atdPEiRMVHh4uSXJ0dNQPP/ygzZs3KyoqStHR0YqNjZUklStXLsc5zp49a7WkJoOPj0+msZIlS1p97uLiopSUlGzPnZiYqKSkJB0/flx+fn6WJT3Hjh2Tj4+P5XMPD48cMwLA/YiyDgCFUIkSJdSwYUNt375dly9flru7uz744APNmzdP1atXV506ddStWzfVrVtX7777rv76668cz5eWlpbr2yfa29/ZvQ3effddy3KeX375RUuXLrXanvHDRmRk5B2dFwDuB5R1ACik0tPTJd0oz2fPntW8efPUrVs3TZ061Wq/ixcv3vZcZcuWVXR0dKbx9evX6+DBg5owYcJd53z++edVo0YNvfvuu5o+fbpKlCih2NhYBQUFacKECVlevQeABwW3bgSAQujixYv6/vvvVa1aNRUrVkyXL1+WJFWqVMlqv927d+vUqVNKTU21jGVcGc8o+5LUrFkzHT16VMeOHbOMpaSkaMGCBTp27Ng9rSuvVKmSnJyc5O7urs6dO6tx48Zyc3OTg4ODAgIC1LhxYzVu3Piuzw8AZsaVdQB4wEVERKhEiRKSJMMw9Pfff+uzzz7TtWvXNHr0aEk3CnHZsmX18ccfKykpSWXKlNFPP/2k9evXy9nZWYmJiZbzZawNX7lypS5evKguXbpo2LBh2rZtmwYMGKC+ffuqdOnS2rJli/744w8tWLDgnr+Go0ePqkaNGpbPf/75Z1WsWFFFixa953MDgJlR1gHgATd58mTLnx0cHOTu7q6aNWvqvffeU6NGjSRJTk5OmjdvnqZMmaKwsDAZhqHy5ctr3LhxSk1N1Xvvvadjx46pRo0aatSokTp27Kivv/5a33//vdq1a6dHHnlEn332mT744AOtWrVKycnJqlq1qhYuXGiZ414cO3ZMTZs2tfr85vIOAA8q7rMOAAAAmBRr1gEAAACToqwDAAAAJkVZBwAAAEyKsg4AAACYFGUdAAAAMCnKOgAAAGBSlHUAAADApCjrAAAAgElR1gEAAACToqwDAAAAJvW/uoom9tK9an0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.497\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
